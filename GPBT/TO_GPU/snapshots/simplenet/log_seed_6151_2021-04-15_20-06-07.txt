save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.9895850269290718, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 6151, 'use_cuda': True, 'aiteration': 0, 'drp': 0.14802166088097174, 'eps': 0.007552098517287806, 'lr': 0.3231584326589826, 'weight_decay': 0.00010263420345491692}
Random Seed: 6151
python version : 3.7.10 (default, Feb 20 2021, 21:17:23)  [GCC 7.5.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '6151'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-04-15 20:06:10] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.323158] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 0.263 (0.263)   Data 0.153 (0.153)   Loss 2.3712 (2.3712)   Prec@1 9.000 (9.000)   Prec@5 55.000 (55.000)   [2021-04-15 20:06:10]
  Epoch: [000][200/500]   Time 0.181 (0.180)   Data 0.000 (0.001)   Loss 1.6614 (1.8824)   Prec@1 36.000 (30.358)   Prec@5 91.000 (83.438)   [2021-04-15 20:06:46]
  Epoch: [000][400/500]   Time 0.180 (0.179)   Data 0.000 (0.001)   Loss 1.3768 (1.7071)   Prec@1 52.000 (36.843)   Prec@5 95.000 (87.411)   [2021-04-15 20:07:22]
  **Train** Prec@1 39.450 Prec@5 88.694 Error@1 60.550
  **Test** Prec@1 54.000 Prec@5 95.500 Error@1 46.000
  **Test** Prec@1 54.780 Prec@5 95.280 Error@1 45.220

==>>[2021-04-15 20:07:45] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.323158] [Best : Accuracy=54.00, Error=46.00]
  Epoch: [001][000/500]   Time 0.240 (0.240)   Data 0.144 (0.144)   Loss 1.2720 (1.2720)   Prec@1 55.000 (55.000)   Prec@5 94.000 (94.000)   [2021-04-15 20:07:45]
  Epoch: [001][200/500]   Time 0.181 (0.179)   Data 0.000 (0.001)   Loss 1.1811 (1.2489)   Prec@1 59.000 (55.065)   Prec@5 94.000 (94.706)   [2021-04-15 20:08:21]
  Epoch: [001][400/500]   Time 0.180 (0.179)   Data 0.000 (0.001)   Loss 1.1150 (1.1850)   Prec@1 61.000 (57.401)   Prec@5 94.000 (95.344)   [2021-04-15 20:08:57]
  **Train** Prec@1 58.576 Prec@5 95.578 Error@1 41.424
  **Test** Prec@1 64.900 Prec@5 97.420 Error@1 35.100

==>>[2021-04-15 20:09:17] [Epoch=002/540] [Need: 00:00:00] [learning_rate=0.323158] [Best : Accuracy=64.90, Error=35.10]
  Epoch: [002][000/500]   Time 0.235 (0.235)   Data 0.144 (0.144)   Loss 0.9362 (0.9362)   Prec@1 62.000 (62.000)   Prec@5 100.000 (100.000)   [2021-04-15 20:09:18]
  Epoch: [002][200/500]   Time 0.179 (0.179)   Data 0.000 (0.001)   Loss 1.0709 (0.9807)   Prec@1 59.000 (65.239)   Prec@5 97.000 (96.816)   [2021-04-15 20:09:54]
  Epoch: [002][400/500]   Time 0.177 (0.179)   Data 0.000 (0.001)   Loss 0.9925 (0.9417)   Prec@1 66.000 (66.758)   Prec@5 99.000 (97.125)   [2021-04-15 20:10:29]
  **Train** Prec@1 67.324 Prec@5 97.240 Error@1 32.676
  **Test** Prec@1 70.320 Prec@5 98.000 Error@1 29.680

==>>[2021-04-15 20:10:50] [Epoch=003/540] [Need: 00:00:00] [learning_rate=0.323158] [Best : Accuracy=70.32, Error=29.68]
  Epoch: [003][000/500]   Time 0.263 (0.263)   Data 0.158 (0.158)   Loss 0.9504 (0.9504)   Prec@1 63.000 (63.000)   Prec@5 99.000 (99.000)   [2021-04-15 20:10:50]
  Epoch: [003][200/500]   Time 0.180 (0.179)   Data 0.000 (0.001)   Loss 0.8300 (0.8288)   Prec@1 71.000 (71.109)   Prec@5 99.000 (97.692)   [2021-04-15 20:11:26]
  Epoch: [003][400/500]   Time 0.179 (0.179)   Data 0.000 (0.001)   Loss 0.7085 (0.7973)   Prec@1 78.000 (72.342)   Prec@5 97.000 (97.935)   [2021-04-15 20:12:02]
  **Train** Prec@1 72.666 Prec@5 97.982 Error@1 27.334
  **Test** Prec@1 78.560 Prec@5 98.980 Error@1 21.440

==>>[2021-04-15 20:12:22] [Epoch=004/540] [Need: 00:00:00] [learning_rate=0.323158] [Best : Accuracy=78.56, Error=21.44]
  Epoch: [004][000/500]   Time 0.253 (0.253)   Data 0.148 (0.148)   Loss 0.9240 (0.9240)   Prec@1 67.000 (67.000)   Prec@5 98.000 (98.000)   [2021-04-15 20:12:22]
  Epoch: [004][200/500]   Time 0.179 (0.179)   Data 0.000 (0.001)   Loss 0.6922 (0.7028)   Prec@1 74.000 (76.109)   Prec@5 100.000 (98.418)   [2021-04-15 20:12:58]
  Epoch: [004][400/500]   Time 0.180 (0.179)   Data 0.000 (0.001)   Loss 0.6407 (0.6964)   Prec@1 81.000 (76.080)   Prec@5 99.000 (98.459)   [2021-04-15 20:13:34]
  **Train** Prec@1 76.150 Prec@5 98.442 Error@1 23.850
  **Test** Prec@1 79.340 Prec@5 99.040 Error@1 20.660

==>>[2021-04-15 20:13:55] [Epoch=005/540] [Need: 00:00:00] [learning_rate=0.323158] [Best : Accuracy=79.34, Error=20.66]
  Epoch: [005][000/500]   Time 0.248 (0.248)   Data 0.137 (0.137)   Loss 0.6868 (0.6868)   Prec@1 77.000 (77.000)   Prec@5 100.000 (100.000)   [2021-04-15 20:13:55]
  Epoch: [005][200/500]   Time 0.178 (0.179)   Data 0.000 (0.001)   Loss 0.6823 (0.6415)   Prec@1 76.000 (77.980)   Prec@5 99.000 (98.791)   [2021-04-15 20:14:31]
  Epoch: [005][400/500]   Time 0.181 (0.179)   Data 0.000 (0.001)   Loss 0.5364 (0.6318)   Prec@1 77.000 (78.486)   Prec@5 98.000 (98.711)   [2021-04-15 20:15:06]
  **Train** Prec@1 78.636 Prec@5 98.744 Error@1 21.364
  **Test** Prec@1 82.380 Prec@5 99.180 Error@1 17.620
  **Test** Prec@1 83.100 Prec@5 99.240 Error@1 16.900

==>>[2021-04-15 20:15:30] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.003415] [Best : Accuracy=54.00, Error=46.00]
  Epoch: [001][000/500]   Time 0.269 (0.269)   Data 0.169 (0.169)   Loss 1.3069 (1.3069)   Prec@1 54.000 (54.000)   Prec@5 94.000 (94.000)   [2021-04-15 20:15:30]
  Epoch: [001][200/500]   Time 0.181 (0.180)   Data 0.000 (0.001)   Loss 1.2661 (1.2405)   Prec@1 52.000 (54.925)   Prec@5 94.000 (94.562)   [2021-04-15 20:16:06]
  Epoch: [001][400/500]   Time 0.179 (0.179)   Data 0.000 (0.001)   Loss 1.1031 (1.2216)   Prec@1 62.000 (55.688)   Prec@5 96.000 (94.840)   [2021-04-15 20:16:42]
  **Train** Prec@1 55.826 Prec@5 94.896 Error@1 44.174
  **Test** Prec@1 62.100 Prec@5 96.720 Error@1 37.900
