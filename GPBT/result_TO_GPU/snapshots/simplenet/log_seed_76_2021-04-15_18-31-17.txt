save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.9894003195096542, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 76, 'use_cuda': True, 'aiteration': 0, 'drp': 0.052945317398942746, 'eps': 0.00015956380988939453, 'lr': 0.04460441217910627, 'weight_decay': 0.00470886487439014}
Random Seed: 76
python version : 3.7.10 (default, Feb 20 2021, 21:17:23)  [GCC 7.5.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '76'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-04-15 18:31:20] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.044604] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 0.274 (0.274)   Data 0.157 (0.157)   Loss 2.3703 (2.3703)   Prec@1 12.000 (12.000)   Prec@5 46.000 (46.000)   [2021-04-15 18:31:20]
  Epoch: [000][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 1.6420 (1.7920)   Prec@1 41.000 (32.915)   Prec@5 86.000 (84.716)   [2021-04-15 18:31:56]
  Epoch: [000][400/500]   Time 0.177 (0.180)   Data 0.000 (0.001)   Loss 1.5769 (1.6482)   Prec@1 40.000 (38.421)   Prec@5 92.000 (88.092)   [2021-04-15 18:32:32]
  **Train** Prec@1 40.626 Prec@5 89.144 Error@1 59.374
  **Test** Prec@1 55.060 Prec@5 95.600 Error@1 44.940
  **Test** Prec@1 54.840 Prec@5 94.940 Error@1 45.160

==>>[2021-04-15 18:34:34] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.044604] [Best : Accuracy=55.06, Error=44.94]
  Epoch: [001][000/500]   Time 0.262 (0.262)   Data 0.157 (0.157)   Loss 1.3797 (1.3797)   Prec@1 53.000 (53.000)   Prec@5 92.000 (92.000)   [2021-04-15 18:34:34]
  Epoch: [001][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 1.1934 (1.2724)   Prec@1 56.000 (53.965)   Prec@5 97.000 (94.239)   [2021-04-15 18:35:10]
  Epoch: [001][400/500]   Time 0.177 (0.179)   Data 0.000 (0.001)   Loss 1.2735 (1.2193)   Prec@1 52.000 (55.925)   Prec@5 96.000 (94.828)   [2021-04-15 18:35:46]
  **Train** Prec@1 56.948 Prec@5 95.138 Error@1 43.052
  **Test** Prec@1 63.980 Prec@5 96.700 Error@1 36.020

==>>[2021-04-15 18:36:06] [Epoch=002/540] [Need: 00:00:00] [learning_rate=0.044604] [Best : Accuracy=63.98, Error=36.02]
  Epoch: [002][000/500]   Time 0.260 (0.260)   Data 0.153 (0.153)   Loss 1.0021 (1.0021)   Prec@1 62.000 (62.000)   Prec@5 97.000 (97.000)   [2021-04-15 18:36:07]
  Epoch: [002][200/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.9807 (1.0019)   Prec@1 63.000 (63.866)   Prec@5 98.000 (96.697)   [2021-04-15 18:36:42]
  Epoch: [002][400/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.8351 (0.9731)   Prec@1 70.000 (65.217)   Prec@5 100.000 (96.880)   [2021-04-15 18:37:18]
  **Train** Prec@1 65.826 Prec@5 96.944 Error@1 34.174
  **Test** Prec@1 70.160 Prec@5 97.680 Error@1 29.840

==>>[2021-04-15 18:37:39] [Epoch=003/540] [Need: 00:00:00] [learning_rate=0.044604] [Best : Accuracy=70.16, Error=29.84]
  Epoch: [003][000/500]   Time 0.259 (0.259)   Data 0.155 (0.155)   Loss 1.0695 (1.0695)   Prec@1 64.000 (64.000)   Prec@5 93.000 (93.000)   [2021-04-15 18:37:39]
  Epoch: [003][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.8386 (0.8512)   Prec@1 72.000 (70.269)   Prec@5 99.000 (97.746)   [2021-04-15 18:38:15]
  Epoch: [003][400/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.6932 (0.8335)   Prec@1 75.000 (70.923)   Prec@5 97.000 (97.733)   [2021-04-15 18:38:51]
  **Train** Prec@1 71.458 Prec@5 97.824 Error@1 28.542
  **Test** Prec@1 73.180 Prec@5 97.640 Error@1 26.820

==>>[2021-04-15 18:39:12] [Epoch=004/540] [Need: 00:00:00] [learning_rate=0.044604] [Best : Accuracy=73.18, Error=26.82]
  Epoch: [004][000/500]   Time 0.267 (0.267)   Data 0.160 (0.160)   Loss 0.8230 (0.8230)   Prec@1 68.000 (68.000)   Prec@5 98.000 (98.000)   [2021-04-15 18:39:12]
  Epoch: [004][200/500]   Time 0.183 (0.180)   Data 0.000 (0.001)   Loss 0.7491 (0.7482)   Prec@1 73.000 (74.095)   Prec@5 99.000 (98.129)   [2021-04-15 18:39:48]
  Epoch: [004][400/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.5913 (0.7306)   Prec@1 78.000 (74.868)   Prec@5 97.000 (98.204)   [2021-04-15 18:40:24]
  **Train** Prec@1 75.116 Prec@5 98.200 Error@1 24.884
  **Test** Prec@1 74.020 Prec@5 98.540 Error@1 25.980

==>>[2021-04-15 18:40:44] [Epoch=005/540] [Need: 00:00:00] [learning_rate=0.044604] [Best : Accuracy=74.02, Error=25.98]
  Epoch: [005][000/500]   Time 0.271 (0.271)   Data 0.153 (0.153)   Loss 0.6927 (0.6927)   Prec@1 76.000 (76.000)   Prec@5 99.000 (99.000)   [2021-04-15 18:40:44]
  Epoch: [005][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.5249 (0.6668)   Prec@1 82.000 (77.149)   Prec@5 100.000 (98.498)   [2021-04-15 18:41:20]
  Epoch: [005][400/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.7002 (0.6525)   Prec@1 81.000 (77.708)   Prec@5 98.000 (98.636)   [2021-04-15 18:41:56]
  **Train** Prec@1 77.836 Prec@5 98.676 Error@1 22.164
  **Test** Prec@1 79.420 Prec@5 99.080 Error@1 20.580
