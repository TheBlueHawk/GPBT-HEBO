{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 3 following cells aim at simuling the behavior of NN models with a simple model for MNIST\n",
    "\n",
    "EPOCH_SIZE = 512*32\n",
    "TEST_SIZE = 256*32\n",
    "\n",
    "#This is a function that can be used by several NN model\n",
    "def train(model, optimizer ,func ,train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    #for (data, target) in train_loader:\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "           # print(\"hehe\")\n",
    "            return\n",
    "        # We set this just for the example to run quickly.\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#This is a function that can be used by several NN model (it only does accuracy ATM)\n",
    "def test(model, func, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "                \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-25623bad8c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# __INCEPTION_SCORE_begin__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m     73\u001b[0m     \u001b[0mLeNet\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mMNist\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minception_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# A random mnist from the internet to get a correct model to reason about\n",
    "\n",
    "class train_mnist():\n",
    "    def __init__(self,config):\n",
    "        \n",
    "        self.config = {\n",
    "         \"weight_decay\": .017\n",
    "       , \"sigmoid_func\": 1\n",
    "      ,  \"hidden_dim\":43\n",
    "      ,  \"n_layer\":2\n",
    "      ,  \"droupout_prob\":0.28     \n",
    "    }\n",
    "        for key, value in config.items():\n",
    "            self.config[key] = value\n",
    "        config = self.config\n",
    "        \n",
    "        self.i = 0\n",
    "        \n",
    "        mnist_transforms = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "            batch_size=64,\n",
    "            shuffle=True)\n",
    "        self.test_loader = DataLoader(\n",
    "            datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "            batch_size=64,\n",
    "            shuffle=True)\n",
    "\n",
    "        sigmoid_func_uniq = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.model = LeNet(192,int(round(config.get(\"hidden_dim\",64))),10,\n",
    "                    int( round(config.get(\"n_layer\",1))),\n",
    "                    config.get(\"droupout_prob\",0.1) ,sigmoid_func_uniq)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \n",
    "                                     betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\n",
    "                                    eps=config.get(\"eps\", 1e-08), \n",
    "                                     weight_decay=config.get(\"weight_decay\", 0), \n",
    "                                     amsgrad=True)\n",
    "\n",
    "    \n",
    "    def adapt(self, config):\n",
    "        for key, value in config.items():\n",
    "            self.config[key] = value\n",
    "        config = self.config\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \n",
    "                                     betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\n",
    "                                    eps=config.get(\"eps\", 1e-08), \n",
    "                                     weight_decay=config.get(\"weight_decay\", 0), \n",
    "                                     amsgrad=True)\n",
    "        return copy.deepcopy(self)\n",
    "    \n",
    "    \n",
    "# All NN models should have a function train1 and test1 that calls the common train and test defined above.\n",
    "# train1 and test1 is then used in the scheduler\n",
    "    def train1(self):\n",
    "        print(\"iteration: \" + str(self.i) )\n",
    "        self.i+=1\n",
    "        train(self.model, self.optimizer, F.nll_loss, self.train_loader)\n",
    "\n",
    "    def test1(self):\n",
    "        return test(self.model, F.nll_loss, self.test_loader)\n",
    "\n",
    "# This should be a hyperspace instead of constants.\n",
    "\n",
    "# __INCEPTION_SCORE_begin__\n",
    "class LeNet(nn.Module):\n",
    "    \"\"\"\n",
    "    LeNet for MNist classification, used for inception_score\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_dim, hidden_dim, output_dim, n_layers,\n",
    "                 drop_prob, sigmoid ):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# Convolution Neural network using Pytorch \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,input_dim, hidden_dim, output_dim, n_layers,\n",
    "                 drop_prob, sigmoid ):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.sigmoid = sigmoid\n",
    "        self.i_d = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.first= nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden = [nn.Linear(hidden_dim,hidden_dim) for _ in range(self.n_layers)]\n",
    "        self.drop_out = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.last = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, self.i_d)\n",
    "        x=self.first(x)\n",
    "        x=self.drop_out(x)\n",
    "        for i in range(self.n_layers):\n",
    "            x=self.hidden[i](x)\n",
    "            x=self.drop_out(x)\n",
    "        x = self.last(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_linear_reg = {\n",
    "    \"lr\": 0.031,\n",
    "    \"l2_regularization\": .01,\n",
    "    \"minibatch_size\": 512,\n",
    "    \"hidden_dims\": [150, 100, 75],\n",
    "    \"droupout_prob\": 0.28,\n",
    "    \"weight_decay\": .017,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "class LinearReg(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(LinearReg, self).__init__()\n",
    "\n",
    "        hidden_dims = config.get(\"hidden_dims\", [150, 100, 75])\n",
    "        self.linears = nn.ModuleList([nn.Linear(28*28, hidden_dims[0], bias=True), nn.ReLU()])\n",
    "        for i in range(1, len(hidden_dims) ):\n",
    "            self.linears.append(nn.Linear(hidden_dims[i-1], hidden_dims[i], bias=True))\n",
    "            self.linears.append(nn.ReLU())\n",
    "        self.model = Net(self.linears) \n",
    "\n",
    "        mnist_transforms = transforms.Compose([transforms.ToTensor(), \\\n",
    "                                               transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "        self.train_loader = DataLoader(datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\\\n",
    "                                       batch_size=config.get(\"batch_size\", 64), shuffle=True)\n",
    "\n",
    "        self.test_loader = DataLoader(datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\\\n",
    "                                      batch_size=config.get(\"batch_size\", 64), shuffle=True)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \n",
    "                                     betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\n",
    "                                    eps=config.get(\"eps\", 1e-08), \n",
    "                                     weight_decay=config.get(\"weight_decay\", 0), \n",
    "                                     amsgrad=True)\n",
    "    def adapt(self, config):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \\\n",
    "                                          betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\\\n",
    "                                          eps=config.get(\"eps\", 1e-08), weight_decay=config.get(\"weight_decay\", 0), \\\n",
    "                                          amsgrad=True)\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.linears):\n",
    "            x = l(x)\n",
    "        return x     \n",
    "    \n",
    "    def train1(self):\n",
    "        train(self.model, self.optimizer, F.nll_loss, self.train_loader)\n",
    "\n",
    "    def test1(self):\n",
    "        return test(self.model, F.nll_loss, self.test_loader)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self,linears):\n",
    "        super(Net, self).__init__()\n",
    "        self.linears = linears\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.linears):\n",
    "            x = layer(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 0.031,\n",
    "    \"l2_regularization\": .01,\n",
    "    \"minibatch_size\": 512,\n",
    "    \"hidden_dims\": [150, 100, 75],\n",
    "    \"droupout_prob\": 0.28,\n",
    "    \"weight_decay\": .017,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "a = LinearReg(config)\n",
    "a.train1()\n",
    "print(a.test1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random mnist from the internet to get a correct model to reason about\n",
    "\n",
    "class toy():\n",
    "    def __init__(self,config):\n",
    "        self.hyperparameter = config.get(\"lr\",0)\n",
    "    \n",
    "    def adapt(self,config):\n",
    "        self.hyperparameter = config.get(\"lr\",0)\n",
    "        return self\n",
    "    \n",
    "    def train1(self):\n",
    "        self.hyperparameter = self.hyperparameter * 2 \n",
    "    def test1(self):\n",
    "        return self.hyperparameter\n",
    "\n",
    "# This should be a hyperspace instead of constants.\n",
    "config= {\n",
    "     \"lr\": 0.031\n",
    "}\n",
    "a = train_mnist(config)\n",
    "a.train1()\n",
    "print(a.test1())\n",
    "\n",
    "class Parent():\n",
    "    def __init__(self,hyperspace,configuration, model, loss):\n",
    "        \n",
    "        self.hyperspace = hyperspace\n",
    "        self.configuration_list = np.array(configuration) \n",
    "        self.loss_list = [np.array(loss)] \n",
    "        self.model = model\n",
    "    \n",
    "    def update(self,configuration,loss, model):\n",
    "        self.configuration_list = np.append(self.configuration_list,configuration) \n",
    "        self.loss_list = np.append(self.loss_list,loss)\n",
    "        self.model = model\n",
    "    \n",
    "    def get_hyperspace(self):\n",
    "        return self.hyperspace\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.train1()\n",
    "print(a.test1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.train1()\n",
    "print(a.test1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-91b6af7502f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mITERATIONS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m config= {\n\u001b[0;32m---> 87\u001b[0;31m      \u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     89\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Scheduler():\n",
    "    def __init__(self, model, num_iteration, num_config,\n",
    "                 oracle):\n",
    "        #Oracle manages the Bayesian optimization\n",
    "        self.oracle = oracle\n",
    "        self.iteration = num_iteration\n",
    "        self.num_config = num_config \n",
    "        self.sqrt_config = math.ceil(num_config/10) #math.floor(math.sqrt(num_config))\n",
    "        \n",
    "        #self.h is for the m \"h\" used at every loop, h is a configuration from the search space\n",
    "        self.h = np.repeat({},num_config) \n",
    "        \n",
    "        #self.out is for storing the result of the algorithm, ie all \"h\" from all iterations\n",
    "        #from all sqrt(m) best models per iterations.\n",
    "        self.out = np.zeros((num_iteration,self.sqrt_config))\n",
    "        \n",
    "        #self.hyperspaces is for storing the sqrt(m) hyperspaces used by the algorithm\n",
    "        self.hyperspaces = np.zeros(self.sqrt_config)\n",
    "        \n",
    "\n",
    "        \n",
    "        #self.model is the m model that will explore new hyperspace points at every iterations\n",
    "        self.models = np.repeat(model,num_config)\n",
    "        \n",
    "        #self.parents is the sqrt(m) best model from last iteration\n",
    "        self.parents = np.repeat(model,self.sqrt_config)\n",
    "\n",
    "        #self.losses remembers the performances of all m models at one iteration to decide which ones are the sqrt(m) best from self.models.\n",
    "        self.losses = np.zeros(num_config)\n",
    "        \n",
    "        self.k = [0] # c'est pour avoir un pointeur sur k, c'est pas paralélisable pour le moment du coup.\n",
    "    \n",
    "    def initialisation(self):\n",
    "        num_config = self.num_config\n",
    "        extended_Hyperspace = Trials()\n",
    "        #for k in range(num_config):\n",
    "        fmin_objective = partial(test_function, models=self.models,h=self.h,losses=self.losses,parent_model=self.models, k_f = self.k,iteration = 0)\n",
    "        self.oracle.compute_Batch(extended_Hyperspace ,num_config , 0 ,fmin_objective)\n",
    "            \n",
    "        indexes = np.argsort(self.losses)     \n",
    "        self.out[0] = (self.losses[indexes])[0:self.sqrt_config]\n",
    "        self.hyperspaces = np.repeat(extended_Hyperspace,self.sqrt_config)    \n",
    "        self.parents = np.array([Parent(copy.deepcopy(extended_Hyperspace),(self.h[indexes])[i], (self.models[indexes])[i],(self.losses[indexes])[i])  \n",
    "                                 for i in range(self.sqrt_config) ])         \n",
    "        \n",
    "    def loop(self):\n",
    "        sqrt_config = self.sqrt_config\n",
    "        iteration = self.iteration\n",
    "        for i in range(1,iteration):\n",
    "            for j in range(sqrt_config):\n",
    "                k = j*sqrt_config\n",
    "                parent = self.parents[j]\n",
    "                extended_Hyperspace = parent.get_hyperspace()\n",
    "                print(\"\\n loss of parent \" + str(parent.get_loss()[-1]) )\n",
    "                print(\"\\n loss \" + str(parent.get_loss()))\n",
    "\n",
    "                \n",
    "                for l in range(int(self.num_config/sqrt_config)):\n",
    "                    fmin_objective = partial(test_function, models=self.models,h=self.h,losses=self.losses,parent_model=parent.get_model(), k_f = k,iteration = i)\n",
    "                    self.oracle.compute_Once(extended_Hyperspace ,i ,fmin_objective)\n",
    "                    k = k+1\n",
    "                \n",
    "            indexes = np.argsort(self.losses)     \n",
    "            #parent_idx = np.floor(indexes/sqrt_config)[:sqrt_config]\n",
    "            parent_idx = indexes[:sqrt_config]\n",
    "            print(self.losses)\n",
    "            print(indexes)\n",
    "            #print(parent_idx)\n",
    " \n",
    "            temp = np.empty(self.sqrt_config, dtype=Parent)\n",
    "            for a,x in enumerate(parent_idx):\n",
    "                x = int(x)\n",
    "                temp[a] = copy.deepcopy(self.parents[math.floor(x/self.num_config*sqrt_config)])\n",
    "                temp[a].update(self.h[x], self.losses[x], self.models[x])\n",
    "            self.parents = temp\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "CONFIGURATION = 10\n",
    "ITERATIONS = 4\n",
    "config= {\n",
    "     \"lr\": hp.uniform(\"lr\",0,1)\n",
    "}\n",
    "model = train_mnist\n",
    "oracle = Oracle(config)\n",
    "scheduler = Scheduler(\n",
    "    model,\n",
    "    ITERATIONS,\n",
    "    CONFIGURATION,\n",
    "    oracle) \n",
    "\n",
    "scheduler.initialisation()     \n",
    "scheduler.loop()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "# Oracle (Paul) TODO\n",
    "class Oracle():\n",
    "    def __init__(self, searchspace ):\n",
    "        #self.hyperspace is the original (input) searchspace\n",
    "        self.searchspace = searchspace\n",
    "\n",
    "    def compute_Once(self,trials, iteration,function): #add space\n",
    "        space = copy.deepcopy(self.searchspace)\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+1, trials=trials)\n",
    "        \n",
    "        \n",
    "    def compute_Batch(self,trials, nb_eval, iteration,function): #add space\n",
    "        space = copy.deepcopy(self.searchspace)\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "            \n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+nb_eval, trials=trials)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x,models,h,losses, parent_model,k_f,iteration):\n",
    "    if iteration == 0:\n",
    "        k = k_f[0]\n",
    "        models[k] = parent_model[k](x)\n",
    "        k_f[0] += 1\n",
    "\n",
    "    else:      \n",
    "        k = k_f\n",
    "        models[k] = parent_model.adapt(x)\n",
    "    print(\"\\n lr, \" + str(x[\"lr\"]))\n",
    "    h[k] = x\n",
    "    models[k].train1()\n",
    "    loss = models[k].test1()\n",
    "    losses[k] = -loss\n",
    "    print(\"accuracy, \" + str(loss))\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal Bayes Opt\n",
    "\n",
    "def function(x):\n",
    "    print(x)\n",
    "    model = train_mnist(x)\n",
    "    for _ in range(4):\n",
    "            model.train1()\n",
    "    loss = model.test1()\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesOpt():\n",
    "    def __init__(self, searchspace ):\n",
    "        self.searchspace = searchspace\n",
    "\n",
    "    def compute_Once(self,function): \n",
    "        fmin(function, self.searchspace, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=9, trials=Trials())\n",
    "    \n",
    "config= {\n",
    "     \"lr\": hp.uniform(\"lr\",0,1)\n",
    "}\n",
    "oracle = BayesOpt(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oracle.compute_Once(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN THIS MODULE: IMPORTS, CNN, TRAIN, TEST, MNIS_FUNCTION, SPACE\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from ray import tune\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "import time\n",
    "import ray\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "import argparse\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.nevergrad import NevergradSearch\n",
    "import nevergrad as ng\n",
    "import json\n",
    "import os\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.dragonfly import DragonflySearch\n",
    "from ray.tune.suggest.zoopt import ZOOptSearch\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from zoopt import ValueType\n",
    "import torch\n",
    "# IN THIS MODULE: IMPORTS, CNN, TRAIN, TEST, MNIS_FUNCTION, SPACE\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler \n",
    "from ray.tune.schedulers import MedianStoppingRule\n",
    "\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from ray import tune\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "import time\n",
    "import ray\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "import argparse\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.nevergrad import NevergradSearch\n",
    "import nevergrad as ng\n",
    "import json\n",
    "import os\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "#from ray.tune.suggest.dragonfly import DragonflySearch\n",
    "from ray.tune.suggest.zoopt import ZOOptSearch\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from zoopt import ValueType\n",
    "import torch\n",
    "import adabelief_pytorch\n",
    "global_checkpoint_period=np.inf\n",
    "\n",
    "def GAN_MNIST(SA):\n",
    "    import ray\n",
    "\n",
    "    import os\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.parallel\n",
    "    import torch.utils.data\n",
    "    import torchvision.datasets as dset\n",
    "    import torchvision.transforms as transforms\n",
    "    import torchvision.utils as vutils\n",
    "    import numpy as np\n",
    "\n",
    "    import ray\n",
    "    from ray import tune\n",
    "    from ray.tune.trial import ExportFormat\n",
    "    from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "    import argparse\n",
    "    import os\n",
    "    from filelock import FileLock\n",
    "    import random\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.parallel\n",
    "    import torch.optim as optim\n",
    "    import torch.utils.data\n",
    "    import numpy as np\n",
    "    from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "    from ray.tune.suggest.ax import AxSearch\n",
    "\n",
    "\n",
    "\n",
    "    from torch.autograd import Variable\n",
    "    from torch.nn import functional as F\n",
    "    from scipy.stats import entropy\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    # Training parameters\n",
    "    dataroot = ray.utils.get_user_temp_dir() + os.sep\n",
    "    workers = 2\n",
    "    batch_size = 64\n",
    "    image_size = 32\n",
    "\n",
    "    # Number of channels in the training images. For color images this is 3\n",
    "    nc = 1\n",
    "\n",
    "    # Size of z latent vector (i.e. size of generator input)\n",
    "    nz = 100\n",
    "\n",
    "    # Size of feature maps in generator\n",
    "    ngf = 32\n",
    "\n",
    "    # Size of feature maps in discriminator\n",
    "    ndf = 32\n",
    "\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "\n",
    "    # iterations of actual training in each Trainable _train\n",
    "    train_iterations_per_step = 5\n",
    "\n",
    "    MODEL_PATH = os.path.expanduser(\"~/.ray/models/mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "    def get_data_loader():\n",
    "        dataset = dset.MNIST(\n",
    "            root=dataroot,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, ), (0.5, )),\n",
    "            ]))\n",
    "\n",
    "        # Create the dataloader\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "\n",
    "    # __GANmodel_begin__\n",
    "    # custom weights initialization called on netG and netD\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find(\"Conv\") != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find(\"BatchNorm\") != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "    # Generator Code\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Generator, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh())\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.main(input)\n",
    "\n",
    "\n",
    "    class Discriminator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Discriminator, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ndf * 2), nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ndf * 4), nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.main(input)\n",
    "\n",
    "\n",
    "    # __GANmodel_end__\n",
    "\n",
    "\n",
    "    # __INCEPTION_SCORE_begin__\n",
    "    class Net(nn.Module):\n",
    "        \"\"\"\n",
    "        LeNet for MNist classification, used for inception_score\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "            self.conv2_drop = nn.Dropout2d()\n",
    "            self.fc1 = nn.Linear(320, 50)\n",
    "            self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "            x = x.view(-1, 320)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "    def inception_score(imgs, mnist_model_ref, batch_size=32, splits=1):\n",
    "        N = len(imgs)\n",
    "        dtype = torch.FloatTensor\n",
    "        dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "        cm = ray.get(mnist_model_ref)  # Get the mnist model from Ray object store.\n",
    "        up = nn.Upsample(size=(28, 28), mode=\"bilinear\").type(dtype)\n",
    "\n",
    "        def get_pred(x):\n",
    "            x = up(x)\n",
    "            x = cm(x)\n",
    "            return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "        preds = np.zeros((N, 10))\n",
    "        for i, batch in enumerate(dataloader, 0):\n",
    "            batch = batch.type(dtype)\n",
    "            batchv = Variable(batch)\n",
    "            batch_size_i = batch.size()[0]\n",
    "            preds[i * batch_size:i * batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "        # Now compute the mean kl-div\n",
    "        split_scores = []\n",
    "        for k in range(splits):\n",
    "            part = preds[k * (N // splits):(k + 1) * (N // splits), :]\n",
    "            py = np.mean(part, axis=0)\n",
    "            scores = []\n",
    "            for i in range(part.shape[0]):\n",
    "                pyx = part[i, :]\n",
    "                scores.append(entropy(pyx, py))\n",
    "            split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "        return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "\n",
    "    # __INCEPTION_SCORE_end__\n",
    "\n",
    "\n",
    "    def train(netD, netG, optimG, optimD, criterion, dataloader, iteration, device,\n",
    "              mnist_model_ref):\n",
    "        real_label = 1\n",
    "        fake_label = 0\n",
    "\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            if i >= train_iterations_per_step:\n",
    "                break\n",
    "\n",
    "            netD.zero_grad()\n",
    "            real_cpu = data[0].to(device)\n",
    "            b_size = real_cpu.size(0)\n",
    "            label = torch.full(\n",
    "                (b_size, ), real_label, dtype=torch.float, device=device)\n",
    "            output = netD(real_cpu).view(-1)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake = netG(noise)\n",
    "            label.fill_(fake_label)\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimD.step()\n",
    "\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)\n",
    "            output = netD(fake).view(-1)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimG.step()\n",
    "\n",
    "            is_score, is_std = inception_score(fake, mnist_model_ref)\n",
    "\n",
    "            # Output training stats\n",
    "           # if iteration % 10 == 0:\n",
    "            #    print(\"[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z))\"\n",
    "             #         \": %.4f / %.4f \\tInception score: %.4f\" %\n",
    "              #        (iteration, len(dataloader), errD.item(), errG.item(), D_x,\n",
    "               #        D_G_z1, D_G_z2, is_score))\n",
    "\n",
    "        return errG.item(), errD.item(), is_score\n",
    "\n",
    "\n",
    "    def plot_images(dataloader):\n",
    "        # Plot some training images\n",
    "        if 1==0:\n",
    "            real_batch = next(iter(dataloader))\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Original Images\")\n",
    "            plt.imshow(\n",
    "                np.transpose(\n",
    "                    vutils.make_grid(real_batch[0][:64], padding=2,\n",
    "                                     normalize=True).cpu(), (1, 2, 0)))\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def demo_gan(checkpoint_paths):\n",
    "        img_list = []\n",
    "        fixed_noise = torch.randn(64, nz, 1, 1)\n",
    "        for netG_path in checkpoint_paths:\n",
    "            loadedG = Generator()\n",
    "            loadedG.load_state_dict(torch.load(netG_path)[\"netGmodel\"])\n",
    "            with torch.no_grad():\n",
    "                fake = loadedG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"off\")\n",
    "        ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)]\n",
    "               for i in img_list]\n",
    "        ani = animation.ArtistAnimation(\n",
    "            fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "        ani.save(\"./generated\" +str(SA)+\"best.gif\", writer=\"imagemagick\", dpi=72)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # __Trainable_begin__\n",
    "    class PytorchTrainable(tune.Trainable):\n",
    "        def setup(self, config):\n",
    "            use_cuda = config.get(\"use_gpu\") and torch.cuda.is_available()\n",
    "            self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "            self.netD = Discriminator().to(self.device)\n",
    "            self.netD.apply(weights_init)\n",
    "            self.netG = Generator().to(self.device)\n",
    "            self.netG.apply(weights_init)\n",
    "            self.criterion = nn.BCELoss()    \n",
    "            self.optimizerD =optim.Adam(\n",
    "            self.netD.parameters(),\n",
    "            lr=10**-(config[\"netD_lr\"]),\n",
    "            betas=(10**-(config[\"netD_B\"]), 0.999),\n",
    "            weight_decay=10**-(config[\"weight_decay1\"]))\n",
    "                              \n",
    "            self.optimizerG =optim.Adam(\n",
    "            self.netG.parameters(),\n",
    "            lr=10**-(config[\"netG_lr\"]),\n",
    "            betas=(10**-(config[\"netG_B\"]), 0.999),\n",
    "            weight_decay=10**-(config[\"weight_decay2\"]))\n",
    "\n",
    "\n",
    "            with FileLock(os.path.expanduser(\"~/.data.lock\")):\n",
    "                self.dataloader = get_data_loader()\n",
    "            self.mnist_model_ref = c[\"mnist_model_ref\"]\n",
    "\n",
    "        def step(self):\n",
    "            lossG, lossD, is_score = train(self.netD, self.netG, self.optimizerG,\n",
    "                                           self.optimizerD, self.criterion,\n",
    "                                           self.dataloader, self._iteration,\n",
    "                                           self.device, self.mnist_model_ref)\n",
    "            return {\"lossg\": lossG, \"lossd\": lossD, \"is_score\": is_score}\n",
    "\n",
    "        def save_checkpoint(self, checkpoint_dir):\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save({\n",
    "                \"netDmodel\": self.netD.state_dict(),\n",
    "                \"netGmodel\": self.netG.state_dict(),\n",
    "                \"optimD\": self.optimizerD.state_dict(),\n",
    "                \"optimG\": self.optimizerG.state_dict(),\n",
    "            }, path)\n",
    "\n",
    "            return checkpoint_dir\n",
    "\n",
    "        def load_checkpoint(self, checkpoint_dir):\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            checkpoint = torch.load(path)\n",
    "            self.netD.load_state_dict(checkpoint[\"netDmodel\"])\n",
    "            self.netG.load_state_dict(checkpoint[\"netGmodel\"])\n",
    "            self.optimizerD.load_state_dict(checkpoint[\"optimD\"])\n",
    "            self.optimizerG.load_state_dict(checkpoint[\"optimG\"])\n",
    "\n",
    "        def reset_config(self, new_config):\n",
    "            if \"netD_lr\" in new_config:\n",
    "                for param_group in self.optimizerD.param_groups:\n",
    "                    param_group[\"lr\"] = 10**-(new_config[\"netD_lr\"])\n",
    "            if \"netG_lr\" in new_config:\n",
    "                for param_group in self.optimizerG.param_groups:\n",
    "                    param_group[\"lr\"] = 10**-(new_config[\"netG_lr\"])\n",
    "            if \"netD_B\" in new_config:\n",
    "                for param_group in self.optimizerD.param_groups:\n",
    "                    param_group[\"betas\"] = (1 - 10**-(new_config[\"netD_B\"]),0.999)\n",
    "            if \"netG_B\" in new_config:\n",
    "                for param_group in self.optimizerG.param_groups:\n",
    "                    param_group[\"betas\"] = (1 - 10**-(new_config[\"netG_B\"]),0.999)\n",
    "            if \"weight_decay1\" in new_config:\n",
    "                for param_group in self.optimizerD.param_groups:\n",
    "                    param_group[\"weight_decay\"] = 10**-(new_config[\"weight_decay1\"])\n",
    "            if \"weight_decay2\" in new_config:\n",
    "                for param_group in self.optimizerG.param_groups:\n",
    "                    param_group[\"weight_decay\"] = 10**-(new_config[\"weight_decay2\"])\n",
    "            self.config = new_config\n",
    "            return True\n",
    "\n",
    "        def _export_model(self, export_formats, export_dir):\n",
    "            if export_formats == [ExportFormat.MODEL]:\n",
    "                path = os.path.join(export_dir, \"exported_models\")\n",
    "                torch.save({\n",
    "                    \"netDmodel\": self.netD.state_dict(),\n",
    "                    \"netGmodel\": self.netG.state_dict()\n",
    "                }, path)\n",
    "                return {ExportFormat.MODEL: path}\n",
    "            else:\n",
    "                raise ValueError(\"unexpected formats: \" + str(export_formats))\n",
    "\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    import urllib.request\n",
    "    # Download a pre-trained MNIST model for inception score calculation.\n",
    "    # This is a tiny model (<100kb).\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(\"downloading model\")\n",
    "        os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "        urllib.request.urlretrieve(\n",
    "            \"https://github.com/ray-project/ray/raw/master/python/ray/tune/\"\n",
    "            \"examples/pbt_dcgan_mnist/mnist_cnn.pt\", MODEL_PATH)\n",
    "\n",
    "    dataloader = get_data_loader()\n",
    "    if not args.smoke_test:\n",
    "        plot_images(dataloader)\n",
    "\n",
    "    # load the pretrained mnist classification model for inception_score\n",
    "    mnist_cnn = Net()\n",
    "    mnist_cnn.load_state_dict(torch.load(MODEL_PATH))\n",
    "    mnist_cnn.eval()\n",
    "    mnist_model_ref = ray.put(mnist_cnn)\n",
    "\n",
    "    # __tune_begin__\n",
    "    scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        perturbation_interval=5,\n",
    "        hyperparam_mutations={\n",
    "            # distribution for resampling\n",
    "            \"netG_lr\": lambda: np.random.uniform(1, 9),\n",
    "            \"netD_lr\": lambda: np.random.uniform(1, 9),\n",
    "            \"netD_B\": lambda: np.random.uniform(0, 2),\n",
    "            \"netD_B\": lambda: np.random.uniform(0, 2),\n",
    "            \"weight_decay1\":lambda: np.random.uniform(3, 8),\n",
    "            \"weight_decay2\":lambda: np.random.uniform(3, 8)\n",
    "        })\n",
    "    from ray.tune.schedulers.pb2 import PB2\n",
    "\n",
    "    scheduler = PB2(\n",
    "    time_attr=\"training_iteration\",\n",
    "    perturbation_interval=3,\n",
    "    hyperparam_bounds={\n",
    "        # distribution for resampling\n",
    "            \"netG_lr\": [1, 9],\n",
    "            \"netD_lr\": [1, 9],\n",
    "            \"netD_B\": [0, 2],\n",
    "            \"netD_B\": [0, 2],\n",
    "            \"weight_decay1\":[3, 8],\n",
    "            \"weight_decay2\":[3, 8]\n",
    "    }) \n",
    "    \n",
    "    c={\"mnist_model_ref\" : mnist_model_ref}\n",
    "\n",
    "\n",
    "    experiment_metrics= dict(metric=\"is_score\",\n",
    "        mode=\"max\")\n",
    "\n",
    " \n",
    "    \n",
    "    if(SA==0):\n",
    "        algo = HyperOptSearch(**experiment_metrics)\n",
    "        name=\"hypher\"\n",
    "\n",
    "    if(SA==1):\n",
    "        algo =   BayesOptSearch(**experiment_metrics) \n",
    "        name=\"Bayes\"\n",
    "        \n",
    "    if(SA==2):\n",
    "        algo = AxSearch(\n",
    "            max_concurrent=2, #was working with 2\n",
    "            **experiment_metrics\n",
    "        )\n",
    "        name=\"AX\"\n",
    "\n",
    "        \n",
    "        \n",
    "    if(SA==3):\n",
    "        algo = NevergradSearch(\n",
    "            optimizer=ng.optimizers.CMA,**experiment_metrics\n",
    "            # space=space,  # If you want to set the space manually\n",
    "            )\n",
    "        algo = ConcurrencyLimiter(algo, max_concurrent=8)\n",
    "        name=\"NG\"\n",
    "\n",
    "        \n",
    "     \n",
    "    if(SA==4):\n",
    "        algo = NevergradSearch(\n",
    "            optimizer=ng.optimizers.TwoPointsDE,**experiment_metrics\n",
    "            # space=space,  # If you want to set the space manually\n",
    "            )\n",
    "        algo = ConcurrencyLimiter(algo, max_concurrent=8)\n",
    "        name=\"NG2DE\"\n",
    "\n",
    "        \n",
    "        \n",
    "    if(SA==5):\n",
    "        algo = NevergradSearch(\n",
    "        optimizer=ng.optimizers.RandomSearch,**experiment_metrics\n",
    "        # space=space,  # If you want to set the space manually\n",
    "        )\n",
    "        algo = ConcurrencyLimiter(algo, max_concurrent=8)\n",
    "        name=\"random\"\n",
    "                \n",
    "    if(SA==6):\n",
    "        dim_dict = {\n",
    "        \"netG_lr\": (ValueType.CONTINUOUS, [0, 0.1], 1e-2),\n",
    "        \"netD_lr\": (ValueType.CONTINUOUS, [0, 0.1], 1e-2)\n",
    "        }\n",
    "        algo = ZOOptSearch(\n",
    "        algo=\"Asracos\",  # only support Asracos currently\n",
    "        #dim_dict=dim_dict,\n",
    "      #  dim_dict=dim_dict,\n",
    "\n",
    "        budget=100,\n",
    "            **experiment_metrics\n",
    "        #dim_dict=dim_dict,\n",
    "       #     **zoopt_search_config,\n",
    "        )\n",
    "        name=\"zoo\"\n",
    "\n",
    "\n",
    "  #  if(SA!=4):\n",
    "    #scheduler = MedianStoppingRule()\n",
    "    #AsyncHyperBandScheduler()\n",
    "        \n",
    "        \n",
    "    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "\n",
    "    tune_kwargs = {\n",
    "    \"num_samples\": 20 if args.smoke_test else 20,\n",
    "      \"stop\":{\n",
    "            \"training_iteration\": 100,\n",
    "        },  \n",
    "\n",
    "    \"config\": {\n",
    "     \"lr1\":  tune.uniform(2, 5) #tune.uniform(1e-4, 0.1 ),#,1e-4), #*10\n",
    "    , \"lr2\":  tune.uniform(2, 5) #tune.uniform(1e-4, 0.1 ),#,1e-4), #*10\n",
    "    ,     \"weight_decay1\":tune.uniform(3, 8)#tune.uniform(1, 5)#,1e-4), #*10 et 0\n",
    "    ,     \"weight_decay2\":tune.uniform(3, 8)#tune.uniform(1, 5)#,1e-4), #*10 et 0    \n",
    "    ,     \"beta1\":2 #tune.uniform(1, 5),#,1e-4), #*10 et 0\n",
    "     ,    \"beta2\":1 #tune.uniform(1, 5),#,1e-4), #*10 et 0\n",
    "      ,  \"adam1\":0#tune.uniform(0,1),\n",
    "      ,  \"adam2\":0#tune.uniform(0,1),\n",
    "        }\n",
    "    }\n",
    "    def trial_name_id(trial):\n",
    "        return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "    analysis = tune.run(\n",
    "    PytorchTrainable,\n",
    "    name=name,\n",
    "    scheduler=scheduler,\n",
    "    reuse_actors=True,\n",
    "    search_alg=algo,\n",
    "    verbose=2,\n",
    "    checkpoint_at_end=True,\n",
    "    num_samples=16,\n",
    "   # export_formats=[ExportFormat.MODEL],\n",
    "        config =     {\n",
    "            \"netG_lr\": tune.uniform(1, 9),\n",
    "           \"netD_lr\": tune.uniform(1, 9),\n",
    "            \"netG_B\": tune.uniform(0, 3),\n",
    "           \"netD_B\": tune.uniform(0, 3),\n",
    "            \"weight_decay1\":tune.uniform(3, 8)#tune.uniform(1, 5)#,1e-4), #*10 et 0\n",
    "    ,     \"weight_decay2\":tune.uniform(3, 8)\n",
    "        },      stop={\n",
    "            \"training_iteration\": 30,\n",
    "        },        metric=\"is_score\",\n",
    "        mode=\"max\"\n",
    "             ,     loggers=[TestLogger])\n",
    "\n",
    "    all_trials = analysis.trials\n",
    "    checkpoint_paths = [\n",
    "        os.path.join(analysis.get_best_checkpoint(t), \"checkpoint\")\n",
    "        for t in all_trials\n",
    "    ]\n",
    "    demo_gan(checkpoint_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:20:46,271\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.1.2.198',\n",
       " 'raylet_ip_address': '10.1.2.198',\n",
       " 'redis_address': '10.1.2.198:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-03-12_14-20-45_188076_4892/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-03-12_14-20-45_188076_4892/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-03-12_14-20-45_188076_4892',\n",
       " 'metrics_export_port': 58687,\n",
       " 'node_id': '3c1e3902a0cf0a28e93947298b5992a5fd3d89cd'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:20:48,191\tWARNING logger.py:328 -- JsonLogger not provided. The ExperimentAnalysis tool is disabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.8/15.6 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 1/16 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.255619</td><td style=\"text-align: right;\">  1.50252</td><td style=\"text-align: right;\"> 0.77397</td><td style=\"text-align: right;\">  6.03856</td><td style=\"text-align: right;\">        4.55235</td><td style=\"text-align: right;\">        5.15503</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12694)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12694)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12698)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12698)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12695)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12695)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12690)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12690)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12696)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12696)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12691)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12691)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12693)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12693)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12692)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=12692)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c25fa8bc:\n",
      "  date: 2021-03-12_14-20-53\n",
      "  done: false\n",
      "  experiment_id: e58aa7aa02d343fb8e27d9398c98cb85\n",
      "  experiment_tag: 2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.5880701541900635\n",
      "  lossg: 0.6416276693344116\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12694\n",
      "  time_since_restore: 2.5769245624542236\n",
      "  time_this_iter_s: 2.5769245624542236\n",
      "  time_total_s: 2.5769245624542236\n",
      "  timestamp: 1615555253\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c25fa8bc\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.8/15.6 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c25fa8bc with is_score=1.0000000000000004 and parameters={'netG_lr': 4.186094259772906, 'netD_lr': 5.137051705288389, 'netG_B': 0.9779715423346025, 'netD_B': 0.7654293250507191, 'weight_decay1': 7.089234038605947, 'weight_decay2': 5.10403899251541}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 8/16 (8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   lossg</th><th style=\"text-align: right;\">  lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.255619</td><td style=\"text-align: right;\">  1.50252</td><td style=\"text-align: right;\">0.77397 </td><td style=\"text-align: right;\">  6.03856</td><td style=\"text-align: right;\">        4.55235</td><td style=\"text-align: right;\">        5.15503</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>RUNNING </td><td>10.1.2.198:12694</td><td style=\"text-align: right;\">0.765429</td><td style=\"text-align: right;\">  5.13705</td><td style=\"text-align: right;\">0.977972</td><td style=\"text-align: right;\">  4.18609</td><td style=\"text-align: right;\">        7.08923</td><td style=\"text-align: right;\">        5.10404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.57692</td><td style=\"text-align: right;\">0.641628</td><td style=\"text-align: right;\">1.58807</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c2551280:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: 5fceba58135d46d297e2be2df99de920\n",
      "  experiment_tag: 1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.43830007314682007\n",
      "  lossg: 26.888717651367188\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12698\n",
      "  time_since_restore: 2.999572515487671\n",
      "  time_this_iter_s: 2.999572515487671\n",
      "  time_total_s: 2.999572515487671\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c2551280\n",
      "  \n",
      "Result for PytorchTrainable_c26d0d54:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: a0887323846e4303a33193340cc9e49d\n",
      "  experiment_tag: 6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.228205919265747\n",
      "  lossg: 0.6831161379814148\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12690\n",
      "  time_since_restore: 2.9431684017181396\n",
      "  time_this_iter_s: 2.9431684017181396\n",
      "  time_total_s: 2.9431684017181396\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c26d0d54\n",
      "  \n",
      "Result for PytorchTrainable_c270956e:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.5772579908370972\n",
      "  lossg: 0.90301513671875\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12693\n",
      "  time_since_restore: 2.823423385620117\n",
      "  time_this_iter_s: 2.823423385620117\n",
      "  time_total_s: 2.823423385620117\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c270956e\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 6.196436405181885\n",
      "  lossg: 0.004989510402083397\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 2.870432138442993\n",
      "  time_this_iter_s: 2.870432138442993\n",
      "  time_total_s: 2.870432138442993\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c27a58f6\n",
      "  \n",
      "Result for PytorchTrainable_c262ef68:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: 32420a51384348c28e420155bc0bb16d\n",
      "  experiment_tag: 3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.005562771577388048\n",
      "  lossg: 6.761663436889648\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12695\n",
      "  time_since_restore: 3.3130416870117188\n",
      "  time_this_iter_s: 3.3130416870117188\n",
      "  time_total_s: 3.3130416870117188\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c262ef68\n",
      "  \n",
      "Result for PytorchTrainable_c269dd1e:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: 6b7a539ade85478782cc3b82d5490653\n",
      "  experiment_tag: 5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 2.446737289428711\n",
      "  lossg: 0.2267647385597229\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12696\n",
      "  time_since_restore: 2.971731424331665\n",
      "  time_this_iter_s: 2.971731424331665\n",
      "  time_total_s: 2.971731424331665\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c269dd1e\n",
      "  \n",
      "Result for PytorchTrainable_c265fbd6:\n",
      "  date: 2021-03-12_14-20-54\n",
      "  done: false\n",
      "  experiment_id: 05637de727b3467d8ee28a95ca2f4e4b\n",
      "  experiment_tag: 4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.23209810256958\n",
      "  lossg: 0.7766537666320801\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12692\n",
      "  time_since_restore: 3.2964353561401367\n",
      "  time_this_iter_s: 3.2964353561401367\n",
      "  time_total_s: 3.2964353561401367\n",
      "  timestamp: 1615555254\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c265fbd6\n",
      "  \n",
      "Result for PytorchTrainable_c25fa8bc:\n",
      "  date: 2021-03-12_14-21-01\n",
      "  done: false\n",
      "  experiment_id: e58aa7aa02d343fb8e27d9398c98cb85\n",
      "  experiment_tag: 2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 1.9128391742706299\n",
      "  lossg: 0.37312451004981995\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12694\n",
      "  time_since_restore: 9.94920539855957\n",
      "  time_this_iter_s: 4.490545988082886\n",
      "  time_total_s: 9.94920539855957\n",
      "  timestamp: 1615555261\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c25fa8bc\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.038562439302529, 'netD_lr': 1.5025180752436178, 'netG_B': 0.7739697042019353, 'netD_B': 0.2556187542489788, 'weight_decay1': 4.552352301834492, 'weight_decay2': 5.155030556976821}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 8/16 (8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>10.1.2.198:12698</td><td style=\"text-align: right;\">0.255619</td><td style=\"text-align: right;\">  1.50252</td><td style=\"text-align: right;\">0.77397 </td><td style=\"text-align: right;\">  6.03856</td><td style=\"text-align: right;\">        4.55235</td><td style=\"text-align: right;\">        5.15503</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.15444</td><td style=\"text-align: right;\">30.2865    </td><td style=\"text-align: right;\">6.83378e-05</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>RUNNING </td><td>10.1.2.198:12694</td><td style=\"text-align: right;\">0.765429</td><td style=\"text-align: right;\">  5.13705</td><td style=\"text-align: right;\">0.977972</td><td style=\"text-align: right;\">  4.18609</td><td style=\"text-align: right;\">        7.08923</td><td style=\"text-align: right;\">        5.10404</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         9.94921</td><td style=\"text-align: right;\"> 0.373125  </td><td style=\"text-align: right;\">1.91284    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>10.1.2.198:12695</td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.29454</td><td style=\"text-align: right;\"> 7.32602   </td><td style=\"text-align: right;\">0.00247042 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>RUNNING </td><td>10.1.2.198:12692</td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.57071</td><td style=\"text-align: right;\"> 0.690042  </td><td style=\"text-align: right;\">1.28811    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.12836</td><td style=\"text-align: right;\"> 0.152498  </td><td style=\"text-align: right;\">2.70573    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.25715</td><td style=\"text-align: right;\"> 0.694307  </td><td style=\"text-align: right;\">1.16848    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         5.83237</td><td style=\"text-align: right;\"> 0.853749  </td><td style=\"text-align: right;\">1.58077    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         6.09432</td><td style=\"text-align: right;\"> 0.00220046</td><td style=\"text-align: right;\">6.93096    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:01,903\tINFO pbt.py:477 -- [pbt]: no checkpoint for trial. Skip exploit for Trial PytorchTrainable_c2551280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c2551280:\n",
      "  date: 2021-03-12_14-21-01\n",
      "  done: false\n",
      "  experiment_id: 5fceba58135d46d297e2be2df99de920\n",
      "  experiment_tag: 1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 3.959944297093898e-05\n",
      "  lossg: 29.42328453063965\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12698\n",
      "  time_since_restore: 10.712591171264648\n",
      "  time_this_iter_s: 4.5581488609313965\n",
      "  time_total_s: 10.712591171264648\n",
      "  timestamp: 1615555261\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c2551280\n",
      "  \n",
      "Result for PytorchTrainable_c270956e:\n",
      "  date: 2021-03-12_14-21-02\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 1.6200082302093506\n",
      "  lossg: 0.8725131750106812\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12693\n",
      "  time_since_restore: 10.610648393630981\n",
      "  time_this_iter_s: 4.778278589248657\n",
      "  time_total_s: 10.610648393630981\n",
      "  timestamp: 1615555262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c270956e\n",
      "  \n",
      "Result for PytorchTrainable_c269dd1e:\n",
      "  date: 2021-03-12_14-21-02\n",
      "  done: false\n",
      "  experiment_id: 6b7a539ade85478782cc3b82d5490653\n",
      "  experiment_tag: 5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 2.5520360469818115\n",
      "  lossg: 0.16209499537944794\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12696\n",
      "  time_since_restore: 10.74982738494873\n",
      "  time_this_iter_s: 4.621470212936401\n",
      "  time_total_s: 10.74982738494873\n",
      "  timestamp: 1615555262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c269dd1e\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-02\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 7.327963352203369\n",
      "  lossg: 0.0014959713444113731\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 10.732969284057617\n",
      "  time_this_iter_s: 4.63864541053772\n",
      "  time_total_s: 10.732969284057617\n",
      "  timestamp: 1615555262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c27a58f6\n",
      "  \n",
      "Result for PytorchTrainable_c262ef68:\n",
      "  date: 2021-03-12_14-21-02\n",
      "  done: false\n",
      "  experiment_id: 32420a51384348c28e420155bc0bb16d\n",
      "  experiment_tag: 3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 0.0015850549098104239\n",
      "  lossg: 7.563457012176514\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12695\n",
      "  time_since_restore: 11.19278597831726\n",
      "  time_this_iter_s: 4.898242712020874\n",
      "  time_total_s: 11.19278597831726\n",
      "  timestamp: 1615555262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c262ef68\n",
      "  \n",
      "Result for PytorchTrainable_c26d0d54:\n",
      "  date: 2021-03-12_14-21-02\n",
      "  done: false\n",
      "  experiment_id: a0887323846e4303a33193340cc9e49d\n",
      "  experiment_tag: 6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 1.0530576705932617\n",
      "  lossg: 0.7418572306632996\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12690\n",
      "  time_since_restore: 11.19967246055603\n",
      "  time_this_iter_s: 4.942521333694458\n",
      "  time_total_s: 11.19967246055603\n",
      "  timestamp: 1615555262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c26d0d54\n",
      "  \n",
      "Result for PytorchTrainable_c265fbd6:\n",
      "  date: 2021-03-12_14-21-02\n",
      "  done: false\n",
      "  experiment_id: 05637de727b3467d8ee28a95ca2f4e4b\n",
      "  experiment_tag: 4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 1.259470820426941\n",
      "  lossg: 0.7763816714286804\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12692\n",
      "  time_since_restore: 11.182160377502441\n",
      "  time_this_iter_s: 4.611447811126709\n",
      "  time_total_s: 11.182160377502441\n",
      "  timestamp: 1615555262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c265fbd6\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.038562439302529, 'netD_lr': 1.5025180752436178, 'netG_B': 0.7739697042019353, 'netD_B': 0.2556187542489788, 'weight_decay1': 4.552352301834492, 'weight_decay2': 5.155030556976821}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 8/16 (8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>10.1.2.198:12698</td><td style=\"text-align: right;\">0.255619</td><td style=\"text-align: right;\">  1.50252</td><td style=\"text-align: right;\">0.77397 </td><td style=\"text-align: right;\">  6.03856</td><td style=\"text-align: right;\">        4.55235</td><td style=\"text-align: right;\">        5.15503</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.0922</td><td style=\"text-align: right;\">29.7904    </td><td style=\"text-align: right;\">0.00261086</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>RUNNING </td><td>10.1.2.198:12694</td><td style=\"text-align: right;\">0.765429</td><td style=\"text-align: right;\">  5.13705</td><td style=\"text-align: right;\">0.977972</td><td style=\"text-align: right;\">  4.18609</td><td style=\"text-align: right;\">        7.08923</td><td style=\"text-align: right;\">        5.10404</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         14.3062</td><td style=\"text-align: right;\"> 0.340361  </td><td style=\"text-align: right;\">1.95337   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>10.1.2.198:12695</td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         11.1928</td><td style=\"text-align: right;\"> 7.56346   </td><td style=\"text-align: right;\">0.00158505</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>RUNNING </td><td>10.1.2.198:12692</td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         11.1822</td><td style=\"text-align: right;\"> 0.776382  </td><td style=\"text-align: right;\">1.25947   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         10.7498</td><td style=\"text-align: right;\"> 0.162095  </td><td style=\"text-align: right;\">2.55204   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         11.1997</td><td style=\"text-align: right;\"> 0.741857  </td><td style=\"text-align: right;\">1.05306   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         10.6106</td><td style=\"text-align: right;\"> 0.872513  </td><td style=\"text-align: right;\">1.62001   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\"> 0.00149597</td><td style=\"text-align: right;\">7.32796   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c25fa8bc:\n",
      "  date: 2021-03-12_14-21-09\n",
      "  done: false\n",
      "  experiment_id: e58aa7aa02d343fb8e27d9398c98cb85\n",
      "  experiment_tag: 2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 2.1214213371276855\n",
      "  lossg: 0.27660655975341797\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12694\n",
      "  time_since_restore: 18.816978216171265\n",
      "  time_this_iter_s: 4.510826349258423\n",
      "  time_total_s: 18.816978216171265\n",
      "  timestamp: 1615555269\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c25fa8bc\n",
      "  \n",
      "Result for PytorchTrainable_c2551280:\n",
      "  date: 2021-03-12_14-21-10\n",
      "  done: false\n",
      "  experiment_id: 5fceba58135d46d297e2be2df99de920\n",
      "  experiment_tag: 1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 1.0653326171450317e-05\n",
      "  lossg: 28.900224685668945\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12698\n",
      "  time_since_restore: 18.797977924346924\n",
      "  time_this_iter_s: 3.7057650089263916\n",
      "  time_total_s: 18.797977924346924\n",
      "  timestamp: 1615555270\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c2551280\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-10\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 7.791835784912109\n",
      "  lossg: 0.0009688679128885269\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 18.819164037704468\n",
      "  time_this_iter_s: 4.147989988327026\n",
      "  time_total_s: 18.819164037704468\n",
      "  timestamp: 1615555270\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c27a58f6\n",
      "  \n",
      "Result for PytorchTrainable_c269dd1e:\n",
      "  date: 2021-03-12_14-21-10\n",
      "  done: false\n",
      "  experiment_id: 6b7a539ade85478782cc3b82d5490653\n",
      "  experiment_tag: 5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 2.611551284790039\n",
      "  lossg: 0.15312926471233368\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12696\n",
      "  time_since_restore: 19.122440099716187\n",
      "  time_this_iter_s: 4.110103130340576\n",
      "  time_total_s: 19.122440099716187\n",
      "  timestamp: 1615555270\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c269dd1e\n",
      "  \n",
      "Result for PytorchTrainable_c270956e:\n",
      "  date: 2021-03-12_14-21-10\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 1.645708441734314\n",
      "  lossg: 0.7611960172653198\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12693\n",
      "  time_since_restore: 19.10310435295105\n",
      "  time_this_iter_s: 3.9267804622650146\n",
      "  time_total_s: 19.10310435295105\n",
      "  timestamp: 1615555270\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c270956e\n",
      "  \n",
      "Result for PytorchTrainable_c26d0d54:\n",
      "  date: 2021-03-12_14-21-11\n",
      "  done: false\n",
      "  experiment_id: a0887323846e4303a33193340cc9e49d\n",
      "  experiment_tag: 6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 0.9044251441955566\n",
      "  lossg: 0.8160523176193237\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12690\n",
      "  time_since_restore: 19.691182136535645\n",
      "  time_this_iter_s: 4.190385580062866\n",
      "  time_total_s: 19.691182136535645\n",
      "  timestamp: 1615555271\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c26d0d54\n",
      "  \n",
      "Result for PytorchTrainable_c265fbd6:\n",
      "  date: 2021-03-12_14-21-11\n",
      "  done: false\n",
      "  experiment_id: 05637de727b3467d8ee28a95ca2f4e4b\n",
      "  experiment_tag: 4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 1.3667206764221191\n",
      "  lossg: 0.6377959847450256\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12692\n",
      "  time_since_restore: 19.751342296600342\n",
      "  time_this_iter_s: 3.9940781593322754\n",
      "  time_total_s: 19.751342296600342\n",
      "  timestamp: 1615555271\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c265fbd6\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.8/15.6 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.038562439302529, 'netD_lr': 1.5025180752436178, 'netG_B': 0.7739697042019353, 'netD_B': 0.2556187542489788, 'weight_decay1': 4.552352301834492, 'weight_decay2': 5.155030556976821}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 8/16 (8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>10.1.2.198:12698</td><td style=\"text-align: right;\">0.255619</td><td style=\"text-align: right;\">  1.50252</td><td style=\"text-align: right;\">0.77397 </td><td style=\"text-align: right;\">  6.03856</td><td style=\"text-align: right;\">        4.55235</td><td style=\"text-align: right;\">        5.15503</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.798 </td><td style=\"text-align: right;\">28.9002     </td><td style=\"text-align: right;\">1.06533e-05</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>RUNNING </td><td>10.1.2.198:12694</td><td style=\"text-align: right;\">0.765429</td><td style=\"text-align: right;\">  5.13705</td><td style=\"text-align: right;\">0.977972</td><td style=\"text-align: right;\">  4.18609</td><td style=\"text-align: right;\">        7.08923</td><td style=\"text-align: right;\">        5.10404</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.817 </td><td style=\"text-align: right;\"> 0.276607   </td><td style=\"text-align: right;\">2.12142    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>10.1.2.198:12695</td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.7997</td><td style=\"text-align: right;\"> 7.83031    </td><td style=\"text-align: right;\">0.00174855 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>RUNNING </td><td>10.1.2.198:12692</td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.7513</td><td style=\"text-align: right;\"> 0.637796   </td><td style=\"text-align: right;\">1.36672    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.1224</td><td style=\"text-align: right;\"> 0.153129   </td><td style=\"text-align: right;\">2.61155    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.6912</td><td style=\"text-align: right;\"> 0.816052   </td><td style=\"text-align: right;\">0.904425   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.1031</td><td style=\"text-align: right;\"> 0.761196   </td><td style=\"text-align: right;\">1.64571    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.8192</td><td style=\"text-align: right;\"> 0.000968868</td><td style=\"text-align: right;\">7.79184    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c262ef68:\n",
      "  date: 2021-03-12_14-21-11\n",
      "  done: false\n",
      "  experiment_id: 32420a51384348c28e420155bc0bb16d\n",
      "  experiment_tag: 3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 0.0014446881832554936\n",
      "  lossg: 8.251484870910645\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12695\n",
      "  time_since_restore: 20.341718673706055\n",
      "  time_this_iter_s: 4.542032480239868\n",
      "  time_total_s: 20.341718673706055\n",
      "  timestamp: 1615555271\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c262ef68\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:14,212\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c270956e (score 1.0000000000000004) -> PytorchTrainable_c2551280 (score 1.0000000000000004)\n",
      "2021-03-12 14:21:14,377\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549} -> {'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}\n",
      "2021-03-12 14:21:14,587\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c270956e (score 1.0000000000000004) -> PytorchTrainable_c25fa8bc (score 1.0000000000000004)\n",
      "\u001b[2m\u001b[36m(pid=12698)\u001b[0m 2021-03-12 14:21:14,575\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-21-14sytj7hti/tmpm7pom8qcrestore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=12698)\u001b[0m 2021-03-12 14:21:14,576\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 10.610648393630981, '_episodes_total': None}\n",
      "2021-03-12 14:21:14,662\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549} -> {'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}\n",
      "\u001b[2m\u001b[36m(pid=12694)\u001b[0m 2021-03-12 14:21:14,805\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-21-143v9v_wz6/tmp19cxdp9jrestore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=12694)\u001b[0m 2021-03-12 14:21:14,805\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 10.610648393630981, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-18\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 8.163922309875488\n",
      "  lossg: 0.0006239423528313637\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 26.573165893554688\n",
      "  time_this_iter_s: 3.9262802600860596\n",
      "  time_total_s: 26.573165893554688\n",
      "  timestamp: 1615555278\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c27a58f6\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.0/15.6 GiB<br>PopulationBasedTraining: 4 checkpoints, 2 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.038562439302529, 'netD_lr': 1.5025180752436178, 'netG_B': 0.7739697042019353, 'netD_B': 0.2556187542489788, 'weight_decay1': 4.552352301834492, 'weight_decay2': 5.155030556976821}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 8/16 (8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>10.1.2.198:12698</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         22.9794</td><td style=\"text-align: right;\">28.2738     </td><td style=\"text-align: right;\">3.98003e-05</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>RUNNING </td><td>10.1.2.198:12694</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         23.42  </td><td style=\"text-align: right;\"> 0.23376    </td><td style=\"text-align: right;\">2.18183    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>10.1.2.198:12695</td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         24.7082</td><td style=\"text-align: right;\"> 8.42853    </td><td style=\"text-align: right;\">0.000989857</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>RUNNING </td><td>10.1.2.198:12692</td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         23.9421</td><td style=\"text-align: right;\"> 0.646656   </td><td style=\"text-align: right;\">1.39286    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         23.8187</td><td style=\"text-align: right;\"> 0.153918   </td><td style=\"text-align: right;\">2.5591     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         23.5212</td><td style=\"text-align: right;\"> 0.829019   </td><td style=\"text-align: right;\">0.893983   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         23.3988</td><td style=\"text-align: right;\"> 0.916175   </td><td style=\"text-align: right;\">1.4979     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         26.5732</td><td style=\"text-align: right;\"> 0.000623942</td><td style=\"text-align: right;\">8.16392    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c2551280:\n",
      "  date: 2021-03-12_14-21-18\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155@perturbed[netD_B=1.045,netD_lr=7.7969,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.5667753219604492\n",
      "  lossg: 0.852971076965332\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12698\n",
      "  time_since_restore: 4.086254119873047\n",
      "  time_this_iter_s: 4.086254119873047\n",
      "  time_total_s: 14.696902513504028\n",
      "  timestamp: 1615555278\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: c2551280\n",
      "  \n",
      "Result for PytorchTrainable_c26d0d54:\n",
      "  date: 2021-03-12_14-21-19\n",
      "  done: false\n",
      "  experiment_id: a0887323846e4303a33193340cc9e49d\n",
      "  experiment_tag: 6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 0.8067592978477478\n",
      "  lossg: 0.9183082580566406\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12690\n",
      "  time_since_restore: 27.654478788375854\n",
      "  time_this_iter_s: 4.133248567581177\n",
      "  time_total_s: 27.654478788375854\n",
      "  timestamp: 1615555279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c26d0d54\n",
      "  \n",
      "Result for PytorchTrainable_c269dd1e:\n",
      "  date: 2021-03-12_14-21-19\n",
      "  done: false\n",
      "  experiment_id: 6b7a539ade85478782cc3b82d5490653\n",
      "  experiment_tag: 5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 2.5403995513916016\n",
      "  lossg: 0.15193136036396027\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12696\n",
      "  time_since_restore: 27.555390119552612\n",
      "  time_this_iter_s: 3.736706495285034\n",
      "  time_total_s: 27.555390119552612\n",
      "  timestamp: 1615555279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c269dd1e\n",
      "  \n",
      "Result for PytorchTrainable_c25fa8bc:\n",
      "  date: 2021-03-12_14-21-19\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104@perturbed[netD_B=1.045,netD_lr=7.7969,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.5574233531951904\n",
      "  lossg: 0.8046096563339233\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12694\n",
      "  time_since_restore: 4.483807802200317\n",
      "  time_this_iter_s: 4.483807802200317\n",
      "  time_total_s: 15.094456195831299\n",
      "  timestamp: 1615555279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: c25fa8bc\n",
      "  \n",
      "Result for PytorchTrainable_c270956e:\n",
      "  date: 2021-03-12_14-21-19\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 1.5890228748321533\n",
      "  lossg: 0.8220675587654114\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12693\n",
      "  time_since_restore: 27.67716693878174\n",
      "  time_this_iter_s: 4.278377532958984\n",
      "  time_total_s: 27.67716693878174\n",
      "  timestamp: 1615555279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c270956e\n",
      "  \n",
      "Result for PytorchTrainable_c265fbd6:\n",
      "  date: 2021-03-12_14-21-19\n",
      "  done: false\n",
      "  experiment_id: 05637de727b3467d8ee28a95ca2f4e4b\n",
      "  experiment_tag: 4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 1.3836376667022705\n",
      "  lossg: 0.5955987572669983\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12692\n",
      "  time_since_restore: 28.034854650497437\n",
      "  time_this_iter_s: 4.092753887176514\n",
      "  time_total_s: 28.034854650497437\n",
      "  timestamp: 1615555279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c265fbd6\n",
      "  \n",
      "Result for PytorchTrainable_c262ef68:\n",
      "  date: 2021-03-12_14-21-20\n",
      "  done: false\n",
      "  experiment_id: 32420a51384348c28e420155bc0bb16d\n",
      "  experiment_tag: 3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 0.0006192154251039028\n",
      "  lossg: 8.711061477661133\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12695\n",
      "  time_since_restore: 29.10582423210144\n",
      "  time_this_iter_s: 4.3976099491119385\n",
      "  time_total_s: 29.10582423210144\n",
      "  timestamp: 1615555280\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c262ef68\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-23\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 8\n",
      "  lossd: 8.278487205505371\n",
      "  lossg: 0.0005441579851321876\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 31.5661199092865\n",
      "  time_this_iter_s: 4.9929540157318115\n",
      "  time_total_s: 31.5661199092865\n",
      "  timestamp: 1615555283\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: c27a58f6\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 4 checkpoints, 2 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 8/16 (8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>RUNNING </td><td>10.1.2.198:12698</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408   </td><td style=\"text-align: right;\">1.6445     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>RUNNING </td><td>10.1.2.198:12694</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418    </td><td style=\"text-align: right;\">1.6213     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>10.1.2.198:12695</td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.1058</td><td style=\"text-align: right;\">8.71106    </td><td style=\"text-align: right;\">0.000619215</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>RUNNING </td><td>10.1.2.198:12692</td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         28.0349</td><td style=\"text-align: right;\">0.595599   </td><td style=\"text-align: right;\">1.38364    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         27.5554</td><td style=\"text-align: right;\">0.151931   </td><td style=\"text-align: right;\">2.5404     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         27.6545</td><td style=\"text-align: right;\">0.918308   </td><td style=\"text-align: right;\">0.806759   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         27.6772</td><td style=\"text-align: right;\">0.822068   </td><td style=\"text-align: right;\">1.58902    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         31.5661</td><td style=\"text-align: right;\">0.000544158</td><td style=\"text-align: right;\">8.27849    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:26,851\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c27a58f6 (score 1.0000000000000004) -> PytorchTrainable_c25fa8bc (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:27,003\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c25fa8bc: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 42, in K\n",
      "    dists = pairwise_distances(T1, T2, \"cityblock\")\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 1432, in pairwise_distances\n",
      "    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 1067, in _parallel_pairwise\n",
      "    return func(X, Y, **kwds)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 501, in manhattan_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "2021-03-12 14:21:27,299\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c270956e (score 1.0000000000000004) -> PytorchTrainable_c2551280 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:27,397\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c2551280: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 42, in K\n",
      "    dists = pairwise_distances(T1, T2, \"cityblock\")\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 1432, in pairwise_distances\n",
      "    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 1067, in _parallel_pairwise\n",
      "    return func(X, Y, **kwds)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 501, in manhattan_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c269dd1e:\n",
      "  date: 2021-03-12_14-21-27\n",
      "  done: false\n",
      "  experiment_id: 6b7a539ade85478782cc3b82d5490653\n",
      "  experiment_tag: 5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 2.3488972187042236\n",
      "  lossg: 0.189730703830719\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12696\n",
      "  time_since_restore: 35.62055015563965\n",
      "  time_this_iter_s: 3.677259922027588\n",
      "  time_total_s: 35.62055015563965\n",
      "  timestamp: 1615555287\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: c269dd1e\n",
      "  \n",
      "Result for PytorchTrainable_c26d0d54:\n",
      "  date: 2021-03-12_14-21-28\n",
      "  done: false\n",
      "  experiment_id: a0887323846e4303a33193340cc9e49d\n",
      "  experiment_tag: 6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 0.8074744343757629\n",
      "  lossg: 0.9449591040611267\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12690\n",
      "  time_since_restore: 36.655590772628784\n",
      "  time_this_iter_s: 4.105539798736572\n",
      "  time_total_s: 36.655590772628784\n",
      "  timestamp: 1615555288\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: c26d0d54\n",
      "  \n",
      "Result for PytorchTrainable_c270956e:\n",
      "  date: 2021-03-12_14-21-28\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 1.5378321409225464\n",
      "  lossg: 0.8473284840583801\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12693\n",
      "  time_since_restore: 36.21815228462219\n",
      "  time_this_iter_s: 4.1827614307403564\n",
      "  time_total_s: 36.21815228462219\n",
      "  timestamp: 1615555288\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: c270956e\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:28,430\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c270956e (score 1.0000000000000004) -> PytorchTrainable_c265fbd6 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:28,545\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c265fbd6: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.3/15.6 GiB<br>PopulationBasedTraining: 6 checkpoints, 2 perturbs<br>Resources requested: 7/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 10/16 (3 ERROR, 7 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>RUNNING </td><td>10.1.2.198:12695</td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224    </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         35.6206</td><td style=\"text-align: right;\">0.189731   </td><td style=\"text-align: right;\">2.3489    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         36.6556</td><td style=\"text-align: right;\">0.944959   </td><td style=\"text-align: right;\">0.807474  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         36.2182</td><td style=\"text-align: right;\">0.847328   </td><td style=\"text-align: right;\">1.53783   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         35.4676</td><td style=\"text-align: right;\">0.000476045</td><td style=\"text-align: right;\">8.39778   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.867992</td><td style=\"text-align: right;\">  5.99165</td><td style=\"text-align: right;\">1.28423 </td><td style=\"text-align: right;\">  4.86506</td><td style=\"text-align: right;\">        6.54505</td><td style=\"text-align: right;\">        6.16935</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408   </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418    </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088   </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 3<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:29,827\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c270956e (score 1.0000000000000004) -> PytorchTrainable_c262ef68 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:29,971\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c262ef68: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c269dd1e:\n",
      "  date: 2021-03-12_14-21-32\n",
      "  done: false\n",
      "  experiment_id: 6b7a539ade85478782cc3b82d5490653\n",
      "  experiment_tag: 5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 10\n",
      "  lossd: 2.564368724822998\n",
      "  lossg: 0.15709157288074493\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12696\n",
      "  time_since_restore: 41.10781168937683\n",
      "  time_this_iter_s: 5.487261533737183\n",
      "  time_total_s: 41.10781168937683\n",
      "  timestamp: 1615555292\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c269dd1e\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-33\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 10\n",
      "  lossd: 8.463130950927734\n",
      "  lossg: 0.0004358137375675142\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 41.06786108016968\n",
      "  time_this_iter_s: 5.600224733352661\n",
      "  time_total_s: 41.06786108016968\n",
      "  timestamp: 1615555293\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c27a58f6\n",
      "  \n",
      "Result for PytorchTrainable_c26d0d54:\n",
      "  date: 2021-03-12_14-21-33\n",
      "  done: false\n",
      "  experiment_id: a0887323846e4303a33193340cc9e49d\n",
      "  experiment_tag: 6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 10\n",
      "  lossd: 0.6914150714874268\n",
      "  lossg: 1.0262367725372314\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12690\n",
      "  time_since_restore: 41.82821607589722\n",
      "  time_this_iter_s: 5.172625303268433\n",
      "  time_total_s: 41.82821607589722\n",
      "  timestamp: 1615555293\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c26d0d54\n",
      "  \n",
      "Result for PytorchTrainable_c270956e:\n",
      "  date: 2021-03-12_14-21-33\n",
      "  done: false\n",
      "  experiment_id: a67edabec5784804876280f474735823\n",
      "  experiment_tag: 7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 10\n",
      "  lossd: 1.5462695360183716\n",
      "  lossg: 0.8445678353309631\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12693\n",
      "  time_since_restore: 41.44031119346619\n",
      "  time_this_iter_s: 5.222158908843994\n",
      "  time_total_s: 41.44031119346619\n",
      "  timestamp: 1615555293\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c270956e\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.1/15.6 GiB<br>PopulationBasedTraining: 6 checkpoints, 2 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 12/16 (4 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         41.1078</td><td style=\"text-align: right;\">0.157092   </td><td style=\"text-align: right;\">2.56437   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         41.8282</td><td style=\"text-align: right;\">1.02624    </td><td style=\"text-align: right;\">0.691415  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         41.4403</td><td style=\"text-align: right;\">0.844568   </td><td style=\"text-align: right;\">1.54627   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         41.0679</td><td style=\"text-align: right;\">0.000435814</td><td style=\"text-align: right;\">8.46313   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.867992</td><td style=\"text-align: right;\">  5.99165</td><td style=\"text-align: right;\">1.28423 </td><td style=\"text-align: right;\">  4.86506</td><td style=\"text-align: right;\">        6.54505</td><td style=\"text-align: right;\">        6.16935</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408   </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418    </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224    </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088   </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 4<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13556)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13556)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=13551)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13551)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=13555)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13555)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=13557)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13557)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d97e8e96:\n",
      "  date: 2021-03-12_14-21-38\n",
      "  done: false\n",
      "  experiment_id: f1270f46b8d54fefacf55b12e0027253\n",
      "  experiment_tag: 9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.3790550231933594\n",
      "  lossg: 0.796058714389801\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13556\n",
      "  time_since_restore: 3.932819366455078\n",
      "  time_this_iter_s: 3.932819366455078\n",
      "  time_total_s: 3.932819366455078\n",
      "  timestamp: 1615555298\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d97e8e96\n",
      "  \n",
      "Result for PytorchTrainable_d9b862b0:\n",
      "  date: 2021-03-12_14-21-39\n",
      "  done: false\n",
      "  experiment_id: f7510209a74545e49257002e27831187\n",
      "  experiment_tag: 10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.09020831435918808\n",
      "  lossg: 3.660874843597412\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13551\n",
      "  time_since_restore: 4.855981349945068\n",
      "  time_this_iter_s: 4.855981349945068\n",
      "  time_total_s: 4.855981349945068\n",
      "  timestamp: 1615555299\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d9b862b0\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 6 checkpoints, 2 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 12/16 (4 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>RUNNING </td><td>10.1.2.198:12696</td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>RUNNING </td><td>10.1.2.198:12690</td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>RUNNING </td><td>10.1.2.198:12693</td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.6821 </td><td style=\"text-align: right;\">0.00040596</td><td style=\"text-align: right;\">8.52859   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">0.867992</td><td style=\"text-align: right;\">  5.99165</td><td style=\"text-align: right;\">1.28423 </td><td style=\"text-align: right;\">  4.86506</td><td style=\"text-align: right;\">        6.54505</td><td style=\"text-align: right;\">        6.16935</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.93282</td><td style=\"text-align: right;\">0.796059  </td><td style=\"text-align: right;\">1.37906   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.85598</td><td style=\"text-align: right;\">3.66087   </td><td style=\"text-align: right;\">0.0902083 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 4<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_da6addc8:\n",
      "  date: 2021-03-12_14-21-39\n",
      "  done: false\n",
      "  experiment_id: 8393d5f89d5b4966984e3dac2920474c\n",
      "  experiment_tag: 11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.5026215314865112\n",
      "  lossg: 1.640519142150879\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13555\n",
      "  time_since_restore: 3.898926019668579\n",
      "  time_this_iter_s: 3.898926019668579\n",
      "  time_total_s: 3.898926019668579\n",
      "  timestamp: 1615555299\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: da6addc8\n",
      "  \n",
      "Result for PytorchTrainable_db41329c:\n",
      "  date: 2021-03-12_14-21-40\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.0164248943328857\n",
      "  lossg: 1.0065804719924927\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13557\n",
      "  time_since_restore: 4.726090431213379\n",
      "  time_this_iter_s: 4.726090431213379\n",
      "  time_total_s: 4.726090431213379\n",
      "  timestamp: 1615555300\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: db41329c\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:41,547\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c27a58f6 (score 1.0000000000000004) -> PytorchTrainable_c269dd1e (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:41,703\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c269dd1e: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "2021-03-12 14:21:41,832\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c27a58f6 (score 1.0000000000000004) -> PytorchTrainable_c26d0d54 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:42,005\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c26d0d54: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:42,516\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_c27a58f6 (score 1.0000000000000004) -> PytorchTrainable_c270956e (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:21:42,690\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c270956e: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-42\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 12\n",
      "  lossd: 8.618123054504395\n",
      "  lossg: 0.00037201083614490926\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 50.43481087684631\n",
      "  time_this_iter_s: 4.752730131149292\n",
      "  time_total_s: 50.43481087684631\n",
      "  timestamp: 1615555302\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: c27a58f6\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.3/15.6 GiB<br>PopulationBasedTraining: 6 checkpoints, 2 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        50.4348 </td><td style=\"text-align: right;\">0.000372011</td><td style=\"text-align: right;\">8.61812   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">0.867992</td><td style=\"text-align: right;\">  5.99165</td><td style=\"text-align: right;\">1.28423 </td><td style=\"text-align: right;\">  4.86506</td><td style=\"text-align: right;\">        6.54505</td><td style=\"text-align: right;\">        6.16935</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.61652</td><td style=\"text-align: right;\">0.688427   </td><td style=\"text-align: right;\">1.47816   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.85598</td><td style=\"text-align: right;\">3.66087    </td><td style=\"text-align: right;\">0.0902083 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.77879</td><td style=\"text-align: right;\">2.63715    </td><td style=\"text-align: right;\">0.185216  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.72609</td><td style=\"text-align: right;\">1.00658    </td><td style=\"text-align: right;\">1.01642   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408   </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418    </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224    </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088   </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798   </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925    </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612   </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d9b862b0:\n",
      "  date: 2021-03-12_14-21-44\n",
      "  done: false\n",
      "  experiment_id: f7510209a74545e49257002e27831187\n",
      "  experiment_tag: 10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 2\n",
      "  lossd: 0.07155363261699677\n",
      "  lossg: 4.13442325592041\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13551\n",
      "  time_since_restore: 10.431094408035278\n",
      "  time_this_iter_s: 5.57511305809021\n",
      "  time_total_s: 10.431094408035278\n",
      "  timestamp: 1615555304\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d9b862b0\n",
      "  \n",
      "Result for PytorchTrainable_db41329c:\n",
      "  date: 2021-03-12_14-21-46\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 2\n",
      "  lossd: 0.728327751159668\n",
      "  lossg: 1.252805471420288\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13557\n",
      "  time_since_restore: 10.362938165664673\n",
      "  time_this_iter_s: 5.636847734451294\n",
      "  time_total_s: 10.362938165664673\n",
      "  timestamp: 1615555306\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: db41329c\n",
      "  \n",
      "Result for PytorchTrainable_d97e8e96:\n",
      "  date: 2021-03-12_14-21-47\n",
      "  done: false\n",
      "  experiment_id: f1270f46b8d54fefacf55b12e0027253\n",
      "  experiment_tag: 9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 1.550417423248291\n",
      "  lossg: 0.6027251482009888\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13556\n",
      "  time_since_restore: 13.383970499038696\n",
      "  time_this_iter_s: 4.7674548625946045\n",
      "  time_total_s: 13.383970499038696\n",
      "  timestamp: 1615555307\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d97e8e96\n",
      "  \n",
      "Result for PytorchTrainable_da6addc8:\n",
      "  date: 2021-03-12_14-21-49\n",
      "  done: false\n",
      "  experiment_id: 8393d5f89d5b4966984e3dac2920474c\n",
      "  experiment_tag: 11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 0.10015325248241425\n",
      "  lossg: 3.111844062805176\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13555\n",
      "  time_since_restore: 13.591318368911743\n",
      "  time_this_iter_s: 4.812526702880859\n",
      "  time_total_s: 13.591318368911743\n",
      "  timestamp: 1615555309\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: da6addc8\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.8/15.6 GiB<br>PopulationBasedTraining: 9 checkpoints, 2 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">0.833915</td><td style=\"text-align: right;\">  6.13565</td><td style=\"text-align: right;\">0.961426</td><td style=\"text-align: right;\">  2.46292</td><td style=\"text-align: right;\">        5.60151</td><td style=\"text-align: right;\">        5.2504 </td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         55.3197</td><td style=\"text-align: right;\">0.000341292</td><td style=\"text-align: right;\">8.76753   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">0.867992</td><td style=\"text-align: right;\">  5.99165</td><td style=\"text-align: right;\">1.28423 </td><td style=\"text-align: right;\">  4.86506</td><td style=\"text-align: right;\">        6.54505</td><td style=\"text-align: right;\">        6.16935</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         13.384 </td><td style=\"text-align: right;\">0.602725   </td><td style=\"text-align: right;\">1.55042   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         14.6232</td><td style=\"text-align: right;\">4.42072    </td><td style=\"text-align: right;\">0.0861595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         13.5913</td><td style=\"text-align: right;\">3.11184    </td><td style=\"text-align: right;\">0.100153  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         14.794 </td><td style=\"text-align: right;\">1.48236    </td><td style=\"text-align: right;\">0.52266   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408   </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418    </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224    </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088   </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798   </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925    </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612   </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13925)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13925)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=13922)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13922)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=13927)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=13927)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-51\n",
      "  done: false\n",
      "  experiment_id: 52b0eddbcd3c4410853e96240b24ee92\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 14\n",
      "  lossd: 8.791297912597656\n",
      "  lossg: 0.00034104124642908573\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 59.46911144256592\n",
      "  time_this_iter_s: 4.149373292922974\n",
      "  time_total_s: 59.46911144256592\n",
      "  timestamp: 1615555311\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: c27a58f6\n",
      "  \n",
      "Result for PytorchTrainable_d9b862b0:\n",
      "  date: 2021-03-12_14-21-53\n",
      "  done: false\n",
      "  experiment_id: f7510209a74545e49257002e27831187\n",
      "  experiment_tag: 10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 4\n",
      "  lossd: 0.04336126148700714\n",
      "  lossg: 4.532009601593018\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13551\n",
      "  time_since_restore: 19.229699850082397\n",
      "  time_this_iter_s: 4.606534719467163\n",
      "  time_total_s: 19.229699850082397\n",
      "  timestamp: 1615555313\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d9b862b0\n",
      "  \n",
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-21-54\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.031131668016314507\n",
      "  lossg: 4.727709770202637\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 4.012221097946167\n",
      "  time_this_iter_s: 4.012221097946167\n",
      "  time_total_s: 4.012221097946167\n",
      "  timestamp: 1615555314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: e2d5a448\n",
      "  \n",
      "Result for PytorchTrainable_e241e8fc:\n",
      "  date: 2021-03-12_14-21-54\n",
      "  done: false\n",
      "  experiment_id: 057eabed80dd48e589303d025f84acc3\n",
      "  experiment_tag: 13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 1.579500675201416\n",
      "  lossg: 0.5133411884307861\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13922\n",
      "  time_since_restore: 4.768573522567749\n",
      "  time_this_iter_s: 4.768573522567749\n",
      "  time_total_s: 4.768573522567749\n",
      "  timestamp: 1615555314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: e241e8fc\n",
      "  \n",
      "Result for PytorchTrainable_db41329c:\n",
      "  date: 2021-03-12_14-21-54\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 4\n",
      "  lossd: 0.3979838490486145\n",
      "  lossg: 1.7413612604141235\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13557\n",
      "  time_since_restore: 18.683096170425415\n",
      "  time_this_iter_s: 3.8891215324401855\n",
      "  time_total_s: 18.683096170425415\n",
      "  timestamp: 1615555314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: db41329c\n",
      "  \n",
      "Result for PytorchTrainable_e26f648a:\n",
      "  date: 2021-03-12_14-21-54\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 3.240777015686035\n",
      "  lossg: 0.13996614515781403\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13927\n",
      "  time_since_restore: 4.577194452285767\n",
      "  time_this_iter_s: 4.577194452285767\n",
      "  time_total_s: 4.577194452285767\n",
      "  timestamp: 1615555314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: e26f648a\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:21:55,989\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_db41329c (score 1.0000000000000004) -> PytorchTrainable_c27a58f6 (score 1.0000000000000004)\n",
      "2021-03-12 14:21:56,044\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 8.36876486253751, 'netD_lr': 4.464290105564972, 'netD_B': 1.3788773985468048, 'weight_decay1': 4.791496422060527, 'weight_decay2': 4.7137851557861} -> {'netG_lr': 8.36876486253751, 'netD_lr': 4.464290105564972, 'netD_B': 1.3788773985468048, 'weight_decay1': 4.791496422060527, 'weight_decay2': 4.7137851557861}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        63.5542 </td><td style=\"text-align: right;\">0.000308753</td><td style=\"text-align: right;\">8.81764   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">0.867992</td><td style=\"text-align: right;\">  5.99165</td><td style=\"text-align: right;\">1.28423 </td><td style=\"text-align: right;\">  4.86506</td><td style=\"text-align: right;\">        6.54505</td><td style=\"text-align: right;\">        6.16935</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        17.8657 </td><td style=\"text-align: right;\">0.556737   </td><td style=\"text-align: right;\">1.63221   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        19.2297 </td><td style=\"text-align: right;\">4.53201    </td><td style=\"text-align: right;\">0.0433613 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        18.1795 </td><td style=\"text-align: right;\">3.45646    </td><td style=\"text-align: right;\">0.0797248 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        18.6831 </td><td style=\"text-align: right;\">1.74136    </td><td style=\"text-align: right;\">0.397984  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.76857</td><td style=\"text-align: right;\">0.513341   </td><td style=\"text-align: right;\">1.5795    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.57719</td><td style=\"text-align: right;\">0.139966   </td><td style=\"text-align: right;\">3.24078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.01222</td><td style=\"text-align: right;\">4.72771    </td><td style=\"text-align: right;\">0.0311317 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408   </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418    </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224    </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088   </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798   </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925    </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612   </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12691)\u001b[0m 2021-03-12 14:21:56,148\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-21-56dsoyep45/tmp1a6zslzfrestore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=12691)\u001b[0m 2021-03-12 14:21:56,149\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 14.79397463798523, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d97e8e96:\n",
      "  date: 2021-03-12_14-21-56\n",
      "  done: false\n",
      "  experiment_id: f1270f46b8d54fefacf55b12e0027253\n",
      "  experiment_tag: 9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 1.527231216430664\n",
      "  lossg: 0.5765392184257507\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13556\n",
      "  time_since_restore: 21.92507529258728\n",
      "  time_this_iter_s: 4.059424638748169\n",
      "  time_total_s: 21.92507529258728\n",
      "  timestamp: 1615555316\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d97e8e96\n",
      "  \n",
      "Result for PytorchTrainable_da6addc8:\n",
      "  date: 2021-03-12_14-21-57\n",
      "  done: false\n",
      "  experiment_id: 8393d5f89d5b4966984e3dac2920474c\n",
      "  experiment_tag: 11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 0.049055956304073334\n",
      "  lossg: 3.816237449645996\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13555\n",
      "  time_since_restore: 21.807289600372314\n",
      "  time_this_iter_s: 3.627830743789673\n",
      "  time_total_s: 21.807289600372314\n",
      "  timestamp: 1615555317\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: da6addc8\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-21-59\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504@perturbed[netD_B=1.3789,netD_lr=4.4643,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.3795732259750366\n",
      "  lossg: 1.8161201477050781\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 3.502678632736206\n",
      "  time_this_iter_s: 3.502678632736206\n",
      "  time_total_s: 18.296653270721436\n",
      "  timestamp: 1615555319\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: c27a58f6\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:00,543\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_db41329c (score 1.0000000000000004) -> PytorchTrainable_d97e8e96 (score 1.0000000000000004)\n",
      "2021-03-12 14:22:00,655\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 8.36876486253751, 'netD_lr': 4.464290105564972, 'netD_B': 1.3788773985468048, 'weight_decay1': 4.791496422060527, 'weight_decay2': 4.7137851557861} -> {'netG_lr': 8.36876486253751, 'netD_lr': 4.464290105564972, 'netD_B': 1.3788773985468048, 'weight_decay1': 4.791496422060527, 'weight_decay2': 4.7137851557861}\n",
      "\u001b[2m\u001b[36m(pid=13556)\u001b[0m 2021-03-12 14:22:00,798\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-22-00tvjklpo5/tmpkt_qgl63restore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=13556)\u001b[0m 2021-03-12 14:22:00,798\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 14.79397463798523, '_episodes_total': None}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        18.2967 </td><td style=\"text-align: right;\">1.81612  </td><td style=\"text-align: right;\">0.379573  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        25.8716 </td><td style=\"text-align: right;\">0.444884 </td><td style=\"text-align: right;\">1.73844   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        23.4645 </td><td style=\"text-align: right;\">4.84975  </td><td style=\"text-align: right;\">0.0396309 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        25.856  </td><td style=\"text-align: right;\">4.09602  </td><td style=\"text-align: right;\">0.0420655 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        22.8226 </td><td style=\"text-align: right;\">2.15343  </td><td style=\"text-align: right;\">0.26194   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.74298</td><td style=\"text-align: right;\">0.545741 </td><td style=\"text-align: right;\">1.56554   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.57615</td><td style=\"text-align: right;\">0.0564483</td><td style=\"text-align: right;\">4.06632   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         7.64448</td><td style=\"text-align: right;\">5.40327  </td><td style=\"text-align: right;\">0.014935  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408 </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418  </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224  </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088 </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798 </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925  </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612 </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d9b862b0:\n",
      "  date: 2021-03-12_14-22-01\n",
      "  done: false\n",
      "  experiment_id: f7510209a74545e49257002e27831187\n",
      "  experiment_tag: 10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 6\n",
      "  lossd: 0.026169972494244576\n",
      "  lossg: 5.556921482086182\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13551\n",
      "  time_since_restore: 27.040177583694458\n",
      "  time_this_iter_s: 3.5756287574768066\n",
      "  time_total_s: 27.040177583694458\n",
      "  timestamp: 1615555321\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d9b862b0\n",
      "  \n",
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-01\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 0.005384470336139202\n",
      "  lossg: 6.1224775314331055\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 11.948883295059204\n",
      "  time_this_iter_s: 4.304399013519287\n",
      "  time_total_s: 11.948883295059204\n",
      "  timestamp: 1615555321\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: e2d5a448\n",
      "  \n",
      "Result for PytorchTrainable_e241e8fc:\n",
      "  date: 2021-03-12_14-22-02\n",
      "  done: false\n",
      "  experiment_id: 057eabed80dd48e589303d025f84acc3\n",
      "  experiment_tag: 13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 1.6304534673690796\n",
      "  lossg: 0.5069016814231873\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13922\n",
      "  time_since_restore: 12.73002028465271\n",
      "  time_this_iter_s: 3.987037420272827\n",
      "  time_total_s: 12.73002028465271\n",
      "  timestamp: 1615555322\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: e241e8fc\n",
      "  \n",
      "Result for PytorchTrainable_e26f648a:\n",
      "  date: 2021-03-12_14-22-02\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 4.515340328216553\n",
      "  lossg: 0.03620219603180885\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13927\n",
      "  time_since_restore: 12.255537509918213\n",
      "  time_this_iter_s: 3.6793911457061768\n",
      "  time_total_s: 12.255537509918213\n",
      "  timestamp: 1615555322\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: e26f648a\n",
      "  \n",
      "Result for PytorchTrainable_db41329c:\n",
      "  date: 2021-03-12_14-22-02\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 6\n",
      "  lossd: 0.22754599153995514\n",
      "  lossg: 2.330031633377075\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13557\n",
      "  time_since_restore: 26.427886962890625\n",
      "  time_this_iter_s: 3.605332136154175\n",
      "  time_total_s: 26.427886962890625\n",
      "  timestamp: 1615555322\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: db41329c\n",
      "  \n",
      "Result for PytorchTrainable_d97e8e96:\n",
      "  date: 2021-03-12_14-22-04\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694@perturbed[netD_B=1.3789,netD_lr=4.4643,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.40644571185112\n",
      "  lossg: 1.6684118509292603\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13556\n",
      "  time_since_restore: 4.054414749145508\n",
      "  time_this_iter_s: 4.054414749145508\n",
      "  time_total_s: 18.848389387130737\n",
      "  timestamp: 1615555324\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d97e8e96\n",
      "  \n",
      "Result for PytorchTrainable_da6addc8:\n",
      "  date: 2021-03-12_14-22-05\n",
      "  done: false\n",
      "  experiment_id: 8393d5f89d5b4966984e3dac2920474c\n",
      "  experiment_tag: 11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 0.029666006565093994\n",
      "  lossg: 4.234748363494873\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13555\n",
      "  time_since_restore: 29.811724185943604\n",
      "  time_this_iter_s: 3.9556941986083984\n",
      "  time_total_s: 29.811724185943604\n",
      "  timestamp: 1615555325\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: da6addc8\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:07,612\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e26f648a (score 1.0000000000000004) -> PytorchTrainable_c27a58f6 (score 1.0000000000000004)\n",
      "2021-03-12 14:22:07,696\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 3.4623454110481675, 'netD_lr': 6.270282197750917, 'netD_B': 1.0040340174155375, 'weight_decay1': 6.68186244647654, 'weight_decay2': 4.952322106451164} -> {'netG_lr': 3.4623454110481675, 'netD_lr': 6.270282197750917, 'netD_B': 1.0040340174155375, 'weight_decay1': 6.68186244647654, 'weight_decay2': 4.952322106451164}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-22-07\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504@perturbed[netD_B=1.004,netD_lr=6.2703,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 0.21361961960792542\n",
      "  lossg: 2.2952206134796143\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 11.406798601150513\n",
      "  time_this_iter_s: 3.78464412689209\n",
      "  time_total_s: 26.200773239135742\n",
      "  timestamp: 1615555327\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: c27a58f6\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.0/15.6 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         26.2008</td><td style=\"text-align: right;\">2.29522  </td><td style=\"text-align: right;\">0.21362   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         18.8484</td><td style=\"text-align: right;\">1.66841  </td><td style=\"text-align: right;\">0.406446  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.8762</td><td style=\"text-align: right;\">6.11394  </td><td style=\"text-align: right;\">0.0245374 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.8117</td><td style=\"text-align: right;\">4.23475  </td><td style=\"text-align: right;\">0.029666  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         30.3431</td><td style=\"text-align: right;\">2.47743  </td><td style=\"text-align: right;\">0.182475  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.1293</td><td style=\"text-align: right;\">0.505818 </td><td style=\"text-align: right;\">1.59936   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.9299</td><td style=\"text-align: right;\">0.0222262</td><td style=\"text-align: right;\">4.92395   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.8847</td><td style=\"text-align: right;\">6.50242  </td><td style=\"text-align: right;\">0.00408834</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408 </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418  </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224  </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088 </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798 </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925  </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612 </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12691)\u001b[0m 2021-03-12 14:22:07,853\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-22-07w2b540dn/tmpwemeqd89restore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=12691)\u001b[0m 2021-03-12 14:22:07,859\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 12.255537509918213, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d9b862b0:\n",
      "  date: 2021-03-12_14-22-09\n",
      "  done: false\n",
      "  experiment_id: f7510209a74545e49257002e27831187\n",
      "  experiment_tag: 10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 8\n",
      "  lossd: 0.014110001735389233\n",
      "  lossg: 6.07495641708374\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13551\n",
      "  time_since_restore: 34.782607078552246\n",
      "  time_this_iter_s: 3.906409740447998\n",
      "  time_total_s: 34.782607078552246\n",
      "  timestamp: 1615555329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d9b862b0\n",
      "  \n",
      "Result for PytorchTrainable_e241e8fc:\n",
      "  date: 2021-03-12_14-22-09\n",
      "  done: false\n",
      "  experiment_id: 057eabed80dd48e589303d025f84acc3\n",
      "  experiment_tag: 13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 1.6059590578079224\n",
      "  lossg: 0.5360192656517029\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13922\n",
      "  time_since_restore: 19.69975519180298\n",
      "  time_this_iter_s: 3.570497751235962\n",
      "  time_total_s: 19.69975519180298\n",
      "  timestamp: 1615555329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: e241e8fc\n",
      "  \n",
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-09\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 0.002422900404781103\n",
      "  lossg: 6.885397911071777\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 19.80229139328003\n",
      "  time_this_iter_s: 3.91754150390625\n",
      "  time_total_s: 19.80229139328003\n",
      "  timestamp: 1615555329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: e2d5a448\n",
      "  \n",
      "Result for PytorchTrainable_e26f648a:\n",
      "  date: 2021-03-12_14-22-10\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 5\n",
      "  lossd: 5.24382209777832\n",
      "  lossg: 0.01615065149962902\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13927\n",
      "  time_since_restore: 19.757105350494385\n",
      "  time_this_iter_s: 3.827176809310913\n",
      "  time_total_s: 19.757105350494385\n",
      "  timestamp: 1615555330\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: e26f648a\n",
      "  \n",
      "Result for PytorchTrainable_db41329c:\n",
      "  date: 2021-03-12_14-22-10\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 8\n",
      "  lossd: 0.16089120507240295\n",
      "  lossg: 2.628537178039551\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13557\n",
      "  time_since_restore: 34.141788959503174\n",
      "  time_this_iter_s: 3.7986905574798584\n",
      "  time_total_s: 34.141788959503174\n",
      "  timestamp: 1615555330\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: db41329c\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:13,239\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e26f648a (score 1.0000000000000004) -> PytorchTrainable_d97e8e96 (score 1.0000000000000004)\n",
      "2021-03-12 14:22:13,357\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 3.4623454110481675, 'netD_lr': 6.270282197750917, 'netD_B': 1.0040340174155375, 'weight_decay1': 6.68186244647654, 'weight_decay2': 4.952322106451164} -> {'netG_lr': 3.4623454110481675, 'netD_lr': 6.270282197750917, 'netD_B': 1.0040340174155375, 'weight_decay1': 6.68186244647654, 'weight_decay2': 4.952322106451164}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d97e8e96:\n",
      "  date: 2021-03-12_14-22-13\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694@perturbed[netD_B=1.004,netD_lr=6.2703,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 3\n",
      "  lossd: 0.2367101013660431\n",
      "  lossg: 2.17611026763916\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13556\n",
      "  time_since_restore: 12.366403579711914\n",
      "  time_this_iter_s: 4.352208614349365\n",
      "  time_total_s: 27.160378217697144\n",
      "  timestamp: 1615555333\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d97e8e96\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 13 checkpoints, 6 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         16.4926</td><td style=\"text-align: right;\">0.0207745</td><td style=\"text-align: right;\">5.00645   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         27.1604</td><td style=\"text-align: right;\">2.17611  </td><td style=\"text-align: right;\">0.23671   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.7826</td><td style=\"text-align: right;\">6.07496  </td><td style=\"text-align: right;\">0.01411   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.6338</td><td style=\"text-align: right;\">4.62717  </td><td style=\"text-align: right;\">0.023775  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         34.1418</td><td style=\"text-align: right;\">2.62854  </td><td style=\"text-align: right;\">0.160891  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.6998</td><td style=\"text-align: right;\">0.536019 </td><td style=\"text-align: right;\">1.60596   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.7571</td><td style=\"text-align: right;\">0.0161507</td><td style=\"text-align: right;\">5.24382   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.8023</td><td style=\"text-align: right;\">6.8854   </td><td style=\"text-align: right;\">0.0024229 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408 </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418  </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224  </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088 </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798 </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925  </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612 </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13556)\u001b[0m 2021-03-12 14:22:13,430\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-22-13w1_bhtsn/tmpl79mika7restore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=13556)\u001b[0m 2021-03-12 14:22:13,431\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 12.255537509918213, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_da6addc8:\n",
      "  date: 2021-03-12_14-22-13\n",
      "  done: false\n",
      "  experiment_id: 8393d5f89d5b4966984e3dac2920474c\n",
      "  experiment_tag: 11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 0.018489649519324303\n",
      "  lossg: 4.648601055145264\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13555\n",
      "  time_since_restore: 37.59556722640991\n",
      "  time_this_iter_s: 3.961790084838867\n",
      "  time_total_s: 37.59556722640991\n",
      "  timestamp: 1615555333\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: da6addc8\n",
      "  \n",
      "Result for PytorchTrainable_c27a58f6:\n",
      "  date: 2021-03-12_14-22-17\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504@perturbed[netD_B=1.004,netD_lr=6.2703,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 2\n",
      "  lossd: 5.281844139099121\n",
      "  lossg: 0.016375506296753883\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 12691\n",
      "  time_since_restore: 9.319866418838501\n",
      "  time_this_iter_s: 5.082837343215942\n",
      "  time_total_s: 21.575403928756714\n",
      "  timestamp: 1615555337\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c27a58f6\n",
      "  \n",
      "Result for PytorchTrainable_e241e8fc:\n",
      "  date: 2021-03-12_14-22-17\n",
      "  done: false\n",
      "  experiment_id: 057eabed80dd48e589303d025f84acc3\n",
      "  experiment_tag: 13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 1.6178479194641113\n",
      "  lossg: 0.5069833993911743\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13922\n",
      "  time_since_restore: 28.01128602027893\n",
      "  time_this_iter_s: 4.366499423980713\n",
      "  time_total_s: 28.01128602027893\n",
      "  timestamp: 1615555337\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: e241e8fc\n",
      "  \n",
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-18\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 0.0016596210189163685\n",
      "  lossg: 7.342127799987793\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 28.021687269210815\n",
      "  time_this_iter_s: 3.9852938652038574\n",
      "  time_total_s: 28.021687269210815\n",
      "  timestamp: 1615555338\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: e2d5a448\n",
      "  \n",
      "Result for PytorchTrainable_db41329c:\n",
      "  date: 2021-03-12_14-22-18\n",
      "  done: false\n",
      "  experiment_id: 4c907ffdde284e948c881896191eb211\n",
      "  experiment_tag: 12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 10\n",
      "  lossd: 0.11673440039157867\n",
      "  lossg: 2.9074363708496094\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13557\n",
      "  time_since_restore: 42.369346141815186\n",
      "  time_this_iter_s: 4.298663854598999\n",
      "  time_total_s: 42.369346141815186\n",
      "  timestamp: 1615555338\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: db41329c\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.9/15.6 GiB<br>PopulationBasedTraining: 15 checkpoints, 6 perturbs<br>Resources requested: 8/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 15/16 (7 ERROR, 8 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>RUNNING </td><td>10.1.2.198:12691</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755</td><td style=\"text-align: right;\"> 5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>RUNNING </td><td>10.1.2.198:13556</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.9279</td><td style=\"text-align: right;\">0.0228801</td><td style=\"text-align: right;\"> 4.91183   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         38.7085</td><td style=\"text-align: right;\">9.70334  </td><td style=\"text-align: right;\">11.4652    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         41.238 </td><td style=\"text-align: right;\">4.8706   </td><td style=\"text-align: right;\"> 0.0189517 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         42.3693</td><td style=\"text-align: right;\">2.90744  </td><td style=\"text-align: right;\"> 0.116734  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         28.0113</td><td style=\"text-align: right;\">0.506983 </td><td style=\"text-align: right;\"> 1.61785   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         23.5924</td><td style=\"text-align: right;\">0.0141164</td><td style=\"text-align: right;\"> 5.35884   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         28.0217</td><td style=\"text-align: right;\">7.34213  </td><td style=\"text-align: right;\"> 0.00165962</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408 </td><td style=\"text-align: right;\"> 1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418  </td><td style=\"text-align: right;\"> 1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224  </td><td style=\"text-align: right;\"> 0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088 </td><td style=\"text-align: right;\"> 1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798 </td><td style=\"text-align: right;\"> 2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925  </td><td style=\"text-align: right;\"> 0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612 </td><td style=\"text-align: right;\"> 1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 7<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_e26f648a:\n",
      "  date: 2021-03-12_14-22-18\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 5.637854099273682\n",
      "  lossg: 0.010978435166180134\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13927\n",
      "  time_since_restore: 28.036757707595825\n",
      "  time_this_iter_s: 4.444396495819092\n",
      "  time_total_s: 28.036757707595825\n",
      "  timestamp: 1615555338\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: e26f648a\n",
      "  \n",
      "Result for PytorchTrainable_d9b862b0:\n",
      "  date: 2021-03-12_14-22-18\n",
      "  done: false\n",
      "  experiment_id: f7510209a74545e49257002e27831187\n",
      "  experiment_tag: 10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 10\n",
      "  lossd: 0.10923776030540466\n",
      "  lossg: 4.273314476013184\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13551\n",
      "  time_since_restore: 43.88936805725098\n",
      "  time_this_iter_s: 5.180856943130493\n",
      "  time_total_s: 43.88936805725098\n",
      "  timestamp: 1615555338\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d9b862b0\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:21,202\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_c27a58f6 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:21,307\tERROR trial_runner.py:793 -- Trial PytorchTrainable_c27a58f6: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_d97e8e96:\n",
      "  date: 2021-03-12_14-22-21\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694@perturbed[netD_B=1.004,netD_lr=6.2703,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 2\n",
      "  lossd: 5.218503952026367\n",
      "  lossg: 0.016783788800239563\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13556\n",
      "  time_since_restore: 8.05648946762085\n",
      "  time_this_iter_s: 4.384160041809082\n",
      "  time_total_s: 20.312026977539062\n",
      "  timestamp: 1615555341\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d97e8e96\n",
      "  \n",
      "Result for PytorchTrainable_da6addc8:\n",
      "  date: 2021-03-12_14-22-21\n",
      "  done: false\n",
      "  experiment_id: 8393d5f89d5b4966984e3dac2920474c\n",
      "  experiment_tag: 11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 11\n",
      "  lossd: 0.014940857887268066\n",
      "  lossg: 5.05705451965332\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13555\n",
      "  time_since_restore: 45.82567524909973\n",
      "  time_this_iter_s: 4.587710857391357\n",
      "  time_total_s: 45.82567524909973\n",
      "  timestamp: 1615555341\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: da6addc8\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:26,040\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_d97e8e96 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:26,134\tERROR trial_runner.py:793 -- Trial PytorchTrainable_d97e8e96: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.8/15.6 GiB<br>PopulationBasedTraining: 15 checkpoints, 6 perturbs<br>Resources requested: 7/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (9 ERROR, 7 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>RUNNING </td><td>10.1.2.198:13551</td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326  </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>RUNNING </td><td>10.1.2.198:13555</td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705  </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>RUNNING </td><td>10.1.2.198:13557</td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266  </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.0805</td><td style=\"text-align: right;\">0.503384 </td><td style=\"text-align: right;\">1.6785    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.8312</td><td style=\"text-align: right;\">0.0109247</td><td style=\"text-align: right;\">5.6378    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         31.9744</td><td style=\"text-align: right;\">7.48152  </td><td style=\"text-align: right;\">0.00134932</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>                </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408 </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418  </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224  </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088 </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798 </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925  </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612 </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755</td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838</td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 9<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt  </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:26,285\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_da6addc8 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_e241e8fc:\n",
      "  date: 2021-03-12_14-22-26\n",
      "  done: false\n",
      "  experiment_id: 057eabed80dd48e589303d025f84acc3\n",
      "  experiment_tag: 13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 1.69356369972229\n",
      "  lossg: 0.4843765199184418\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13922\n",
      "  time_since_restore: 36.42336344718933\n",
      "  time_this_iter_s: 4.342870473861694\n",
      "  time_total_s: 36.42336344718933\n",
      "  timestamp: 1615555346\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: e241e8fc\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:26,448\tERROR trial_runner.py:793 -- Trial PytorchTrainable_da6addc8: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "2021-03-12 14:22:26,483\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_db41329c (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:26,660\tERROR trial_runner.py:793 -- Trial PytorchTrainable_db41329c: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-26\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 0.0011189746437594295\n",
      "  lossg: 7.649582862854004\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 36.610156297683716\n",
      "  time_this_iter_s: 4.635709524154663\n",
      "  time_total_s: 36.610156297683716\n",
      "  timestamp: 1615555346\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: e2d5a448\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:27,808\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_d9b862b0 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_e26f648a:\n",
      "  date: 2021-03-12_14-22-27\n",
      "  done: false\n",
      "  experiment_id: b08eceabf288424484cdd5663158456a\n",
      "  experiment_tag: 14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 9\n",
      "  lossd: 5.8535990715026855\n",
      "  lossg: 0.008747009560465813\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13927\n",
      "  time_since_restore: 37.178669929504395\n",
      "  time_this_iter_s: 4.347507476806641\n",
      "  time_total_s: 37.178669929504395\n",
      "  timestamp: 1615555347\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: e26f648a\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:27,899\tERROR trial_runner.py:793 -- Trial PytorchTrainable_d9b862b0: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\u001b[2m\u001b[36m(pid=14742)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning:Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "\u001b[2m\u001b[36m(pid=14742)\u001b[0m  /home/antoine/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:254: UserWarning:Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-22-30\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 1\n",
      "  lossd: 0.5016739964485168\n",
      "  lossg: 1.5727561712265015\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 2.4025769233703613\n",
      "  time_this_iter_s: 2.4025769233703613\n",
      "  time_total_s: 2.4025769233703613\n",
      "  timestamp: 1615555350\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: f9d8bbda\n",
      "  \n",
      "Result for PytorchTrainable_e241e8fc:\n",
      "  date: 2021-03-12_14-22-31\n",
      "  done: false\n",
      "  experiment_id: 057eabed80dd48e589303d025f84acc3\n",
      "  experiment_tag: 13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 11\n",
      "  lossd: 1.6207833290100098\n",
      "  lossg: 0.49115249514579773\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13922\n",
      "  time_since_restore: 41.5073447227478\n",
      "  time_this_iter_s: 2.178675413131714\n",
      "  time_total_s: 41.5073447227478\n",
      "  timestamp: 1615555351\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: e241e8fc\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.8/15.6 GiB<br>PopulationBasedTraining: 16 checkpoints, 6 perturbs<br>Resources requested: 4/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (12 ERROR, 4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>RUNNING </td><td>10.1.2.198:13922</td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        41.5073 </td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>RUNNING </td><td>10.1.2.198:13927</td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        39.6883 </td><td style=\"text-align: right;\">0.00773388</td><td style=\"text-align: right;\">5.93983    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        39.3999 </td><td style=\"text-align: right;\">7.95041   </td><td style=\"text-align: right;\">0.000845567</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.40258</td><td style=\"text-align: right;\">1.57276   </td><td style=\"text-align: right;\">0.501674   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        21.5754 </td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        20.312  </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        48.2084 </td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.8257 </td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        46.3257 </td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 12<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-32\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 11\n",
      "  lossd: 0.0008588670752942562\n",
      "  lossg: 7.916140556335449\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 41.75971341133118\n",
      "  time_this_iter_s: 2.359861373901367\n",
      "  time_total_s: 41.75971341133118\n",
      "  timestamp: 1615555352\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: e2d5a448\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:33,692\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_e241e8fc (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:33,779\tERROR trial_runner.py:793 -- Trial PytorchTrainable_e241e8fc: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "2021-03-12 14:22:34,691\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_e2d5a448 (score 1.0000000000000004) -> PytorchTrainable_e26f648a (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:34,734\tERROR trial_runner.py:793 -- Trial PytorchTrainable_e26f648a: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-22-36\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 4\n",
      "  lossd: 0.0565372034907341\n",
      "  lossg: 3.683284282684326\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 8.587267875671387\n",
      "  time_this_iter_s: 1.7313778400421143\n",
      "  time_total_s: 8.587267875671387\n",
      "  timestamp: 1615555356\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.2/15.6 GiB<br>PopulationBasedTraining: 18 checkpoints, 6 perturbs<br>Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (14 ERROR, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">      lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.920955</td><td style=\"text-align: right;\">  3.0581 </td><td style=\"text-align: right;\">0.812347</td><td style=\"text-align: right;\">  6.9501 </td><td style=\"text-align: right;\">        5.07534</td><td style=\"text-align: right;\">        5.57334</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        45.7241 </td><td style=\"text-align: right;\">8.25362   </td><td style=\"text-align: right;\">0.000673104</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         8.58727</td><td style=\"text-align: right;\">3.68328   </td><td style=\"text-align: right;\">0.0565372  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        21.5754 </td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        20.312  </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185     </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        48.2084 </td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.8257 </td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        46.3257 </td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        41.5073 </td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        42.0622 </td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 14<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt  </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-37\n",
      "  done: false\n",
      "  experiment_id: 21082ec2dc564765b6c989bb19d2638e\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 14\n",
      "  lossd: 0.000456801411928609\n",
      "  lossg: 8.4677734375\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 47.409807443618774\n",
      "  time_this_iter_s: 1.6857292652130127\n",
      "  time_total_s: 47.409807443618774\n",
      "  timestamp: 1615555357\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: e2d5a448\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:39,682\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_f9d8bbda (score 1.0000000000000004) -> PytorchTrainable_e2d5a448 (score 1.0000000000000004)\n",
      "2021-03-12 14:22:39,709\tINFO pbt.py:545 -- [explore] perturbed config from {'netG_lr': 6.033969441280953, 'netD_lr': 4.0878502473844405, 'netD_B': 0.0843720200185647, 'weight_decay1': 4.557307214836912, 'weight_decay2': 4.584954206540125} -> {'netG_lr': 6.033969441280953, 'netD_lr': 4.0878502473844405, 'netD_B': 0.0843720200185647, 'weight_decay1': 4.557307214836912, 'weight_decay2': 4.584954206540125}\n",
      "\u001b[2m\u001b[36m(pid=13925)\u001b[0m 2021-03-12 14:22:39,746\tINFO trainable.py:482 -- Restored on 10.1.2.198 from checkpoint: /home/antoine/ray_results/2021-03-12_14-22-3914rxs6hs/tmpj_tc982wrestore_from_object/./\n",
      "\u001b[2m\u001b[36m(pid=13925)\u001b[0m 2021-03-12 14:22:39,746\tINFO trainable.py:489 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 6.8558900356292725, '_episodes_total': None}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 7.2/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 2/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (14 ERROR, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>RUNNING </td><td>10.1.2.198:13925</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         9.31146</td><td style=\"text-align: right;\">3.69574   </td><td style=\"text-align: right;\">0.0669836 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        12.1586 </td><td style=\"text-align: right;\">4.08657   </td><td style=\"text-align: right;\">0.0377918 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        19.0173 </td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        18.9261 </td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        33.3747 </td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        32.7041 </td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.3075 </td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5197 </td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.5906 </td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        21.5754 </td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        20.312  </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        48.2084 </td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        45.8257 </td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        46.3257 </td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        41.5073 </td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">        42.0622 </td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 14<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt    </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt  </td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-22-42\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 7\n",
      "  lossd: 0.028402406722307205\n",
      "  lossg: 4.380671977996826\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 14.636997699737549\n",
      "  time_this_iter_s: 2.4784343242645264\n",
      "  time_total_s: 14.636997699737549\n",
      "  timestamp: 1615555362\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: f9d8bbda\n",
      "  \n",
      "Result for PytorchTrainable_e2d5a448:\n",
      "  date: 2021-03-12_14-22-43\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733@perturbed[netD_B=0.084372,netD_lr=4.0879,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585]\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 2\n",
      "  lossd: 0.04361388087272644\n",
      "  lossg: 3.9717350006103516\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 13925\n",
      "  time_since_restore: 3.8771119117736816\n",
      "  time_this_iter_s: 1.4215402603149414\n",
      "  time_total_s: 10.733001947402954\n",
      "  timestamp: 1615555363\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: e2d5a448\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 14:22:45,178\tINFO pbt.py:530 -- [exploit] transferring weights from trial PytorchTrainable_f9d8bbda (score 1.0000000000000004) -> PytorchTrainable_e2d5a448 (score 1.0000000000000004)\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py:83: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "2021-03-12 14:22:45,218\tERROR trial_runner.py:793 -- Trial PytorchTrainable_e2d5a448: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 755, in _process_trial\n",
      "    self, trial, flat_result)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 387, in on_trial_result\n",
      "    lower_quantile)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 479, in _perturb_trial\n",
      "    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pbt.py\", line 532, in _exploit\n",
      "    new_config = self._get_new_config(trial, trial_to_clone)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 357, in _get_new_config\n",
      "    trial_to_clone.config)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 174, in explore\n",
      "    X, y, current, newpoint, bounds, num_f=len(t_r.columns))\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2.py\", line 83, in select_config\n",
      "    m = GPy.models.GPRegression(X, y, kernel)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/parameterized.py\", line 58, in __call__\n",
      "    self.initialize_parameter()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 337, in initialize_parameter\n",
      "    self.trigger_update()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/updateable.py\", line 79, in trigger_update\n",
      "    self._trigger_params_changed(trigger_parent)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 134, in _trigger_params_changed\n",
      "    self.notify_observers(None, None if trigger_parent else -np.inf)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in notify_observers\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/observable.py\", line 91, in <listcomp>\n",
      "    [callble(self, which=which) for _, _, callble in self.observers]\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/paramz/core/parameter_core.py\", line 508, in _parameters_changed_notification\n",
      "    self.parameters_changed()\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/core/gp.py\", line 267, in parameters_changed\n",
      "    self.posterior, self._log_marginal_likelihood, self.grad_dict = self.inference_method.inference(self.kern, self.X, self.likelihood, self.Y_normalized, self.mean_function, self.Y_metadata)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.py\", line 53, in inference\n",
      "    K = kern.K(X)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/GPy/kern/src/kernel_slice_operations.py\", line 110, in wrap\n",
      "    ret = f(self, s.X, s.X2, *a, **kw)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/ray/tune/schedulers/pb2_utils.py\", line 49, in K\n",
      "    -np.square(euclidean_distances(X, X2)) / self.lengthscale)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 224, in euclidean_distances\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 573, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/antoine/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n",
      "    raise ValueError(msg_err.format(type_err, X.dtype))\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-22-48\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 11\n",
      "  lossd: 0.01769445836544037\n",
      "  lossg: 4.879393100738525\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 20.156265020370483\n",
      "  time_this_iter_s: 1.2506463527679443\n",
      "  time_total_s: 20.156265020370483\n",
      "  timestamp: 1615555368\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (15 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         20.1563</td><td style=\"text-align: right;\">4.87939   </td><td style=\"text-align: right;\">0.0176945 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.5073</td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.0622</td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\">3.97174   </td><td style=\"text-align: right;\">0.0436139 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 15<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt      </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e2d5a448_15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733_2021-03-12_14-21-42/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-22-53\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 15\n",
      "  lossd: 0.010388880968093872\n",
      "  lossg: 5.341435432434082\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 25.23275876045227\n",
      "  time_this_iter_s: 1.250870943069458\n",
      "  time_total_s: 25.23275876045227\n",
      "  timestamp: 1615555373\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 15\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (15 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         25.2328</td><td style=\"text-align: right;\">5.34144   </td><td style=\"text-align: right;\">0.0103889 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.5073</td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.0622</td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\">3.97174   </td><td style=\"text-align: right;\">0.0436139 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 15<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt      </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e2d5a448_15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733_2021-03-12_14-21-42/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-22-58\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 19\n",
      "  lossd: 0.008392575196921825\n",
      "  lossg: 5.517648220062256\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 30.440569400787354\n",
      "  time_this_iter_s: 1.3086843490600586\n",
      "  time_total_s: 30.440569400787354\n",
      "  timestamp: 1615555378\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 19\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (15 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         30.4406</td><td style=\"text-align: right;\">5.51765   </td><td style=\"text-align: right;\">0.00839258</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.5073</td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.0622</td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\">3.97174   </td><td style=\"text-align: right;\">0.0436139 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 15<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt      </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e2d5a448_15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733_2021-03-12_14-21-42/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-23-04\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 23\n",
      "  lossd: 0.005966068245470524\n",
      "  lossg: 5.839381694793701\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 36.20836019515991\n",
      "  time_this_iter_s: 1.2080373764038086\n",
      "  time_total_s: 36.20836019515991\n",
      "  timestamp: 1615555384\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 23\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (15 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         36.2084</td><td style=\"text-align: right;\">5.83938   </td><td style=\"text-align: right;\">0.00596607</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.5073</td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.0622</td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\">3.97174   </td><td style=\"text-align: right;\">0.0436139 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 15<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt      </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e2d5a448_15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733_2021-03-12_14-21-42/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-23-11\n",
      "  done: false\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 27\n",
      "  lossd: 0.005663279443979263\n",
      "  lossg: 6.019207000732422\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 43.0130558013916\n",
      "  time_this_iter_s: 2.149265766143799\n",
      "  time_total_s: 43.0130558013916\n",
      "  timestamp: 1615555391\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 27\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (15 ERROR, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>RUNNING </td><td>10.1.2.198:14742</td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         43.0131</td><td style=\"text-align: right;\">6.01921   </td><td style=\"text-align: right;\">0.00566328</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.5073</td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.0622</td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>ERROR   </td><td>                </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\">3.97174   </td><td style=\"text-align: right;\">0.0436139 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 15<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt      </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e2d5a448_15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733_2021-03-12_14-21-42/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PytorchTrainable_f9d8bbda:\n",
      "  date: 2021-03-12_14-23-15\n",
      "  done: true\n",
      "  experiment_id: 2b859fb4ac41446ab1a1e0f6a7ace33c\n",
      "  experiment_tag: 16_netD_B=0.084372,netD_lr=4.0879,netG_B=0.91287,netG_lr=6.034,weight_decay1=4.5573,weight_decay2=4.585\n",
      "  hostname: antoine-HP-Spectre-Laptop-13-af0xx\n",
      "  is_score: 1.0000000000000004\n",
      "  iterations_since_restore: 30\n",
      "  lossd: 0.005500889848917723\n",
      "  lossg: 6.074499607086182\n",
      "  node_ip: 10.1.2.198\n",
      "  pid: 14742\n",
      "  time_since_restore: 46.720534801483154\n",
      "  time_this_iter_s: 1.2115044593811035\n",
      "  time_total_s: 46.720534801483154\n",
      "  timestamp: 1615555395\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 30\n",
      "  trial_id: f9d8bbda\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>PopulationBasedTraining: 19 checkpoints, 7 perturbs<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.2 GiB heap, 0.0/2.15 GiB objects<br>Current best trial: c2551280 with is_score=1.0000000000000004 and parameters={'netG_lr': 6.298524811005323, 'netD_lr': 7.796861221429467, 'netG_B': 1.3594163050527683, 'netD_B': 1.045031571819214, 'weight_decay1': 7.5880087108218754, 'weight_decay2': 6.428297544146549}<br>Result logdir: /home/antoine/ray_results/random<br>Number of trials: 16/16 (15 ERROR, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  netD_B</th><th style=\"text-align: right;\">  netD_lr</th><th style=\"text-align: right;\">  netG_B</th><th style=\"text-align: right;\">  netG_lr</th><th style=\"text-align: right;\">  weight_decay1</th><th style=\"text-align: right;\">  weight_decay2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     lossg</th><th style=\"text-align: right;\">     lossd</th><th style=\"text-align: right;\">  is_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_f9d8bbda</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         46.7205</td><td style=\"text-align: right;\">6.0745    </td><td style=\"text-align: right;\">0.00550089</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         19.0173</td><td style=\"text-align: right;\">0.789408  </td><td style=\"text-align: right;\">1.6445    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         18.9261</td><td style=\"text-align: right;\">0.78418   </td><td style=\"text-align: right;\">1.6213    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">0.956785</td><td style=\"text-align: right;\">  2.53445</td><td style=\"text-align: right;\">0.953325</td><td style=\"text-align: right;\">  4.72262</td><td style=\"text-align: right;\">        6.4508 </td><td style=\"text-align: right;\">        5.73415</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         33.3747</td><td style=\"text-align: right;\">8.94224   </td><td style=\"text-align: right;\">0.00106892</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.20648 </td><td style=\"text-align: right;\">  7.14941</td><td style=\"text-align: right;\">0.644432</td><td style=\"text-align: right;\">  5.30553</td><td style=\"text-align: right;\">        5.86367</td><td style=\"text-align: right;\">        5.1391 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         32.7041</td><td style=\"text-align: right;\">0.616088  </td><td style=\"text-align: right;\">1.48325   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.14477 </td><td style=\"text-align: right;\">  4.66077</td><td style=\"text-align: right;\">0.600882</td><td style=\"text-align: right;\">  3.64255</td><td style=\"text-align: right;\">        6.05619</td><td style=\"text-align: right;\">        6.49979</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.3075</td><td style=\"text-align: right;\">0.180798  </td><td style=\"text-align: right;\">2.50897   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">0.846731</td><td style=\"text-align: right;\">  4.60001</td><td style=\"text-align: right;\">1.4341  </td><td style=\"text-align: right;\">  4.48102</td><td style=\"text-align: right;\">        6.86691</td><td style=\"text-align: right;\">        5.59992</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5197</td><td style=\"text-align: right;\">1.01925   </td><td style=\"text-align: right;\">0.690928  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.04503 </td><td style=\"text-align: right;\">  7.79686</td><td style=\"text-align: right;\">1.35942 </td><td style=\"text-align: right;\">  6.29852</td><td style=\"text-align: right;\">        7.58801</td><td style=\"text-align: right;\">        6.4283 </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.5906</td><td style=\"text-align: right;\">0.830612  </td><td style=\"text-align: right;\">1.62145   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.5754</td><td style=\"text-align: right;\">0.0163755 </td><td style=\"text-align: right;\">5.28184   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         20.312 </td><td style=\"text-align: right;\">0.0167838 </td><td style=\"text-align: right;\">5.2185    </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">0.541607</td><td style=\"text-align: right;\">  3.28412</td><td style=\"text-align: right;\">1.1722  </td><td style=\"text-align: right;\">  4.0627 </td><td style=\"text-align: right;\">        6.11939</td><td style=\"text-align: right;\">        5.49429</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.2084</td><td style=\"text-align: right;\">4.51326   </td><td style=\"text-align: right;\">0.122205  </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">0.358363</td><td style=\"text-align: right;\">  3.88791</td><td style=\"text-align: right;\">1.02776 </td><td style=\"text-align: right;\">  6.1497 </td><td style=\"text-align: right;\">        5.68238</td><td style=\"text-align: right;\">        6.20321</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         45.8257</td><td style=\"text-align: right;\">5.05705   </td><td style=\"text-align: right;\">0.0149409 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.37888 </td><td style=\"text-align: right;\">  4.46429</td><td style=\"text-align: right;\">0.857893</td><td style=\"text-align: right;\">  8.36876</td><td style=\"text-align: right;\">        4.7915 </td><td style=\"text-align: right;\">        4.71379</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3257</td><td style=\"text-align: right;\">3.11266   </td><td style=\"text-align: right;\">0.0913595 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.31538 </td><td style=\"text-align: right;\">  7.58605</td><td style=\"text-align: right;\">0.919551</td><td style=\"text-align: right;\">  5.79432</td><td style=\"text-align: right;\">        5.63923</td><td style=\"text-align: right;\">        5.48734</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.5073</td><td style=\"text-align: right;\">0.491152  </td><td style=\"text-align: right;\">1.62078   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">1.00403 </td><td style=\"text-align: right;\">  6.27028</td><td style=\"text-align: right;\">1.2544  </td><td style=\"text-align: right;\">  3.46235</td><td style=\"text-align: right;\">        6.68186</td><td style=\"text-align: right;\">        4.95232</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.0622</td><td style=\"text-align: right;\">0.00717643</td><td style=\"text-align: right;\">6.06011   </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td>ERROR     </td><td>     </td><td style=\"text-align: right;\">0.084372</td><td style=\"text-align: right;\">  4.08785</td><td style=\"text-align: right;\">0.912872</td><td style=\"text-align: right;\">  6.03397</td><td style=\"text-align: right;\">        4.55731</td><td style=\"text-align: right;\">        4.58495</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         10.733 </td><td style=\"text-align: right;\">3.97174   </td><td style=\"text-align: right;\">0.0436139 </td><td style=\"text-align: right;\">         1</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 15<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PytorchTrainable_c2551280</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c2551280_1_netD_B=0.25562,netD_lr=1.5025,netG_B=0.77397,netG_lr=6.0386,weight_decay1=4.5524,weight_decay2=5.155_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c25fa8bc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c25fa8bc_2_netD_B=0.76543,netD_lr=5.1371,netG_B=0.97797,netG_lr=4.1861,weight_decay1=7.0892,weight_decay2=5.104_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c262ef68</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c262ef68_3_netD_B=0.95679,netD_lr=2.5345,netG_B=0.95332,netG_lr=4.7226,weight_decay1=6.4508,weight_decay2=5.7342_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_c265fbd6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c265fbd6_4_netD_B=1.2065,netD_lr=7.1494,netG_B=0.64443,netG_lr=5.3055,weight_decay1=5.8637,weight_decay2=5.1391_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c269dd1e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c269dd1e_5_netD_B=1.1448,netD_lr=4.6608,netG_B=0.60088,netG_lr=3.6426,weight_decay1=6.0562,weight_decay2=6.4998_2021-03-12_14-20-48/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_c26d0d54</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c26d0d54_6_netD_B=0.84673,netD_lr=4.6,netG_B=1.4341,netG_lr=4.481,weight_decay1=6.8669,weight_decay2=5.5999_2021-03-12_14-20-48/error.txt      </td></tr>\n",
       "<tr><td>PytorchTrainable_c270956e</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c270956e_7_netD_B=1.045,netD_lr=7.7969,netG_B=1.3594,netG_lr=6.2985,weight_decay1=7.588,weight_decay2=6.4283_2021-03-12_14-20-48/error.txt     </td></tr>\n",
       "<tr><td>PytorchTrainable_c27a58f6</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_c27a58f6_8_netD_B=0.83391,netD_lr=6.1357,netG_B=0.96143,netG_lr=2.4629,weight_decay1=5.6015,weight_decay2=5.2504_2021-03-12_14-20-48/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_d97e8e96</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d97e8e96_9_netD_B=0.86799,netD_lr=5.9917,netG_B=1.2842,netG_lr=4.8651,weight_decay1=6.545,weight_decay2=6.1694_2021-03-12_14-21-27/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_d9b862b0</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_d9b862b0_10_netD_B=0.54161,netD_lr=3.2841,netG_B=1.1722,netG_lr=4.0627,weight_decay1=6.1194,weight_decay2=5.4943_2021-03-12_14-21-27/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_da6addc8</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_da6addc8_11_netD_B=0.35836,netD_lr=3.8879,netG_B=1.0278,netG_lr=6.1497,weight_decay1=5.6824,weight_decay2=6.2032_2021-03-12_14-21-28/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_db41329c</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_db41329c_12_netD_B=1.3789,netD_lr=4.4643,netG_B=0.85789,netG_lr=8.3688,weight_decay1=4.7915,weight_decay2=4.7138_2021-03-12_14-21-30/error.txt </td></tr>\n",
       "<tr><td>PytorchTrainable_e241e8fc</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e241e8fc_13_netD_B=1.3154,netD_lr=7.586,netG_B=0.91955,netG_lr=5.7943,weight_decay1=5.6392,weight_decay2=5.4873_2021-03-12_14-21-41/error.txt  </td></tr>\n",
       "<tr><td>PytorchTrainable_e26f648a</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e26f648a_14_netD_B=1.004,netD_lr=6.2703,netG_B=1.2544,netG_lr=3.4623,weight_decay1=6.6819,weight_decay2=4.9523_2021-03-12_14-21-42/error.txt   </td></tr>\n",
       "<tr><td>PytorchTrainable_e2d5a448</td><td style=\"text-align: right;\">           1</td><td>/home/antoine/ray_results/random/PytorchTrainable_e2d5a448_15_netD_B=0.92096,netD_lr=3.0581,netG_B=0.81235,netG_lr=6.9501,weight_decay1=5.0753,weight_decay2=5.5733_2021-03-12_14-21-42/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PytorchTrainable_c2551280, PytorchTrainable_c25fa8bc, PytorchTrainable_c262ef68, PytorchTrainable_c265fbd6, PytorchTrainable_c269dd1e, PytorchTrainable_c26d0d54, PytorchTrainable_c270956e, PytorchTrainable_c27a58f6, PytorchTrainable_d97e8e96, PytorchTrainable_d9b862b0, PytorchTrainable_da6addc8, PytorchTrainable_db41329c, PytorchTrainable_e241e8fc, PytorchTrainable_e26f648a, PytorchTrainable_e2d5a448])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cedbcdb6e345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mGAN_MNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-92272273d8e5>\u001b[0m in \u001b[0;36mGAN_MNIST\u001b[0;34m(SA)\u001b[0m\n\u001b[1;32m    623\u001b[0m         },        metric=\"is_score\",\n\u001b[1;32m    624\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m              ,     loggers=[TestLogger])\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mall_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PytorchTrainable_c2551280, PytorchTrainable_c25fa8bc, PytorchTrainable_c262ef68, PytorchTrainable_c265fbd6, PytorchTrainable_c269dd1e, PytorchTrainable_c26d0d54, PytorchTrainable_c270956e, PytorchTrainable_c27a58f6, PytorchTrainable_d97e8e96, PytorchTrainable_d9b862b0, PytorchTrainable_da6addc8, PytorchTrainable_db41329c, PytorchTrainable_e241e8fc, PytorchTrainable_e26f648a, PytorchTrainable_e2d5a448])"
     ]
    }
   ],
   "source": [
    "from ray.tune.logger import *\n",
    "supernombre=\"PB2TRAN\";\n",
    "class TestLogger(tune.logger.Logger):\n",
    "    def _init(self):\n",
    "        progress_file = os.path.join(\"/home/antoine/Projet/NovelTuning/\", supernombre+\"com.csv\")\n",
    "        self._continuing = os.path.exists(progress_file)\n",
    "        self._file = open(progress_file, \"a\")\n",
    "        self._csv_out = None\n",
    "    def on_result(self, result):\n",
    "        tmp = result.copy()\n",
    "        #if \"done\" in tmp:\n",
    "         #   if(tmp[\"done\"] != True):\n",
    "\n",
    "        if \"config\" in tmp:\n",
    "            del tmp[\"config\"]\n",
    "        result = flatten_dict(tmp, delimiter=\"/\")\n",
    "        if self._csv_out is None:\n",
    "            self._csv_out = csv.DictWriter(self._file, result.keys())\n",
    "            if not self._continuing:\n",
    "                self._csv_out.writeheader()\n",
    "        self._csv_out.writerow(\n",
    "            {k: v\n",
    "             for k, v in result.items() if k in self._csv_out.fieldnames})\n",
    "        self._file.flush()\n",
    "                   \n",
    "            \n",
    "GAN_MNIST(5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN THIS MODULE: IMPORTS, CNN, TRAIN, TEST, MNIS_FUNCTION, SPACE\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from ray import tune\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "import time\n",
    "import ray\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "import argparse\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.nevergrad import NevergradSearch\n",
    "import nevergrad as ng\n",
    "import json\n",
    "import os\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.dragonfly import DragonflySearch\n",
    "from ray.tune.suggest.zoopt import ZOOptSearch\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from zoopt import ValueType\n",
    "import torch\n",
    "# IN THIS MODULE: IMPORTS, CNN, TRAIN, TEST, MNIS_FUNCTION, SPACE\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler \n",
    "from ray.tune.schedulers import MedianStoppingRule\n",
    "\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from ray import tune\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "import time\n",
    "import ray\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "import argparse\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.nevergrad import NevergradSearch\n",
    "import nevergrad as ng\n",
    "import json\n",
    "import os\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "#from ray.tune.suggest.dragonfly import DragonflySearch\n",
    "from ray.tune.suggest.zoopt import ZOOptSearch\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from zoopt import ValueType\n",
    "import torch\n",
    "import adabelief_pytorch\n",
    "global_checkpoint_period=np.inf\n",
    "\n",
    "import ray\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.trial import ExportFormat\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from filelock import FileLock\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ray.tune.suggest.ax import AxSearch\n",
    "\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Training parameters\n",
    "dataroot = ray.utils.get_user_temp_dir() + os.sep\n",
    "workers = 2\n",
    "batch_size = 64\n",
    "image_size = 32\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 32\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# iterations of actual training in each Trainable _train\n",
    "train_iterations_per_step = 5\n",
    "\n",
    "MODEL_PATH = os.path.expanduser(\"~/.ray/models/mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "def get_data_loader():\n",
    "    dataset = dset.MNIST(\n",
    "        root=dataroot,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, ), (0.5, )),\n",
    "        ]))\n",
    "\n",
    "    # Create the dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# __GANmodel_begin__\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# Generator Code\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# __GANmodel_end__\n",
    "\n",
    "\n",
    "# __INCEPTION_SCORE_begin__\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    LeNet for MNist classification, used for inception_score\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def inception_score(imgs, mnist_model_ref, batch_size=32, splits=1):\n",
    "    N = len(imgs)\n",
    "    dtype = torch.FloatTensor\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "    cm = mnist_model_ref  # Get the mnist model from Ray object store.\n",
    "    up = nn.Upsample(size=(28, 28), mode=\"bilinear\").type(dtype)\n",
    "\n",
    "    def get_pred(x):\n",
    "        x = up(x)\n",
    "        x = cm(x)\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "    preds = np.zeros((N, 10))\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.type(dtype)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "        preds[i * batch_size:i * batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits):(k + 1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "\n",
    "# __INCEPTION_SCORE_end__\n",
    "\n",
    "\n",
    "def train(netD, netG, optimG, optimD, criterion, dataloader, iteration, device,\n",
    "          mnist_model_ref):\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        if i >= train_iterations_per_step:\n",
    "            break\n",
    "\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full(\n",
    "            (b_size, ), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimG.step()\n",
    "\n",
    "        is_score, is_std = inception_score(fake, mnist_model_ref)\n",
    "\n",
    "    return errG.item(), errD.item(), is_score\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "# __Trainable_begin__\n",
    "class PytorchTrainable():\n",
    "    def __init__(self, config):\n",
    "        use_cuda = config.get(\"use_gpu\") and torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.netD = Discriminator().to(self.device)\n",
    "        self.netD.apply(weights_init)\n",
    "        self.netG = Generator().to(self.device)\n",
    "        self.netG.apply(weights_init)\n",
    "        self.criterion = nn.BCELoss()   \n",
    "        self.iteration = 0\n",
    "        self.optimizerD =optim.Adam(\n",
    "            self.netD.parameters(),\n",
    "            lr=10**-(config[\"netD_lr\"]),\n",
    "            betas=(1-10**-(config[\"netD_B\"]), 0.999),\n",
    "            weight_decay=10**-(config[\"weight_decay1\"]))\n",
    "                              \n",
    "        self.optimizerG =optim.Adam(\n",
    "            self.netG.parameters(),\n",
    "            lr=10**-(config[\"netG_lr\"]),\n",
    "            betas=(1-10**-(config[\"netG_B\"]), 0.999),\n",
    "            weight_decay=10**-(config[\"weight_decay2\"]))\n",
    "\n",
    "        with FileLock(os.path.expanduser(\"~/.data.lock\")):\n",
    "            self.dataloader = get_data_loader()\n",
    "        self.mnist_model_ref = mnist_cnn\n",
    "\n",
    "    def step(self):\n",
    "        lossG, lossD, is_score = train(self.netD, self.netG, self.optimizerG,\n",
    "                                       self.optimizerD, self.criterion,\n",
    "                                       self.dataloader, self.iteration,\n",
    "                                       self.device, self.mnist_model_ref)\n",
    "        self.iteration+=1\n",
    "        return is_score #{\"lossg\": lossG, \"lossd\": lossD, \"is_score\": is_score}\n",
    "\n",
    "\n",
    "    def adapt(self, new_config):\n",
    "\n",
    "        temp = copy.deepcopy(self)\n",
    "\n",
    "        if \"netD_lr\" in new_config:\n",
    "            for param_group in temp.optimizerD.param_groups:\n",
    "                param_group[\"lr\"] = 10**-(new_config[\"netD_lr\"])\n",
    "        if \"netG_lr\" in new_config:\n",
    "            for param_group in temp.optimizerG.param_groups:\n",
    "                param_group[\"lr\"] = 10**-(new_config[\"netG_lr\"])\n",
    "        if \"netD_B\" in new_config:\n",
    "            for param_group in temp.optimizerD.param_groups:\n",
    "                param_group[\"betas\"] = (1-10**-(new_config[\"netD_B\"]),0.999)\n",
    "        if \"netG_B\" in new_config:\n",
    "            for param_group in temp.optimizerG.param_groups:\n",
    "                param_group[\"betas\"] = (1-10**-(new_config[\"netG_B\"]),0.999)\n",
    "        if \"weight_decay1\" in new_config:\n",
    "            for param_group in temp.optimizerD.param_groups:\n",
    "                param_group[\"weight_decay\"] = 10**-(new_config[\"weight_decay1\"])\n",
    "        if \"weight_decay2\" in new_config:\n",
    "            for param_group in temp.optimizerG.param_groups:\n",
    "                param_group[\"weight_decay\"] = 10**-(new_config[\"weight_decay2\"])\n",
    "               \n",
    "\n",
    "        \n",
    "        return temp\n",
    "\n",
    "        #temp = copy.deepcopy(self)\n",
    "        #for key, value in config.items():\n",
    "        #    temp.config[key] = value\n",
    "        #config = temp.config\n",
    "\n",
    "        #temp.model.adapt(config.get(\"droupout_prob\", 0.5))\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\")\n",
    "args, _ = parser.parse_known_args()\n",
    "import urllib.request\n",
    "# Download a pre-trained MNIST model for inception score calculation.\n",
    "# This is a tiny model (<100kb).\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"downloading model\")\n",
    "    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://github.com/ray-project/ray/raw/master/python/ray/tune/\"\n",
    "        \"examples/pbt_dcgan_mnist/mnist_cnn.pt\", MODEL_PATH)\n",
    "\n",
    "dataloader = get_data_loader()\n",
    "#if not args.smoke_test:\n",
    "#    plot_images(dataloader)\n",
    "\n",
    "# load the pretrained mnist classification model for inception_score\n",
    "mnist_cnn = Net()\n",
    "mnist_cnn.load_state_dict(torch.load(MODEL_PATH))\n",
    "mnist_cnn.eval()\n",
    "#  mnist_model_ref = ray.put(mnist_cnn)\n",
    "\n",
    "\n",
    "from ray.tune.schedulers.pb2 import PB2\n",
    "\n",
    "scheduler = PB2(\n",
    "time_attr=\"training_iteration\",\n",
    "perturbation_interval=1,\n",
    "hyperparam_bounds={\n",
    "    # distribution for resampling\n",
    "        \"netG_lr\": [1, 9],\n",
    "        \"netD_lr\": [1, 9],\n",
    "        \"netD_B\": [0, 2],\n",
    "        \"netD_B\": [0, 2],\n",
    "        \"weight_decay1\":[3, 8],\n",
    "        \"weight_decay2\":[3, 8]\n",
    "}) \n",
    "\n",
    "#    c={\"mnist_model_ref\" : mnist_model_ref}\n",
    "\n",
    "\n",
    "experiment_metrics= dict(metric=\"is_score\",\n",
    "    mode=\"max\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Parent():\n",
    "    def __init__(self,hyperspace,configuration, model, loss):\n",
    "        \n",
    "        self.hyperspace = hyperspace\n",
    "        self.configuration_list = [configuration] \n",
    "        self.loss_list = [np.array(loss)] \n",
    "        self.model = model\n",
    "    \n",
    "    def update(self,configuration,loss, model):\n",
    "        self.configuration_list = np.append(self.configuration_list,configuration) \n",
    "        self.loss_list = np.append(self.loss_list,loss)\n",
    "        self.model = model\n",
    "    \n",
    "    def get_hyperspace(self):\n",
    "        return self.hyperspace\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.loss_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 0.0                                          \n",
      "netD_B 0.38660832249559474                             \n",
      "netD_lr 7.298388096483894                              \n",
      "netG_B 0.9670771214934172                              \n",
      "netG_lr 7.418760770463007                              \n",
      "weight_decay1 7.501755958563166                        \n",
      "weight_decay2 7.265052676447382                        \n",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476258960 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476258960 released on /home/antoine/.data.lock\n",
      "/home/antoine/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:253: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                           \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 0.1262179566553448                                                         \n",
      "netD_lr 8.141507488515586                                                         \n",
      "netG_B 0.6421548035772979                                                         \n",
      "netG_lr 8.109210702932003                                                         \n",
      "weight_decay1 7.973881950921562                                                   \n",
      "weight_decay2 7.973096699893967                                                   \n",
      "  1%|          | 1/100 [00:03<05:50,  3.54s/trial, best loss: -1.0000000000000029]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444033663888 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444033663888 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.3668860716115905                                                         \n",
      "netD_lr 2.736955021175844                                                         \n",
      "netG_B 2.9816843007040053                                                         \n",
      "netG_lr 1.9051212964182231                                                        \n",
      "weight_decay1 4.127874782947522                                                   \n",
      "weight_decay2 4.436464217436043                                                   \n",
      "  2%|▏         | 2/100 [00:07<05:51,  3.58s/trial, best loss: -1.0000000000000029]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140445569874256 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140445569874256 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0005577396163474                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.9724404002197637                                                         \n",
      "netD_lr 1.0527768581510557                                                        \n",
      "netG_B 2.9863716653952572                                                         \n",
      "netG_lr 1.1256785903000315                                                        \n",
      "weight_decay1 3.5060613136169225                                                  \n",
      "weight_decay2 3.0083488829973186                                                  \n",
      "  3%|▎         | 3/100 [00:11<05:57,  3.68s/trial, best loss: -1.0005577396163474]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444034222480 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444034222480 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.6368339592310663                                                         \n",
      "netD_lr 2.105291572723287                                                         \n",
      "netG_B 2.995809721671326                                                          \n",
      "netG_lr 1.3266805319453163                                                        \n",
      "weight_decay1 3.1312994416415743                                                  \n",
      "weight_decay2 3.941118972825944                                                   \n",
      "  4%|▍         | 4/100 [00:15<05:57,  3.72s/trial, best loss: -1.0005577396163474]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444032104528 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444032104528 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.234438008608312                                                       \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.5155801095186887                                                        \n",
      "netD_lr 4.460746666017706                                                        \n",
      "netG_B 2.0001696699911444                                                        \n",
      "netG_lr 3.669279771067182                                                        \n",
      "weight_decay1 5.642757728645976                                                  \n",
      "weight_decay2 5.460933855783763                                                  \n",
      "  5%|▌         | 5/100 [00:18<05:56,  3.76s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477745808 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477745808 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                     \n",
      "\n",
      "itération -0.0                                                                   \n",
      "netD_B 2.9821813432991906                                                        \n",
      "netD_lr 1.040370291286409                                                        \n",
      "netG_B 2.015551986692979                                                         \n",
      "netG_lr 5.01194806473                                                            \n",
      "weight_decay1 5.1603885435520525                                                 \n",
      "weight_decay2 3.2446257419393074                                                 \n",
      "  6%|▌         | 6/100 [00:22<05:56,  3.79s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476354768 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476354768 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                     \n",
      "\n",
      "itération 0.0                                                                    \n",
      "netD_B 1.6934406091316796                                                        \n",
      "netD_lr 5.592692860648004                                                        \n",
      "netG_B 2.3950917552336906                                                        \n",
      "netG_lr 3.755388518802472                                                        \n",
      "weight_decay1 3.0535198561445305                                                 \n",
      "weight_decay2 6.387988883033623                                                  \n",
      "  7%|▋         | 7/100 [00:26<05:57,  3.84s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477831440 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477831440 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                     \n",
      "\n",
      "itération 0.0                                                                    \n",
      "netD_B 0.800371298521505                                                         \n",
      "netD_lr 3.2303529941876565                                                       \n",
      "netG_B 1.2504671516112016                                                        \n",
      "netG_lr 6.083070447039642                                                        \n",
      "weight_decay1 6.730048647327445                                                  \n",
      "weight_decay2 4.421111455204064                                                  \n",
      "  8%|▊         | 8/100 [00:30<06:00,  3.92s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477831440 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477831440 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                     \n",
      "\n",
      "itération 0.0                                                                    \n",
      "netD_B 2.3061719067602224                                                        \n",
      "netD_lr 6.196053769264021                                                        \n",
      "netG_B 0.2224187594928888                                                        \n",
      "netG_lr 2.250142346151325                                                        \n",
      "weight_decay1 4.524566709068309                                                  \n",
      "weight_decay2 4.164015331010052                                                  \n",
      "  9%|▉         | 9/100 [00:34<06:03,  4.00s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444032220880 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444032220880 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                     \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.288577684229687                                                          \n",
      "netD_lr 2.4944946010182907                                                        \n",
      "netG_B 2.5569455820323377                                                         \n",
      "netG_lr 1.006871561167224                                                         \n",
      "weight_decay1 6.166680424321567                                                   \n",
      "weight_decay2 5.476326787540509                                                   \n",
      " 10%|█         | 10/100 [00:38<05:59,  3.99s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477830800 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477830800 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.1404788258871057                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.1181654956327818                                                         \n",
      "netD_lr 4.184573747485372                                                         \n",
      "netG_B 1.7710113386451505                                                         \n",
      "netG_lr 3.2041644888424594                                                        \n",
      "weight_decay1 3.038647486162903                                                   \n",
      "weight_decay2 6.57356083986143                                                    \n",
      " 11%|█         | 11/100 [00:42<05:57,  4.01s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443943219600 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443943219600 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.0125318744743983                                                         \n",
      "netD_lr 8.91111168253786                                                          \n",
      "netG_B 2.5421206312209814                                                         \n",
      "netG_lr 6.206359137444812                                                         \n",
      "weight_decay1 4.041959800620269                                                   \n",
      "weight_decay2 3.665604962517058                                                   \n",
      " 12%|█▏        | 12/100 [00:47<05:55,  4.04s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443948546896 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443948546896 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.9498979634142954                                                         \n",
      "netD_lr 1.7018050033102439                                                        \n",
      "netG_B 0.13602083502487927                                                        \n",
      "netG_lr 8.919739434804452                                                         \n",
      "weight_decay1 4.893860550310924                                                   \n",
      "weight_decay2 5.090845730986002                                                   \n",
      " 13%|█▎        | 13/100 [00:51<05:54,  4.07s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443948547792 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443948547792 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.091393350448568                                                          \n",
      "netD_lr 3.7502575966611515                                                        \n",
      "netG_B 1.4869537302666564                                                         \n",
      "netG_lr 4.92392862476917                                                          \n",
      "weight_decay1 6.945599667081787                                                   \n",
      "weight_decay2 6.307755595665933                                                   \n",
      " 14%|█▍        | 14/100 [00:55<05:51,  4.09s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476188048 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476188048 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.608024664118214                                                          \n",
      "netD_lr 6.431676166097116                                                         \n",
      "netG_B 2.717509403766733                                                          \n",
      "netG_lr 2.3937860626044176                                                        \n",
      "weight_decay1 3.6472099354126124                                                  \n",
      "weight_decay2 3.6681422417880305                                                  \n",
      " 15%|█▌        | 15/100 [00:59<05:51,  4.13s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476183952 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476183952 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0004925319791722                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.8501489290961937                                                         \n",
      "netD_lr 1.915250793321103                                                         \n",
      "netG_B 2.1781662106921003                                                         \n",
      "netG_lr 4.764645021650071                                                         \n",
      "weight_decay1 5.680241730103614                                                   \n",
      "weight_decay2 7.912916548182512                                                   \n",
      " 16%|█▌        | 16/100 [01:06<07:00,  5.01s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443946478160 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443946478160 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.6097872720768613                                                         \n",
      "netD_lr 2.2275283553092624                                                        \n",
      "netG_B 2.8230624665604758                                                         \n",
      "netG_lr 1.148778024028775                                                         \n",
      "weight_decay1 6.29108154204669                                                    \n",
      "weight_decay2 5.0641572195941675                                                  \n",
      " 17%|█▋        | 17/100 [01:10<06:32,  4.73s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443946475664 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443946475664 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.150107335640441                                                          \n",
      "netD_lr 2.771592607392502                                                         \n",
      "netG_B 2.3133520336027584                                                         \n",
      "netG_lr 1.050280461157277                                                         \n",
      "weight_decay1 5.946684920312045                                                   \n",
      "weight_decay2 5.810660373724558                                                   \n",
      " 18%|█▊        | 18/100 [01:14<06:12,  4.55s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443942349904 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443942349904 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0154598884517176                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.676965617124628                                                          \n",
      "netD_lr 1.1881729548583135                                                        \n",
      "netG_B 2.6747264262713912                                                         \n",
      "netG_lr 1.834126899552705                                                         \n",
      "weight_decay1 6.402367076873086                                                   \n",
      "weight_decay2 4.790960223950357                                                   \n",
      " 19%|█▉        | 19/100 [01:19<06:02,  4.48s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443942307792 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443942307792 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.465194223912129                                                          \n",
      "netD_lr 4.809889632065427                                                         \n",
      "netG_B 2.9002212532669898                                                         \n",
      "netG_lr 2.896917113710911                                                         \n",
      "weight_decay1 7.147910629287203                                                   \n",
      "weight_decay2 5.735273134789958                                                   \n",
      " 20%|██        | 20/100 [01:26<06:56,  5.21s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443943447568 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443943447568 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.0377598349694543                                                         \n",
      "netD_lr 3.485707196755571                                                         \n",
      "netG_B 1.7232278067486126                                                         \n",
      "netG_lr 1.1553161927549052                                                        \n",
      "weight_decay1 4.9133082192253665                                                  \n",
      "weight_decay2 3.8282050859947487                                                  \n",
      " 21%|██        | 21/100 [01:30<06:28,  4.92s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443941456208 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443941456208 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0340890235763396                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.743608304851512                                                          \n",
      "netD_lr 2.5814316498799026                                                        \n",
      "netG_B 2.500614783753799                                                          \n",
      "netG_lr 4.083670181292067                                                         \n",
      "weight_decay1 6.240126454494731                                                   \n",
      "weight_decay2 6.8737493278016935                                                  \n",
      " 22%|██▏       | 22/100 [01:34<06:07,  4.71s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477350800 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477350800 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.7574168037994724                                                         \n",
      "netD_lr 1.6068681977683328                                                        \n",
      "netG_B 2.989054449902141                                                          \n",
      "netG_lr 2.8598269264071363                                                        \n",
      "weight_decay1 5.345917106578273                                                   \n",
      "weight_decay2 5.974541105758303                                                   \n",
      " 23%|██▎       | 23/100 [01:38<05:50,  4.56s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443941457232 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443941457232 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.2752703908954746                                                         \n",
      "netD_lr 5.375789715861374                                                         \n",
      "netG_B 2.2170459125621127                                                         \n",
      "netG_lr 1.7718573892022582                                                        \n",
      "weight_decay1 7.620273814664749                                                   \n",
      "weight_decay2 7.368945125786791                                                   \n",
      " 24%|██▍       | 24/100 [01:43<05:38,  4.46s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476392208 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476392208 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0150196755376042                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.232118710503902                                                          \n",
      "netD_lr 3.8008847192294875                                                        \n",
      "netG_B 1.299965779846046                                                          \n",
      "netG_lr 1.5052323182913312                                                        \n",
      "weight_decay1 4.579931841117516                                                   \n",
      "weight_decay2 5.30959252557073                                                    \n",
      " 25%|██▌       | 25/100 [01:47<05:29,  4.40s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477212048 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477212048 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000052344686234                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.7866099170902636                                                         \n",
      "netD_lr 2.280815125767062                                                         \n",
      "netG_B 1.812653143328739                                                          \n",
      "netG_lr 6.301867436479617                                                         \n",
      "weight_decay1 5.964444933871947                                                   \n",
      "weight_decay2 3.171925161120703                                                   \n",
      " 26%|██▌       | 26/100 [01:51<05:20,  4.33s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940497168 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940497168 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.5329094122836149                                                         \n",
      "netD_lr 3.0021676352932465                                                        \n",
      "netG_B 2.6989068581927507                                                         \n",
      "netG_lr 2.5615890917604407                                                        \n",
      "weight_decay1 6.691397638634275                                                   \n",
      "weight_decay2 4.600730480836685                                                   \n",
      " 27%|██▋       | 27/100 [01:55<05:16,  4.33s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940398096 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940398096 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 0.6234891335609265                                                         \n",
      "netD_lr 1.4805289367955288                                                        \n",
      "netG_B 0.728029226105607                                                          \n",
      "netG_lr 6.984743555954145                                                         \n",
      "weight_decay1 7.338680619378917                                                   \n",
      "weight_decay2 3.9925975626139056                                                  \n",
      " 28%|██▊       | 28/100 [02:00<05:11,  4.33s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940407568 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940407568 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.945500734582313                                                          \n",
      "netD_lr 4.163972027746874                                                         \n",
      "netG_B 1.0395845639019914                                                         \n",
      "netG_lr 5.577536968151287                                                         \n",
      "weight_decay1 3.4917266393105812                                                  \n",
      "weight_decay2 3.4400089362893294                                                  \n",
      " 29%|██▉       | 29/100 [02:04<05:07,  4.34s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939525840 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939525840 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 0.013862838481882855                                                       \n",
      "netD_lr 6.828660911994433                                                         \n",
      "netG_B 0.4161359435130221                                                         \n",
      "netG_lr 7.682428527430572                                                         \n",
      "weight_decay1 7.987254213801739                                                   \n",
      "weight_decay2 7.060477232644649                                                   \n",
      " 30%|███       | 30/100 [02:08<04:59,  4.28s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939634064 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939634064 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.464534256257478                                                          \n",
      "netD_lr 8.348108543809161                                                         \n",
      "netG_B 2.4648614332887098                                                         \n",
      "netG_lr 4.477339452893659                                                         \n",
      "weight_decay1 7.685175142034816                                                   \n",
      "weight_decay2 4.922093115937953                                                   \n",
      " 31%|███       | 31/100 [02:12<04:53,  4.26s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940061776 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940061776 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.8829642870214607                                                         \n",
      "netD_lr 7.693125497558005                                                         \n",
      "netG_B 1.9864017369623808                                                         \n",
      "netG_lr 8.705673911589631                                                         \n",
      "weight_decay1 4.164048226433694                                                   \n",
      "weight_decay2 4.177940054000124                                                   \n",
      " 32%|███▏      | 32/100 [02:19<05:44,  5.07s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940265488 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940265488 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 0.3065691188457027                                                         \n",
      "netD_lr 2.2937509130147755                                                        \n",
      "netG_B 1.5299198687383728                                                         \n",
      "netG_lr 3.3524075937449735                                                        \n",
      "weight_decay1 5.858889859626351                                                   \n",
      "weight_decay2 5.992055428472469                                                   \n",
      " 33%|███▎      | 33/100 [02:23<05:17,  4.74s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443941886928 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443941886928 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.436485007189025                                                          \n",
      "netD_lr 4.949095335583552                                                         \n",
      "netG_B 2.9652615343438895                                                         \n",
      "netG_lr 2.0552359381405934                                                        \n",
      "weight_decay1 5.367368904344724                                                   \n",
      "weight_decay2 7.628833381336313                                                   \n",
      " 34%|███▍      | 34/100 [02:27<05:02,  4.58s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940264016 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940264016 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.365003016043786                                                          \n",
      "netD_lr 1.0288539037255777                                                        \n",
      "netG_B 2.626314398025648                                                          \n",
      "netG_lr 1.6139182494438413                                                        \n",
      "weight_decay1 6.562922474880481                                                   \n",
      "weight_decay2 4.563328860877297                                                   \n",
      " 35%|███▌      | 35/100 [02:32<04:52,  4.50s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940891472 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940891472 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.000006029899754                                                       \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.6359956504680997                                                         \n",
      "netD_lr 3.2964963044374676                                                        \n",
      "netG_B 2.2024591240885316                                                         \n",
      "netG_lr 4.1082448198407615                                                        \n",
      "weight_decay1 5.004420136600943                                                   \n",
      "weight_decay2 5.382228132505038                                                   \n",
      " 36%|███▌      | 36/100 [02:36<04:46,  4.48s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939684496 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939684496 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.156277876946269                                                          \n",
      "netD_lr 5.423622976410435                                                         \n",
      "netG_B 2.8389091244348044                                                         \n",
      "netG_lr 1.00595753076726                                                          \n",
      "weight_decay1 3.386781008976505                                                   \n",
      "weight_decay2 3.043464284970583                                                   \n",
      " 37%|███▋      | 37/100 [02:40<04:38,  4.42s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443941082896 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443941082896 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000464144136632                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.3718167623603184                                                         \n",
      "netD_lr 4.451849191636809                                                         \n",
      "netG_B 2.0233735790218326                                                         \n",
      "netG_lr 3.50364564571563                                                          \n",
      "weight_decay1 3.9415476714313606                                                  \n",
      "weight_decay2 4.342702529626165                                                   \n",
      " 38%|███▊      | 38/100 [02:45<04:29,  4.35s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443941072720 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443941072720 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.8344748787552314                                                         \n",
      "netD_lr 2.7958472344162395                                                        \n",
      "netG_B 1.0205009406771874                                                         \n",
      "netG_lr 2.7697011154676376                                                        \n",
      "weight_decay1 4.493082151255578                                                   \n",
      "weight_decay2 3.37610551669644                                                    \n",
      " 39%|███▉      | 39/100 [02:52<05:14,  5.15s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939686416 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939686416 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.8588893526261117                                                         \n",
      "netD_lr 1.3186327757197893                                                        \n",
      "netG_B 2.3635007015788405                                                         \n",
      "netG_lr 5.547885614437985                                                         \n",
      "weight_decay1 6.988152117001251                                                   \n",
      "weight_decay2 6.584469261456915                                                   \n",
      " 40%|████      | 40/100 [02:56<04:50,  4.85s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939856208 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939856208 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 0.9669690468802856                                                         \n",
      "netD_lr 2.0220597728966645                                                        \n",
      "netG_B 0.6695695476807236                                                         \n",
      "netG_lr 1.4401348168041137                                                        \n",
      "weight_decay1 5.541327893666468                                                   \n",
      "weight_decay2 5.551692316391523                                                   \n",
      " 41%|████      | 41/100 [03:00<04:43,  4.80s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939026192 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939026192 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.974834757782451                                                          \n",
      "netD_lr 5.928244351408782                                                         \n",
      "netG_B 1.6329047815640165                                                         \n",
      "netG_lr 2.212938726396149                                                         \n",
      "weight_decay1 6.084938658888105                                                   \n",
      "weight_decay2 6.20700870635434                                                    \n",
      " 42%|████▏     | 42/100 [03:05<04:29,  4.64s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939072912 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939072912 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.007033875847732                                                       \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.579493036842809                                                          \n",
      "netD_lr 3.79523886213913                                                          \n",
      "netG_B 1.3224614125584115                                                         \n",
      "netG_lr 6.675435607054748                                                         \n",
      "weight_decay1 3.297399696486999                                                   \n",
      "weight_decay2 3.991442095417572                                                   \n",
      " 43%|████▎     | 43/100 [03:09<04:16,  4.49s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443939028112 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443939028112 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 2.293929671701432                                                          \n",
      "netD_lr 3.0826506095138213                                                        \n",
      "netG_B 1.8923690443559167                                                         \n",
      "netG_lr 3.925480136113335                                                         \n",
      "weight_decay1 3.7842273299874005                                                  \n",
      "weight_decay2 4.775129997118031                                                   \n",
      " 44%|████▍     | 44/100 [03:13<04:06,  4.40s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443938232720 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443938232720 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.106707441678955                                                          \n",
      "netD_lr 4.567008369036984                                                         \n",
      "netG_B 2.7806534925536543                                                         \n",
      "netG_lr 8.381655093918342                                                         \n",
      "weight_decay1 5.196366431094534                                                   \n",
      "weight_decay2 5.1830346839644905                                                  \n",
      " 45%|████▌     | 45/100 [03:17<04:01,  4.39s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443938347280 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443938347280 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.3920090169021928                                                         \n",
      "netD_lr 1.8804625604911451                                                        \n",
      "netG_B 0.8456073831274411                                                         \n",
      "netG_lr 5.412606734490993                                                         \n",
      "weight_decay1 5.707687430551839                                                   \n",
      "weight_decay2 6.805651539056886                                                   \n",
      " 46%|████▌     | 46/100 [03:22<03:53,  4.33s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443938467408 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443938467408 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.612275362445847                                                          \n",
      "netD_lr 2.5211773253752225                                                        \n",
      "netG_B 0.3502078758082552                                                         \n",
      "netG_lr 3.0948988127697667                                                        \n",
      "weight_decay1 4.6828718339727455                                                  \n",
      "weight_decay2 3.626222683574116                                                   \n",
      " 47%|████▋     | 47/100 [03:26<03:47,  4.30s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443938565584 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443938565584 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 2.5457932216065506                                                         \n",
      "netD_lr 4.12205723415023                                                          \n",
      "netG_B 0.007031706689037964                                                       \n",
      "netG_lr 4.538316785441959                                                         \n",
      "weight_decay1 4.345287703583485                                                   \n",
      "weight_decay2 5.623747896263984                                                   \n",
      " 48%|████▊     | 48/100 [03:30<03:44,  4.32s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443938647632 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443938647632 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.8238254013579034                                                         \n",
      "netD_lr 3.5738603252448504                                                        \n",
      "netG_B 2.599276121065243                                                          \n",
      "netG_lr 2.3500514128646035                                                        \n",
      "weight_decay1 3.053200332355503                                                   \n",
      "weight_decay2 4.228759086798529                                                   \n",
      " 49%|████▉     | 49/100 [03:35<03:43,  4.38s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443940582608 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443940582608 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.9894590324093293                                                         \n",
      "netD_lr 1.024182297695328                                                         \n",
      "netG_B 2.108080998162121                                                          \n",
      "netG_lr 1.2180929578487187                                                        \n",
      "weight_decay1 7.8150422920704035                                                  \n",
      "weight_decay2 6.163079933988889                                                   \n",
      " 50%|█████     | 50/100 [03:43<04:31,  5.44s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443938647120 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443938647120 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.1959403944899405                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 1.9590114195159423                                                         \n",
      "netD_lr 1.093066994492393                                                         \n",
      "netG_B 2.1120377481746933                                                         \n",
      "netG_lr 1.3554581553847798                                                        \n",
      "weight_decay1 7.26421024722571                                                    \n",
      "weight_decay2 6.499539151732601                                                   \n",
      " 51%|█████     | 51/100 [03:51<05:11,  6.35s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443937459152 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443937459152 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération 0.0                                                                     \n",
      "netD_B 0.6904826711119864                                                         \n",
      "netD_lr 1.450884087969745                                                         \n",
      "netG_B 1.4671980170107037                                                         \n",
      "netG_lr 3.6802357977557163                                                        \n",
      "weight_decay1 7.7267607793378374                                                  \n",
      "weight_decay2 7.415141537647716                                                   \n",
      " 52%|█████▏    | 52/100 [03:59<05:18,  6.64s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443945533904 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443945533904 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                      \n",
      "\n",
      "itération -0.0                                                                    \n",
      "netD_B 1.024940112464531                                                          \n",
      "netD_lr 1.8095240539540933                                                        \n",
      "netG_B 1.1475371173663622                                                         \n",
      "netG_lr 1.8313836064293036                                                        \n",
      "weight_decay1 3.2183877997986694                                                  \n",
      "weight_decay2 6.111437365611431                                                   \n",
      " 53%|█████▎    | 53/100 [04:06<05:25,  6.92s/trial, best loss: -1.234438008608312]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443944037264 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443944037264 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.3135538937560618                                                      \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.41669148709460335                                                         \n",
      "netD_lr 8.924148338321698                                                          \n",
      "netG_B 1.1236923487095472                                                          \n",
      "netG_lr 1.9509635864734567                                                         \n",
      "weight_decay1 3.143222023991279                                                    \n",
      "weight_decay2 7.842202870157227                                                    \n",
      " 54%|█████▍    | 54/100 [04:12<04:53,  6.38s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443947804688 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443947804688 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000014520153488                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.1178210090852863                                                          \n",
      "netD_lr 7.001913689447166                                                          \n",
      "netG_B 1.1845331645573833                                                          \n",
      "netG_lr 2.596277491460953                                                          \n",
      "weight_decay1 3.644945879601227                                                    \n",
      "weight_decay2 6.803339931324542                                                    \n",
      " 55%|█████▌    | 55/100 [04:17<04:36,  6.15s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443947894032 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443947894032 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000004208072                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.00357073266695                                                            \n",
      "netD_lr 1.8821387204208455                                                         \n",
      "netG_B 0.5141123616404882                                                          \n",
      "netG_lr 5.143981370114316                                                          \n",
      "weight_decay1 3.207809335930432                                                    \n",
      "weight_decay2 5.885315827989085                                                    \n",
      " 56%|█████▌    | 56/100 [04:21<04:04,  5.55s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443947664720 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443947664720 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.8495147799254389                                                          \n",
      "netD_lr 5.299683486510435                                                          \n",
      "netG_B 0.885647446518564                                                           \n",
      "netG_lr 4.256983018792678                                                          \n",
      "weight_decay1 4.210646563861214                                                    \n",
      "weight_decay2 7.172836202538628                                                    \n",
      " 57%|█████▋    | 57/100 [04:25<03:40,  5.13s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443946333712 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443946333712 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.247915930688221                                                           \n",
      "netD_lr 5.795779186997798                                                          \n",
      "netG_B 1.4197441073133972                                                          \n",
      "netG_lr 5.840074251606616                                                          \n",
      "weight_decay1 3.8255953829036766                                                   \n",
      "weight_decay2 5.687644705254211                                                    \n",
      " 58%|█████▊    | 58/100 [04:29<03:22,  4.82s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443941451792 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443941451792 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.42583036940722474                                                         \n",
      "netD_lr 2.8846583993147386                                                         \n",
      "netG_B 1.6330352590172474                                                          \n",
      "netG_lr 3.072417077601196                                                          \n",
      "weight_decay1 4.776335109369295                                                    \n",
      "weight_decay2 5.193547705527722                                                    \n",
      " 59%|█████▉    | 59/100 [04:33<03:11,  4.66s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443944909840 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443944909840 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.03904075976974819                                                         \n",
      "netD_lr 3.436058205475873                                                          \n",
      "netG_B 0.8148170757826936                                                          \n",
      "netG_lr 1.7647878062255262                                                         \n",
      "weight_decay1 3.0020314287722694                                                   \n",
      "weight_decay2 4.956878658043731                                                    \n",
      " 60%|██████    | 60/100 [04:38<03:01,  4.54s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444033028752 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444033028752 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.2597230022269645                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.23100620519858955                                                         \n",
      "netD_lr 6.3596130939800775                                                         \n",
      "netG_B 0.0502780973039485                                                          \n",
      "netG_lr 1.6812163950000456                                                         \n",
      "weight_decay1 3.610790203001918                                                    \n",
      "weight_decay2 4.904034802544719                                                    \n",
      " 61%|██████    | 61/100 [04:42<02:53,  4.45s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443943063248 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443943063248 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.000248611808816                                                        \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.621457333213073                                                           \n",
      "netD_lr 3.3547125548199492                                                         \n",
      "netG_B 0.5318573641558169                                                          \n",
      "netG_lr 3.437976949159854                                                          \n",
      "weight_decay1 3.9366537142261504                                                   \n",
      "weight_decay2 6.049309252854822                                                    \n",
      " 62%|██████▏   | 62/100 [04:46<02:47,  4.41s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443944132688 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443944132688 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.5290107104512103                                                          \n",
      "netD_lr 3.9357348408866653                                                         \n",
      "netG_B 0.8021926719391644                                                          \n",
      "netG_lr 7.324029871576322                                                          \n",
      "weight_decay1 4.32212371434022                                                     \n",
      "weight_decay2 6.3943952750436175                                                   \n",
      " 63%|██████▎   | 63/100 [04:51<02:41,  4.36s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443947566416 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443947566416 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.009641004501805384                                                        \n",
      "netD_lr 1.7049202914823036                                                         \n",
      "netG_B 0.30848082341614935                                                         \n",
      "netG_lr 2.120359686790581                                                          \n",
      "weight_decay1 3.469392551794604                                                    \n",
      "weight_decay2 4.588877697007061                                                    \n",
      " 64%|██████▍   | 64/100 [04:55<02:36,  4.35s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476717392 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476717392 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.131081381453367                                                        \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.2269340181989068                                                          \n",
      "netD_lr 2.208491094136776                                                          \n",
      "netG_B 0.5969025932342602                                                          \n",
      "netG_lr 2.6437854927492177                                                         \n",
      "weight_decay1 3.004683909584583                                                    \n",
      "weight_decay2 4.713356784850052                                                    \n",
      " 65%|██████▌   | 65/100 [04:59<02:32,  4.35s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476248656 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476248656 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0006404445308494                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.10260467485861635                                                         \n",
      "netD_lr 2.5409416750158025                                                         \n",
      "netG_B 0.9308119448173032                                                          \n",
      "netG_lr 1.0134828695444225                                                         \n",
      "weight_decay1 3.3512492787252395                                                   \n",
      "weight_decay2 4.000319061192157                                                    \n",
      " 66%|██████▌   | 66/100 [05:04<02:30,  4.43s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444033147664 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444033147664 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.8370154891452044                                                          \n",
      "netD_lr 3.055948752049017                                                          \n",
      "netG_B 0.17169850725720082                                                         \n",
      "netG_lr 1.8100533811201578                                                         \n",
      "weight_decay1 3.831230162812361                                                    \n",
      "weight_decay2 4.429463223186396                                                    \n",
      " 67%|██████▋   | 67/100 [05:08<02:27,  4.48s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443943757712 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443943757712 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.012451446030044                                                        \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.9725707090949356                                                          \n",
      "netD_lr 4.441482083638074                                                          \n",
      "netG_B 1.1003888218219193                                                          \n",
      "netG_lr 2.4242179709198766                                                         \n",
      "weight_decay1 3.160330383681873                                                    \n",
      "weight_decay2 4.992550292901189                                                    \n",
      " 68%|██████▊   | 68/100 [05:13<02:21,  4.42s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443937457616 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443937457616 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000059131307255                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.4622933697602727                                                          \n",
      "netD_lr 2.156862885185184                                                          \n",
      "netG_B 1.2399388856568578                                                          \n",
      "netG_lr 1.3330450793405213                                                         \n",
      "weight_decay1 3.5338128361067054                                                   \n",
      "weight_decay2 5.288633633603916                                                    \n",
      " 69%|██████▉   | 69/100 [05:20<02:43,  5.29s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443937458320 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443937458320 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.2987473053529028                                                          \n",
      "netD_lr 3.5788303254234135                                                         \n",
      "netG_B 1.3482563604521607                                                          \n",
      "netG_lr 3.026192359681019                                                          \n",
      "weight_decay1 3.0011564698915825                                                   \n",
      "weight_decay2 3.864112311969976                                                    \n",
      " 70%|███████   | 70/100 [05:25<02:32,  5.08s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476013968 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476013968 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.10679686500233654                                                         \n",
      "netD_lr 1.2788970117486307                                                         \n",
      "netG_B 0.7566998644170929                                                          \n",
      "netG_lr 1.6036597063131668                                                         \n",
      "weight_decay1 4.063934941237559                                                    \n",
      "weight_decay2 4.308060313592845                                                    \n",
      " 71%|███████   | 71/100 [05:29<02:20,  4.86s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443948317200 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443948317200 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.196286548816472                                                           \n",
      "netD_lr 2.7115563884010117                                                         \n",
      "netG_B 1.5600160424488139                                                          \n",
      "netG_lr 3.8635753680100233                                                         \n",
      "weight_decay1 4.452545386916838                                                    \n",
      "weight_decay2 3.4408851970587873                                                   \n",
      " 72%|███████▏  | 72/100 [05:34<02:14,  4.81s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443952500816 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443952500816 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.6740208424481768                                                          \n",
      "netD_lr 4.682814226231667                                                          \n",
      "netG_B 0.9723984964944181                                                          \n",
      "netG_lr 1.9600401835546735                                                         \n",
      "weight_decay1 3.2717915981495955                                                   \n",
      "weight_decay2 5.474588853158342                                                    \n",
      " 73%|███████▎  | 73/100 [05:38<02:08,  4.77s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444032335312 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444032335312 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0304539390810545                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.5042403286203584                                                          \n",
      "netD_lr 1.6056742291124342                                                         \n",
      "netG_B 1.8488651818180357                                                          \n",
      "netG_lr 3.218780665036502                                                          \n",
      "weight_decay1 3.7066577852552163                                                   \n",
      "weight_decay2 5.844818450866542                                                    \n",
      " 74%|███████▍  | 74/100 [05:43<02:02,  4.70s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476013392 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476013392 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.7070758797365497                                                          \n",
      "netD_lr 2.4089148344836073                                                         \n",
      "netG_B 0.4851012283538285                                                          \n",
      "netG_lr 2.761530216128226                                                          \n",
      "weight_decay1 3.9713525542781225                                                   \n",
      "weight_decay2 3.0936672714830924                                                   \n",
      " 75%|███████▌  | 75/100 [05:48<01:57,  4.71s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443952673232 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443952673232 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.7571008881559842                                                          \n",
      "netD_lr 3.3982950611749                                                            \n",
      "netG_B 0.6661105232038196                                                          \n",
      "netG_lr 2.2287580911505267                                                         \n",
      "weight_decay1 3.4394157213130563                                                   \n",
      "weight_decay2 3.5948528366179247                                                   \n",
      " 76%|███████▌  | 76/100 [05:52<01:50,  4.62s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443953323536 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443953323536 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0118475570518808                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.17669000602606946                                                         \n",
      "netD_lr 5.112268136862675                                                          \n",
      "netG_B 0.2529471978757649                                                          \n",
      "netG_lr 4.674587482277044                                                          \n",
      "weight_decay1 4.21115755413685                                                     \n",
      "weight_decay2 3.296536263362984                                                    \n",
      " 77%|███████▋  | 77/100 [05:56<01:45,  4.57s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443953307856 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443953307856 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.35361662784157355                                                         \n",
      "netD_lr 3.0980229163161157                                                         \n",
      "netG_B 1.7215299860456712                                                          \n",
      "netG_lr 1.247116854855573                                                          \n",
      "weight_decay1 4.901228168005645                                                    \n",
      "weight_decay2 4.110052358093733                                                    \n",
      " 78%|███████▊  | 78/100 [06:01<01:40,  4.57s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443950041296 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443950041296 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0001915607978653                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 2.712013473222753                                                           \n",
      "netD_lr 4.3322086889348554                                                         \n",
      "netG_B 1.3837732080705871                                                          \n",
      "netG_lr 2.4802594525691277                                                         \n",
      "weight_decay1 5.1841459881934675                                                   \n",
      "weight_decay2 3.754946891263181                                                    \n",
      " 79%|███████▉  | 79/100 [06:09<01:54,  5.45s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444023521936 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444023521936 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.5634882764559124                                                          \n",
      "netD_lr 2.0664298388381437                                                         \n",
      "netG_B 1.2252682341406032                                                          \n",
      "netG_lr 6.486845155739323                                                          \n",
      "weight_decay1 4.670432717362087                                                    \n",
      "weight_decay2 6.693711115496528                                                    \n",
      " 80%|████████  | 80/100 [06:13<01:43,  5.16s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476660624 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476660624 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.0296204156913913                                                          \n",
      "netD_lr 3.8980934795132556                                                         \n",
      "netG_B 1.1012274203966275                                                          \n",
      "netG_lr 1.5759248012811526                                                         \n",
      "weight_decay1 3.557131546751532                                                    \n",
      "weight_decay2 5.086908038800235                                                    \n",
      " 81%|████████  | 81/100 [06:18<01:35,  5.02s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444034438992 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444034438992 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0001792413069641                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.8857046210730402                                                          \n",
      "netD_lr 2.6810136877356                                                            \n",
      "netG_B 2.2888905438632863                                                          \n",
      "netG_lr 1.77621604861344                                                           \n",
      "weight_decay1 4.365848736446852                                                    \n",
      "weight_decay2 4.492335084959959                                                    \n",
      " 82%|████████▏ | 82/100 [06:22<01:27,  4.89s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443952769744 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443952769744 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000233712791315                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 2.20989084155412                                                            \n",
      "netD_lr 1.7930147171216375                                                         \n",
      "netG_B 0.43743061521932003                                                         \n",
      "netG_lr 4.218096476438295                                                          \n",
      "weight_decay1 3.1115399255424148                                                   \n",
      "weight_decay2 6.979822847641085                                                    \n",
      " 83%|████████▎ | 83/100 [06:27<01:22,  4.86s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140444081944464 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140444081944464 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.4638644111127401                                                          \n",
      "netD_lr 1.463034149951579                                                          \n",
      "netG_B 1.9387830266343433                                                          \n",
      "netG_lr 2.0569640177250568                                                         \n",
      "weight_decay1 5.03847992346617                                                     \n",
      "weight_decay2 4.782422571731197                                                    \n",
      " 84%|████████▍ | 84/100 [06:35<01:33,  5.87s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476337552 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476337552 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.1160103192038544                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.166453175866858                                                           \n",
      "netD_lr 3.232627756628068                                                          \n",
      "netG_B 1.0007079839209148                                                          \n",
      "netG_lr 1.0981331138394255                                                         \n",
      "weight_decay1 3.7142177257228597                                                   \n",
      "weight_decay2 6.279251043428214                                                    \n",
      " 85%|████████▌ | 85/100 [06:40<01:21,  5.44s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443949001552 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443949001552 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.8081899032574165                                                          \n",
      "netD_lr 8.671002279424926                                                          \n",
      "netG_B 0.5791229012611596                                                          \n",
      "netG_lr 3.5577939539803918                                                         \n",
      "weight_decay1 3.2741515441365054                                                   \n",
      "weight_decay2 5.367045390976971                                                    \n",
      " 86%|████████▌ | 86/100 [06:47<01:22,  5.89s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476478032 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476478032 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 2.898259960582778                                                           \n",
      "netD_lr 3.6529474493126024                                                         \n",
      "netG_B 0.7511618888421682                                                          \n",
      "netG_lr 1.4211997854198832                                                         \n",
      "weight_decay1 4.108901992532783                                                    \n",
      "weight_decay2 4.658701256470955                                                    \n",
      " 87%|████████▋ | 87/100 [06:51<01:10,  5.41s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443953843024 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443953843024 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0003145307355992                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 2.0985770816176776                                                          \n",
      "netD_lr 2.3592819759404784                                                         \n",
      "netG_B 0.8763729944337293                                                          \n",
      "netG_lr 5.058261699290385                                                          \n",
      "weight_decay1 6.433218439061678                                                    \n",
      "weight_decay2 5.576629797151541                                                    \n",
      " 88%|████████▊ | 88/100 [06:56<01:01,  5.16s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443949115984 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443949115984 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.9088315860488851                                                          \n",
      "netD_lr 4.066709613229847                                                          \n",
      "netG_B 0.09541696218083062                                                         \n",
      "netG_lr 8.103379802563092                                                          \n",
      "weight_decay1 3.3720721241983944                                                   \n",
      "weight_decay2 5.7565376726106505                                                   \n",
      " 89%|████████▉ | 89/100 [07:03<01:03,  5.77s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443953327376 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443953327376 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 2.380648488615493                                                           \n",
      "netD_lr 2.9113189440299467                                                         \n",
      "netG_B 1.2784207301390556                                                          \n",
      "netG_lr 3.3013379444023863                                                         \n",
      "weight_decay1 3.8405314428762543                                                   \n",
      "weight_decay2 6.076173820587119                                                    \n",
      " 90%|█████████ | 90/100 [07:07<00:54,  5.43s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476595856 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476595856 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 0.5071718177041843                                                          \n",
      "netD_lr 7.58469125116445                                                           \n",
      "netG_B 1.6358052002849524                                                          \n",
      "netG_lr 2.990982513992692                                                          \n",
      "weight_decay1 5.465334525594959                                                    \n",
      "weight_decay2 4.868144625143796                                                    \n",
      " 91%|█████████ | 91/100 [07:12<00:46,  5.20s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443476530896 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443476530896 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.3380193369855327                                                          \n",
      "netD_lr 4.990513459800801                                                          \n",
      "netG_B 1.176176244290213                                                           \n",
      "netG_lr 2.819446374208275                                                          \n",
      "weight_decay1 6.829633991223686                                                    \n",
      "weight_decay2 5.190295502767548                                                    \n",
      " 92%|█████████▏| 92/100 [07:17<00:40,  5.08s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443951470160 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443951470160 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 2.50947433914458                                                            \n",
      "netD_lr 2.0450087950655402                                                         \n",
      "netG_B 1.4482028511125538                                                          \n",
      "netG_lr 3.790250264116956                                                          \n",
      "weight_decay1 4.772054475323387                                                    \n",
      "weight_decay2 7.623875641500603                                                    \n",
      " 93%|█████████▎| 93/100 [07:23<00:35,  5.12s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443952231952 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443952231952 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.6492156497950354                                                          \n",
      "netD_lr 1.2359462746655367                                                         \n",
      "netG_B 1.5372601861780182                                                          \n",
      "netG_lr 2.24012899741271                                                           \n",
      "weight_decay1 3.001093301591857                                                    \n",
      "weight_decay2 6.441652534025349                                                    \n",
      " 94%|█████████▍| 94/100 [07:29<00:33,  5.54s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443953726544 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443953726544 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0019778520530438                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.897586781299389                                                           \n",
      "netD_lr 1.6623044008770498                                                         \n",
      "netG_B 0.3897282018876316                                                          \n",
      "netG_lr 4.437112389587087                                                          \n",
      "weight_decay1 5.774867861842278                                                    \n",
      "weight_decay2 4.086855753750688                                                    \n",
      " 95%|█████████▌| 95/100 [07:33<00:26,  5.21s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443953881616 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443953881616 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 0.7662126429361267                                                          \n",
      "netD_lr 4.79945697418049                                                           \n",
      "netG_B 2.4295931890269697                                                          \n",
      "netG_lr 1.9195783351582323                                                         \n",
      "weight_decay1 3.2372992131117795                                                   \n",
      "weight_decay2 4.275025968917067                                                    \n",
      " 96%|█████████▌| 96/100 [07:37<00:19,  4.98s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443475691664 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443475691664 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0189348040143942                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 2.666028444037212                                                           \n",
      "netD_lr 5.614213190669119                                                          \n",
      "netG_B 1.714709428743137                                                           \n",
      "netG_lr 6.084942655563354                                                          \n",
      "weight_decay1 3.977711998536021                                                    \n",
      "weight_decay2 3.4749955655031664                                                   \n",
      " 97%|█████████▋| 97/100 [07:42<00:14,  4.86s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443475691216 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443475691216 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération 0.0                                                                      \n",
      "netD_B 1.0481101889597653                                                          \n",
      "netD_lr 6.1138053699826305                                                         \n",
      "netG_B 0.9408899404053522                                                          \n",
      "netG_lr 4.029421745880459                                                          \n",
      "weight_decay1 4.610735879003833                                                    \n",
      "weight_decay2 3.8128614421482308                                                   \n",
      " 98%|█████████▊| 98/100 [07:49<00:11,  5.58s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443946844752 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443946844752 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.0000000000000029                                                       \n",
      "\n",
      "itération -0.0                                                                     \n",
      "netD_B 1.753740899484381                                                           \n",
      "netD_lr 3.4557549094876214                                                         \n",
      "netG_B 1.064452182517178                                                           \n",
      "netG_lr 2.6250483373331512                                                         \n",
      "weight_decay1 4.2311939545572566                                                   \n",
      "weight_decay2 5.915177604486244                                                    \n",
      " 99%|█████████▉| 99/100 [07:54<00:05,  5.29s/trial, best loss: -1.3135538937560618]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140443477177872 acquired on /home/antoine/.data.lock\n",
      "INFO:filelock:Lock 140443477177872 released on /home/antoine/.data.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 1.000000039993341                                                        \n",
      "\n",
      "100%|██████████| 100/100 [07:58<00:00,  4.79s/trial, best loss: -1.3135538937560618]\n",
      "\n",
      " loss of parent -1.3135538937560618\n",
      "\n",
      " loss [array(-1.31355389)]\n",
      "itération 1.0                                            \n",
      "netD_B 1.0249401124636477                                          \n",
      "netD_lr 1.809524053982563                                          \n",
      "netG_B 1.1475371173353428                                          \n",
      "netG_lr 1.8313836064297717                                         \n",
      "weight_decay1 3.2183877998016155                                   \n",
      "weight_decay2 6.111437365611455                                    \n",
      "accuracy, 1.281476658071203                                        \n",
      "\n",
      "100%|██████████| 101/101 [00:08<00:00, 12.06trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.5634143544722486                                         \n",
      "netD_lr 1.4078941612678446                                        \n",
      "netG_B 0.6119642580832065                                         \n",
      "netG_lr 4.851710356348318                                         \n",
      "weight_decay1 7.4979254878943795                                  \n",
      "weight_decay2 6.664368538495253                                   \n",
      "accuracy, 1.0965820963282071                                      \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.29403638044451375                                                          \n",
      "netD_lr 1.0570546161930423                                                          \n",
      "netG_B 0.6997769751316579                                                           \n",
      "netG_lr 3.572192876398394                                                           \n",
      "weight_decay1 3.105052271292131                                                     \n",
      "weight_decay2 7.131058170902499                                                     \n",
      "accuracy, 1.0718318982703645                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.4246491543381805                                                           \n",
      "netD_lr 2.657334932308242                                                           \n",
      "netG_B 0.8222208046651199                                                           \n",
      "netG_lr 2.3624578640629488                                                          \n",
      "weight_decay1 3.7028193182595626                                                    \n",
      "weight_decay2 6.154763146739038                                                     \n",
      "accuracy, 1.2005537881665869                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.1915335086301273                                                           \n",
      "netD_lr 4.290586400031042                                                           \n",
      "netG_B 1.1481773506423048                                                           \n",
      "netG_lr 5.845565130582797                                                           \n",
      "weight_decay1 5.306715217522834                                                     \n",
      "weight_decay2 6.309778136279059                                                     \n",
      "accuracy, 1.0852899734402335                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.0786522126839357                                                           \n",
      "netD_lr 3.194399290826156                                                           \n",
      "netG_B 0.2541435700108431                                                           \n",
      "netG_lr 5.345746071238314                                                           \n",
      "weight_decay1 3.461512448341982                                                     \n",
      "weight_decay2 6.97135464618738                                                      \n",
      "accuracy, 1.0709271157397025                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.9336269147886374                                                           \n",
      "netD_lr 1.910061285162962                                                           \n",
      "netG_B 1.3701124379133711                                                           \n",
      "netG_lr 1.1620835336125424                                                          \n",
      "weight_decay1 6.034034037171008                                                     \n",
      "weight_decay2 7.293602949954288                                                     \n",
      "accuracy, 1.3284450018760616                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.9540527091018843                                                           \n",
      "netD_lr 2.428031706065004                                                           \n",
      "netG_B 1.375902227711932                                                            \n",
      "netG_lr 1.022277762494898                                                           \n",
      "weight_decay1 6.628305237223945                                                     \n",
      "weight_decay2 7.998484206385427                                                     \n",
      "accuracy, 1.1644967709641718                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.5575013692824178                                                           \n",
      "netD_lr 1.8803752156692901                                                          \n",
      "netG_B 2.038976728625305                                                            \n",
      "netG_lr 3.177236986351838                                                           \n",
      "weight_decay1 6.109974385962436                                                     \n",
      "weight_decay2 7.346154799148615                                                     \n",
      "accuracy, 1.0126213218502418                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.7333278873411022                                                           \n",
      "netD_lr 1.145541892049629                                                           \n",
      "netG_B 1.7678220997226028                                                           \n",
      "netG_lr 1.5035851450329885                                                          \n",
      "weight_decay1 5.913428351087176                                                     \n",
      "weight_decay2 7.554504267357863                                                     \n",
      "accuracy, 1.1376504355162658                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:41<00:00,  2.67trial/s, best loss: -1.3284450018760616]\n",
      "\n",
      " loss of parent -1.2597230022269645\n",
      "\n",
      " loss [array(-1.259723)]\n",
      "itération 1.0                                            \n",
      "netD_B 0.039040759772360066                                        \n",
      "netD_lr 3.4360582054743602                                         \n",
      "netG_B 0.8148170757491436                                          \n",
      "netG_lr 1.7647878061494813                                         \n",
      "weight_decay1 3.002031428727584                                    \n",
      "weight_decay2 4.956878658120564                                    \n",
      "accuracy, 1.0749886330947078                                       \n",
      "\n",
      "100%|██████████| 101/101 [00:04<00:00, 20.61trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.31588874256510113                                         \n",
      "netD_lr 2.60870988278867                                           \n",
      "netG_B 1.784028916625342                                           \n",
      "netG_lr 4.911862963866239                                          \n",
      "weight_decay1 7.445350357716379                                    \n",
      "weight_decay2 6.5916256012494525                                   \n",
      "accuracy, 1.2598268803695365                                       \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 1.0                                                                       \n",
      "netD_B 0.31318670069722193                                                          \n",
      "netD_lr 4.351123070748346                                                           \n",
      "netG_B 1.766077708574226                                                            \n",
      "netG_lr 7.183351955508412                                                           \n",
      "weight_decay1 7.445888247630819                                                     \n",
      "weight_decay2 6.6427190007935355                                                    \n",
      "accuracy, 1.2847943671170852                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.2991234388341259                                                           \n",
      "netD_lr 6.5525437202480905                                                          \n",
      "netG_B 2.049021184228062                                                            \n",
      "netG_lr 6.983515150699432                                                           \n",
      "weight_decay1 7.890585560966236                                                     \n",
      "weight_decay2 7.274338696460878                                                     \n",
      "accuracy, 1.265578415299994                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.20081657687387522                                                          \n",
      "netD_lr 6.586263440679144                                                           \n",
      "netG_B 2.0364453955315738                                                           \n",
      "netG_lr 6.991977908367813                                                           \n",
      "weight_decay1 7.876005335986692                                                     \n",
      "weight_decay2 7.9934349791562                                                       \n",
      "accuracy, 1.2508830568723275                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.4675616293413327                                                           \n",
      "netD_lr 8.222061643231617                                                           \n",
      "netG_B 2.316474028977783                                                            \n",
      "netG_lr 7.835390016704181                                                           \n",
      "weight_decay1 7.167823246891009                                                     \n",
      "weight_decay2 7.354901377803207                                                     \n",
      "accuracy, 1.3017322923420156                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.6032845040593531                                                           \n",
      "netD_lr 7.111937413580727                                                           \n",
      "netG_B 1.924631393195731                                                            \n",
      "netG_lr 8.93107469561199                                                            \n",
      "weight_decay1 7.070680069154519                                                     \n",
      "weight_decay2 7.604910436451176                                                     \n",
      "accuracy, 1.2591012906377288                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.6904859707096971                                                           \n",
      "netD_lr 8.347808798586179                                                           \n",
      "netG_B 2.2666379043281886                                                           \n",
      "netG_lr 7.87120720710412                                                            \n",
      "weight_decay1 7.556881421422737                                                     \n",
      "weight_decay2 7.792245382857236                                                     \n",
      "accuracy, 1.2756737317587215                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.4510914968327967                                                           \n",
      "netD_lr 7.629061195946404                                                           \n",
      "netG_B 2.652435399605225                                                            \n",
      "netG_lr 8.38753358813588                                                            \n",
      "weight_decay1 7.230553412063933                                                     \n",
      "weight_decay2 6.931471906164706                                                     \n",
      "accuracy, 1.2860328488042168                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.44008433415293635                                                          \n",
      "netD_lr 7.597792057866576                                                           \n",
      "netG_B 2.9393938871842904                                                           \n",
      "netG_lr 8.476836134203069                                                           \n",
      "weight_decay1 6.124440939913862                                                     \n",
      "weight_decay2 7.503701537227958                                                     \n",
      "accuracy, 1.2886783131503317                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:42<00:00,  2.57trial/s, best loss: -1.3135538937560618]\n",
      "\n",
      " loss of parent -1.234438008608312\n",
      "\n",
      " loss [array(-1.23443801)]\n",
      "itération 1.0                                            \n",
      "netD_B 2.6368339592336874                                          \n",
      "netD_lr 2.1052915727484693                                         \n",
      "netG_B 2.9958097216713853                                          \n",
      "netG_lr 1.32668053186897                                           \n",
      "weight_decay1 3.1312994415860707                                   \n",
      "weight_decay2 3.941118972759                                       \n",
      "accuracy, 1.296066317249133                                        \n",
      "\n",
      "100%|██████████| 101/101 [00:04<00:00, 20.23trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.3179596547435106                                          \n",
      "netD_lr 3.19016162951771                                           \n",
      "netG_B 0.7141496126744162                                          \n",
      "netG_lr 1.0061119319510863                                         \n",
      "weight_decay1 3.0700901938044596                                   \n",
      "weight_decay2 4.998444346358743                                    \n",
      "accuracy, 1.164719677866222                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.040758526511832                                                            \n",
      "netD_lr 2.60637783951838                                                            \n",
      "netG_B 2.9042378423664177                                                           \n",
      "netG_lr 2.374509058627443                                                           \n",
      "weight_decay1 6.105652912473633                                                     \n",
      "weight_decay2 4.39706862127176                                                      \n",
      "accuracy, 1.2293129058066907                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.802800828329567                                                            \n",
      "netD_lr 2.909658717956                                                              \n",
      "netG_B 1.1879794135470298                                                           \n",
      "netG_lr 7.352521459748678                                                           \n",
      "weight_decay1 3.7481739541737884                                                    \n",
      "weight_decay2 3.5635245095313524                                                    \n",
      "accuracy, 1.1912927609645796                                                        \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 1.0                                                                       \n",
      "netD_B 0.5899179593269199                                                           \n",
      "netD_lr 6.729035973120338                                                           \n",
      "netG_B 1.7695154938909377                                                           \n",
      "netG_lr 3.617967949287268                                                           \n",
      "weight_decay1 3.880116311024641                                                     \n",
      "weight_decay2 6.611376103937482                                                     \n",
      "accuracy, 1.1678741088070135                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.06643066229649364                                                          \n",
      "netD_lr 1.047611310141356                                                           \n",
      "netG_B 0.8232013039869949                                                           \n",
      "netG_lr 5.289482951345596                                                           \n",
      "weight_decay1 5.298733232876045                                                     \n",
      "weight_decay2 3.206119382065694                                                     \n",
      "accuracy, 1.194155699360795                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.45154386460688495                                                          \n",
      "netD_lr 4.270554365304955                                                           \n",
      "netG_B 0.23258367754613518                                                          \n",
      "netG_lr 6.788364690101985                                                           \n",
      "weight_decay1 3.640911791397019                                                     \n",
      "weight_decay2 7.359445646652453                                                     \n",
      "accuracy, 1.2254302536995696                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.2493008359677664                                                           \n",
      "netD_lr 4.032938081748308                                                           \n",
      "netG_B 2.0550902069633885                                                           \n",
      "netG_lr 1.723344280910388                                                           \n",
      "weight_decay1 3.4138902201060657                                                    \n",
      "weight_decay2 5.672005851017206                                                     \n",
      "accuracy, 1.216677165888023                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.2345429082480743                                                           \n",
      "netD_lr 3.7274680819681674                                                          \n",
      "netG_B 0.5840998071190382                                                           \n",
      "netG_lr 1.1869416948042089                                                          \n",
      "weight_decay1 4.417079041561007                                                     \n",
      "weight_decay2 3.7174551625460195                                                    \n",
      "accuracy, 1.1138808930932727                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.2427698808216845                                                           \n",
      "netD_lr 1.3561050042327736                                                          \n",
      "netG_B 2.2955577324338607                                                           \n",
      "netG_lr 5.687869642159662                                                           \n",
      "weight_decay1 7.479473753757855                                                     \n",
      "weight_decay2 5.460220296040523                                                     \n",
      "accuracy, 1.2277988897870522                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:48<00:00,  2.29trial/s, best loss: -1.3135538937560618]\n",
      "\n",
      " loss of parent -1.1959403944899405\n",
      "\n",
      " loss [array(-1.19594039)]\n",
      "itération 1.0                                            \n",
      "netD_B 1.9894590324506367                                          \n",
      "netD_lr 1.0241822976231618                                         \n",
      "netG_B 2.1080809981011854                                          \n",
      "netG_lr 1.2180929578999247                                         \n",
      "weight_decay1 7.815042292096718                                    \n",
      "weight_decay2 6.163079933996252                                    \n",
      "accuracy, 1.3216252199603493                                      \n",
      "\n",
      "100%|██████████| 101/101 [00:07<00:00, 12.66trial/s, best loss: -1.3216252199603493]\n",
      "itération 1.0                                            \n",
      "netD_B 2.3227342809278233                                          \n",
      "netD_lr 1.4909438552641625                                         \n",
      "netG_B 2.1344651687428127                                          \n",
      "netG_lr 5.242144068891425                                          \n",
      "weight_decay1 7.869471174442566                                    \n",
      "weight_decay2 6.995509735920499                                    \n",
      "accuracy, 1.1964747970795968                                       \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.0203597972117677                                                           \n",
      "netD_lr 1.1470448796027097                                                          \n",
      "netG_B 2.0654002467036823                                                           \n",
      "netG_lr 1.019247436097846                                                           \n",
      "weight_decay1 7.466203247417445                                                     \n",
      "weight_decay2 6.628779145823342                                                     \n",
      "accuracy, 1.2787869368483145                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.24042038344342                                                             \n",
      "netD_lr 1.1209699203802261                                                          \n",
      "netG_B 2.061321934163687                                                            \n",
      "netG_lr 1.1694515830892427                                                          \n",
      "weight_decay1 7.076871106699991                                                     \n",
      "weight_decay2 7.203544833435181                                                     \n",
      "accuracy, 1.3944968554794008                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.4105370906994847                                                           \n",
      "netD_lr 6.786587633508686                                                           \n",
      "netG_B 2.275139839742025                                                            \n",
      "netG_lr 8.946584275870139                                                           \n",
      "weight_decay1 7.081081304499346                                                     \n",
      "weight_decay2 7.242570899604849                                                     \n",
      "accuracy, 1.199972967604172                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.1826482910084968                                                           \n",
      "netD_lr 1.3789020393338545                                                          \n",
      "netG_B 2.5404270181615543                                                           \n",
      "netG_lr 6.952567712038985                                                           \n",
      "weight_decay1 6.678943540782816                                                     \n",
      "weight_decay2 7.9655362051245575                                                    \n",
      "accuracy, 1.2369165228412882                                                        \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 1.0                                                                       \n",
      "netD_B 1.8861258517848039                                                           \n",
      "netD_lr 1.035312012995115                                                           \n",
      "netG_B 1.7973906224692657                                                           \n",
      "netG_lr 1.4486557555822994                                                          \n",
      "weight_decay1 7.521963716257881                                                     \n",
      "weight_decay2 7.437850696749761                                                     \n",
      "accuracy, 1.3908995591643964                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.240008235883368                                                            \n",
      "netD_lr 1.9385274435368776                                                          \n",
      "netG_B 2.373673399980584                                                            \n",
      "netG_lr 1.4530837401002055                                                          \n",
      "weight_decay1 7.493431317727369                                                     \n",
      "weight_decay2 7.553003742081947                                                     \n",
      "accuracy, 1.1944454103243562                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.12063670663331                                                             \n",
      "netD_lr 8.074569833602467                                                           \n",
      "netG_B 1.9585611847420272                                                           \n",
      "netG_lr 1.234979887696992                                                           \n",
      "weight_decay1 7.3229214181294005                                                    \n",
      "weight_decay2 7.802606732586449                                                     \n",
      "accuracy, 1.2433997412517657                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.9213091508969948                                                           \n",
      "netD_lr 1.134399199851888                                                           \n",
      "netG_B 1.8219275130646373                                                           \n",
      "netG_lr 4.841537177540403                                                           \n",
      "weight_decay1 7.972421724366684                                                     \n",
      "weight_decay2 7.378137470679106                                                     \n",
      "accuracy, 1.1925205419737073                                                        \n",
      "\n",
      "100%|██████████| 110/110 [01:19<00:00,  1.38trial/s, best loss: -1.3944968554794008]\n",
      "\n",
      " loss of parent -1.1404788258871057\n",
      "\n",
      " loss [array(-1.14047883)]\n",
      "itération 1.0                                            \n",
      "netD_B 2.288577684199767                                           \n",
      "netD_lr 2.4944946010116635                                         \n",
      "netG_B 2.556945582081551                                           \n",
      "netG_lr 1.0068715611588244                                         \n",
      "weight_decay1 6.166680424315376                                    \n",
      "weight_decay2 5.476326787485715                                    \n",
      "accuracy, 1.06490225391716                                         \n",
      "\n",
      "100%|██████████| 101/101 [00:04<00:00, 22.47trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.35420041614177966                                         \n",
      "netD_lr 4.347529758302125                                          \n",
      "netG_B 0.8074504218780579                                          \n",
      "netG_lr 3.644487318789216                                          \n",
      "weight_decay1 3.717148828950058                                    \n",
      "weight_decay2 4.5233894484724715                                   \n",
      "accuracy, 1.1699215145849826                                       \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.05876389734199175                                                          \n",
      "netD_lr 1.037518644854949                                                           \n",
      "netG_B 1.7843186141126408                                                           \n",
      "netG_lr 8.993514188260106                                                           \n",
      "weight_decay1 3.1160850243614377                                                    \n",
      "weight_decay2 4.388746010052443                                                     \n",
      "accuracy, 1.1392526017016704                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.6106322147883256                                                           \n",
      "netD_lr 3.123594615758411                                                           \n",
      "netG_B 0.28611685152177446                                                          \n",
      "netG_lr 5.352288710844982                                                           \n",
      "weight_decay1 5.297729864610022                                                     \n",
      "weight_decay2 7.317394288071517                                                     \n",
      "accuracy, 1.1964926834226637                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.4109281182162001                                                           \n",
      "netD_lr 5.208927179320077                                                           \n",
      "netG_B 1.1546140901534283                                                           \n",
      "netG_lr 2.3267439776293406                                                          \n",
      "weight_decay1 3.5249185826799456                                                    \n",
      "weight_decay2 6.16714865569231                                                      \n",
      "accuracy, 1.2385234405782037                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.2127194946253987                                                           \n",
      "netD_lr 6.733081788070311                                                           \n",
      "netG_B 1.1552193110254718                                                           \n",
      "netG_lr 4.833674273463527                                                           \n",
      "weight_decay1 3.5759304051388137                                                    \n",
      "weight_decay2 6.15247752233149                                                      \n",
      "accuracy, 1.1800268460509493                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.0908905336342225                                                           \n",
      "netD_lr 5.224119953422958                                                           \n",
      "netG_B 1.4038194317622281                                                           \n",
      "netG_lr 6.854010511743466                                                           \n",
      "weight_decay1 7.501509981905285                                                     \n",
      "weight_decay2 6.586260290711387                                                     \n",
      "accuracy, 1.1701982443286663                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.4050304614845157                                                           \n",
      "netD_lr 5.453690465579184                                                           \n",
      "netG_B 0.6492553878798406                                                           \n",
      "netG_lr 3.184292886177823                                                           \n",
      "weight_decay1 5.020758598709008                                                     \n",
      "weight_decay2 7.11139223208092                                                      \n",
      "accuracy, 1.199536482221005                                                         \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 1.0                                                                       \n",
      "netD_B 1.5205844343559258                                                           \n",
      "netD_lr 5.866060138143053                                                           \n",
      "netG_B 1.5917835037798465                                                           \n",
      "netG_lr 2.301636280445578                                                           \n",
      "weight_decay1 4.435137813501811                                                     \n",
      "weight_decay2 7.478383479024645                                                     \n",
      "accuracy, 1.2728406364488354                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.5532994674334748                                                           \n",
      "netD_lr 7.251490360150135                                                           \n",
      "netG_B 1.6058182380953516                                                           \n",
      "netG_lr 2.9127618848251333                                                          \n",
      "weight_decay1 4.501441910563857                                                     \n",
      "weight_decay2 7.452913427738481                                                     \n",
      "accuracy, 1.2188916021613567                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:40<00:00,  2.68trial/s, best loss: -1.3135538937560618]\n",
      "\n",
      " loss of parent -1.131081381453367\n",
      "\n",
      " loss [array(-1.13108138)]\n",
      "itération 1.0                                            \n",
      "netD_B 0.009641004584952652                                        \n",
      "netD_lr 1.7049202914769812                                         \n",
      "netG_B 0.3084808233724988                                          \n",
      "netG_lr 2.1203596867208865                                         \n",
      "weight_decay1 3.469392551806069                                    \n",
      "weight_decay2 4.5888776970418945                                   \n",
      "accuracy, 1.0448234796635008                                       \n",
      "\n",
      "100%|██████████| 101/101 [00:06<00:00, 15.15trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 2.2306895332484276                                          \n",
      "netD_lr 4.30662319053947                                           \n",
      "netG_B 0.8071636186041908                                          \n",
      "netG_lr 2.3737721774005136                                         \n",
      "weight_decay1 3.1622755740941986                                   \n",
      "weight_decay2 5.674379856842583                                    \n",
      "accuracy, 1.2357531387052305                                       \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.7942035593153287                                                           \n",
      "netD_lr 4.301006954133471                                                           \n",
      "netG_B 0.8083898453363223                                                           \n",
      "netG_lr 4.9144027318748655                                                          \n",
      "weight_decay1 6.078812895960626                                                     \n",
      "weight_decay2 6.6459904837447485                                                    \n",
      "accuracy, 1.1184685105981733                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.2677096726287356                                                           \n",
      "netD_lr 5.28195349340795                                                            \n",
      "netG_B 0.6950267433663515                                                           \n",
      "netG_lr 3.5670425092582354                                                          \n",
      "weight_decay1 5.268592679273611                                                     \n",
      "weight_decay2 6.168921143859784                                                     \n",
      "accuracy, 1.225161195261003                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.041540721079009                                                            \n",
      "netD_lr 6.7097207362538125                                                          \n",
      "netG_B 0.5966499172953301                                                           \n",
      "netG_lr 5.793641143574317                                                           \n",
      "weight_decay1 5.061045894233455                                                     \n",
      "weight_decay2 5.454192729979871                                                     \n",
      "accuracy, 1.2191244499108578                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.2733857914578204                                                           \n",
      "netD_lr 4.0078108278408795                                                          \n",
      "netG_B 0.21734590946109777                                                          \n",
      "netG_lr 5.328646241198659                                                           \n",
      "weight_decay1 3.143230633067749                                                     \n",
      "weight_decay2 5.685681803744117                                                     \n",
      "accuracy, 1.1688509397329956                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.06872457571295287                                                          \n",
      "netD_lr 4.626469671686062                                                           \n",
      "netG_B 1.1710448854623294                                                           \n",
      "netG_lr 3.1395916801068404                                                          \n",
      "weight_decay1 3.7210655171422307                                                    \n",
      "weight_decay2 7.21774256249297                                                      \n",
      "accuracy, 1.436454296262931                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.06359712799957705                                                         \n",
      "netD_lr 5.6102618122219425                                                         \n",
      "netG_B 1.3446731119476614                                                          \n",
      "netG_lr 4.338559224746548                                                          \n",
      "weight_decay1 4.468133012197029                                                    \n",
      "weight_decay2 7.4508782297759915                                                   \n",
      "accuracy, 1.1849009454061339                                                       \n",
      "\n",
      "itération 1.0                                                                      \n",
      "netD_B 0.3093969963194122                                                          \n",
      "netD_lr 4.57251981376452                                                           \n",
      "netG_B 1.1707120616582865                                                          \n",
      "netG_lr 3.3916756840531055                                                         \n",
      "weight_decay1 3.6090837697397475                                                   \n",
      "weight_decay2 7.213167378703947                                                    \n",
      "accuracy, 1.2853933947959102                                                       \n",
      "\n",
      "itération 1.0                                                                      \n",
      "netD_B 0.3855363313875658                                                          \n",
      "netD_lr 7.463961486490558                                                          \n",
      "netG_B 1.7997861040252312                                                          \n",
      "netG_lr 4.615692904064737                                                          \n",
      "weight_decay1 3.759311227830202                                                    \n",
      "weight_decay2 7.9503441836359094                                                   \n",
      "accuracy, 1.063536408932702                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:45<00:00,  2.44trial/s, best loss: -1.436454296262931]\n",
      "\n",
      " loss of parent -1.1160103192038544\n",
      "\n",
      " loss [array(-1.11601032)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 1.0                                            \n",
      "netD_B 1.4638644111870551                                          \n",
      "netD_lr 1.463034150032986                                          \n",
      "netG_B 1.9387830265701667                                          \n",
      "netG_lr 2.0569640176806825                                         \n",
      "weight_decay1 5.038479923479032                                    \n",
      "weight_decay2 4.782422571633792                                    \n",
      "accuracy, 1.2287869027738771                                       \n",
      "\n",
      "100%|██████████| 101/101 [00:04<00:00, 20.72trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.28986299065450516                                         \n",
      "netD_lr 4.298843691028078                                          \n",
      "netG_B 0.7982860375184155                                          \n",
      "netG_lr 1.153020933216717                                          \n",
      "weight_decay1 6.088472239161774                                    \n",
      "weight_decay2 3.2241932809340024                                   \n",
      "accuracy, 1.2144184460442844                                       \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.2517982645173737                                                           \n",
      "netD_lr 2.607971263909576                                                           \n",
      "netG_B 1.7926022838027242                                                           \n",
      "netG_lr 2.3804679315315904                                                          \n",
      "weight_decay1 3.1200743470843144                                                    \n",
      "weight_decay2 5.03597138467051                                                      \n",
      "accuracy, 1.1047526759320405                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.038214812894319                                                            \n",
      "netD_lr 6.755792291888712                                                           \n",
      "netG_B 0.6857466989859573                                                           \n",
      "netG_lr 6.975478541306597                                                           \n",
      "weight_decay1 3.739848097004391                                                     \n",
      "weight_decay2 4.524782943135829                                                     \n",
      "accuracy, 1.1422172037874714                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.027256280571370972                                                         \n",
      "netD_lr 1.1402589561806835                                                          \n",
      "netG_B 0.27572455794700457                                                          \n",
      "netG_lr 1.50430951694242                                                            \n",
      "weight_decay1 3.446657158531311                                                     \n",
      "weight_decay2 7.280510551322323                                                     \n",
      "accuracy, 1.8146277099457573                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.04512971632803508                                                          \n",
      "netD_lr 3.178554117031034                                                           \n",
      "netG_B 0.2936175837793707                                                           \n",
      "netG_lr 3.595413474029253                                                           \n",
      "weight_decay1 7.431950046415643                                                     \n",
      "weight_decay2 7.362761083978926                                                     \n",
      "accuracy, 1.1185500653421547                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.17516359319597352                                                          \n",
      "netD_lr 1.9354859630146717                                                          \n",
      "netG_B 0.13268015461217386                                                          \n",
      "netG_lr 1.750985583595905                                                           \n",
      "weight_decay1 3.6069126822426973                                                    \n",
      "weight_decay2 7.961650203720228                                                     \n",
      "accuracy, 1.4732594183710617                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.5845233632299381                                                           \n",
      "netD_lr 1.1251686536211527                                                          \n",
      "netG_B 0.1805484661688994                                                           \n",
      "netG_lr 4.8642236563935874                                                          \n",
      "weight_decay1 3.5722686311551857                                                    \n",
      "weight_decay2 7.933888116569406                                                     \n",
      "accuracy, 1.1502194655516562                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.3494961911738772                                                           \n",
      "netD_lr 1.840968405782984                                                           \n",
      "netG_B 0.15619744556721735                                                          \n",
      "netG_lr 5.276622982343805                                                           \n",
      "weight_decay1 3.8973212504355437                                                    \n",
      "weight_decay2 7.565454583165788                                                     \n",
      "accuracy, 1.159172090959694                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.1734895736473168                                                           \n",
      "netD_lr 1.3373954151898533                                                          \n",
      "netG_B 0.3575903969991222                                                           \n",
      "netG_lr 1.4248800584337395                                                          \n",
      "weight_decay1 5.3054404675671405                                                    \n",
      "weight_decay2 7.102149112614758                                                     \n",
      "accuracy, 1.4228160466068058                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:41<00:00,  2.64trial/s, best loss: -1.8146277099457573]\n",
      "\n",
      " loss of parent -1.0340890235763396\n",
      "\n",
      " loss [array(-1.03408902)]\n",
      "itération 1.0                                            \n",
      "netD_B 2.037759835057542                                           \n",
      "netD_lr 3.485707196696763                                          \n",
      "netG_B 1.7232278067713727                                          \n",
      "netG_lr 1.1553161928447448                                         \n",
      "weight_decay1 4.913308219284921                                    \n",
      "weight_decay2 3.8282050859195422                                   \n",
      "accuracy, 1.0029144921810482                                       \n",
      "\n",
      "100%|██████████| 101/101 [00:04<00:00, 25.20trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 1.1621222847673216                                          \n",
      "netD_lr 1.0184616220592697                                         \n",
      "netG_B 0.8040129010758365                                          \n",
      "netG_lr 1.010620387659638                                          \n",
      "weight_decay1 3.088794904638181                                    \n",
      "weight_decay2 4.994603703806072                                    \n",
      "accuracy, 1.083133213464859                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.6168494141243478                                                           \n",
      "netD_lr 2.6422851045077054                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG_B 0.63233007733509                                                             \n",
      "netG_lr 2.3756875310867964                                                          \n",
      "weight_decay1 5.339176770212221                                                     \n",
      "weight_decay2 4.514323429728801                                                     \n",
      "accuracy, 1.1051665959542758                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.32319760721550006                                                          \n",
      "netD_lr 3.1744938384861285                                                          \n",
      "netG_B 2.0923435810825706                                                           \n",
      "netG_lr 4.803243363939539                                                           \n",
      "weight_decay1 3.5679297476712164                                                    \n",
      "weight_decay2 6.28108035689994                                                      \n",
      "accuracy, 1.0943224338545585                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.04916774951078895                                                          \n",
      "netD_lr 1.3897199059640157                                                          \n",
      "netG_B 1.169353291003743                                                            \n",
      "netG_lr 5.81243602024817                                                            \n",
      "weight_decay1 6.048475225366839                                                     \n",
      "weight_decay2 6.642235650175203                                                     \n",
      "accuracy, 1.1062522002459418                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.4106630510609646                                                           \n",
      "netD_lr 2.8678416648147618                                                          \n",
      "netG_B 1.5812741154055108                                                           \n",
      "netG_lr 7.059169748042847                                                           \n",
      "weight_decay1 7.474963906050925                                                     \n",
      "weight_decay2 4.387189390404195                                                     \n",
      "accuracy, 1.0835098110469359                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.78795523324507                                                             \n",
      "netD_lr 1.9116991062571833                                                          \n",
      "netG_B 2.8947016462045174                                                           \n",
      "netG_lr 5.261600490396838                                                           \n",
      "weight_decay1 3.4110734941707785                                                    \n",
      "weight_decay2 3.2265844939289288                                                    \n",
      "accuracy, 1.0847091549882695                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.24697999690533876                                                          \n",
      "netD_lr 2.400319946133148                                                           \n",
      "netG_B 0.3217412257077163                                                           \n",
      "netG_lr 3.5420820631100813                                                          \n",
      "weight_decay1 3.7128542004678473                                                    \n",
      "weight_decay2 7.3397714826784695                                                    \n",
      "accuracy, 1.0818150200657604                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.44447558724124914                                                          \n",
      "netD_lr 3.7718076182060067                                                          \n",
      "netG_B 0.7007004166456814                                                           \n",
      "netG_lr 1.4657311166601952                                                          \n",
      "weight_decay1 4.478669090001969                                                     \n",
      "weight_decay2 5.638222626182612                                                     \n",
      "accuracy, 1.0590084651245104                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.220845713944912                                                            \n",
      "netD_lr 1.5711456567247903                                                          \n",
      "netG_B 0.25360139329378484                                                          \n",
      "netG_lr 1.7094960256265976                                                          \n",
      "weight_decay1 3.9044070776419244                                                    \n",
      "weight_decay2 3.524674368885088                                                     \n",
      "accuracy, 1.0159593929323814                                                        \n",
      "\n",
      "100%|██████████| 110/110 [00:35<00:00,  3.10trial/s, best loss: -1.3135538937560618]\n",
      "\n",
      " loss of parent -1.0304539390810545\n",
      "\n",
      " loss [array(-1.03045394)]\n",
      "itération 1.0                                            \n",
      "netD_B 0.6740208424443712                                          \n",
      "netD_lr 4.682814226144789                                          \n",
      "netG_B 0.9723984965156227                                          \n",
      "netG_lr 1.9600401836438703                                         \n",
      "weight_decay1 3.271791598177922                                    \n",
      "weight_decay2 5.4745888531413005                                   \n",
      "accuracy, 1.0067762972877972                                       \n",
      "\n",
      "100%|██████████| 101/101 [00:03<00:00, 25.63trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.3092606959892842                                          \n",
      "netD_lr 4.27720374298099                                           \n",
      "netG_B 0.2802313018477498                                          \n",
      "netG_lr 4.878047366040263                                          \n",
      "weight_decay1 3.725390633143481                                    \n",
      "weight_decay2 4.993395740120224                                    \n",
      "accuracy, 1.0415258443050028                                       \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.5641242227908032                                                           \n",
      "netD_lr 2.6290021777027412                                                          \n",
      "netG_B 0.8226680325576592                                                           \n",
      "netG_lr 1.0465221311966824                                                          \n",
      "weight_decay1 3.1181474965142884                                                    \n",
      "weight_decay2 6.572045416080324                                                     \n",
      "accuracy, 1.0146642003785535                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.042613466681315                                                            \n",
      "netD_lr 4.007607780587627                                                           \n",
      "netG_B 2.0636200287549036                                                           \n",
      "netG_lr 6.916704699969784                                                           \n",
      "weight_decay1 3.438796212556523                                                     \n",
      "weight_decay2 4.506437311773642                                                     \n",
      "accuracy, 1.0316627313738538                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 0.047092368747489344                                                         \n",
      "netD_lr 3.169452118246304                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG_B 0.6714320378184715                                                           \n",
      "netG_lr 5.385274975288631                                                           \n",
      "weight_decay1 3.59528835680481                                                      \n",
      "weight_decay2 6.131652027446925                                                     \n",
      "accuracy, 1.0308215827019367                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.782568987649899                                                            \n",
      "netD_lr 2.8765070184340384                                                          \n",
      "netG_B 1.1672954497385137                                                           \n",
      "netG_lr 1.5020846321016723                                                          \n",
      "weight_decay1 5.022537440008581                                                     \n",
      "weight_decay2 4.385689137018139                                                     \n",
      "accuracy, 1.0194119593436894                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 2.2309443741039443                                                           \n",
      "netD_lr 1.0171430089452664                                                          \n",
      "netG_B 1.3626713301773752                                                           \n",
      "netG_lr 5.8456759498697                                                             \n",
      "weight_decay1 4.4333467604152                                                       \n",
      "weight_decay2 6.284988424060698                                                     \n",
      "accuracy, 1.0368332724154083                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.432555757724794                                                            \n",
      "netD_lr 6.687645675553132                                                           \n",
      "netG_B 1.7895910114712177                                                           \n",
      "netG_lr 2.4120292152306826                                                          \n",
      "weight_decay1 3.005184718715281                                                     \n",
      "weight_decay2 5.661247220956061                                                     \n",
      "accuracy, 1.014761645501496                                                         \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.537936483296682                                                            \n",
      "netD_lr 1.9818470935021653                                                          \n",
      "netG_B 1.3012537854407678                                                           \n",
      "netG_lr 1.2513144248252233                                                          \n",
      "weight_decay1 6.095553713468124                                                     \n",
      "weight_decay2 7.209705671420645                                                     \n",
      "accuracy, 1.0906397023280126                                                        \n",
      "\n",
      "itération 1.0                                                                       \n",
      "netD_B 1.2361490943152604                                                           \n",
      "netD_lr 3.7236189967354307                                                          \n",
      "netG_B 2.2749153632488053                                                           \n",
      "netG_lr 3.668697036343566                                                           \n",
      "weight_decay1 7.479169440686724                                                     \n",
      "weight_decay2 3.9348509746099434                                                    \n",
      "accuracy, 1.049590409309436                                                         \n",
      "\n",
      "100%|██████████| 110/110 [00:37<00:00,  2.90trial/s, best loss: -1.3135538937560618]\n",
      "\n",
      " loss of parent -1.0189348040143942\n",
      "\n",
      " loss [array(-1.0189348)]\n",
      "itération 1.0                                            \n",
      "netD_B 0.7662126430136909                                          \n",
      "netD_lr 4.799456974236588                                          \n",
      "netG_B 2.4295931890423157                                          \n",
      "netG_lr 1.9195783351769546                                         \n",
      "weight_decay1 3.2372992130607283                                   \n",
      "weight_decay2 4.275025968918265                                    \n",
      "accuracy, 1.0047384299400153                                       \n",
      "\n",
      "100%|██████████| 101/101 [00:04<00:00, 24.79trial/s, best loss: -1.3135538937560618]\n",
      "itération 1.0                                            \n",
      "netD_B 0.32825794143269516                                         \n",
      "netD_lr 1.014990414743629                                          \n",
      "netG_B 0.7034045539732796                                          \n",
      "netG_lr 1.0203777774566776                                         \n",
      "weight_decay1 3.1020129817960176                                   \n",
      "weight_decay2 4.974870629987231                                    \n",
      " 92%|█████████▏| 101/110 [00:01<00:00, 87.38trial/s, best loss=?]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-de230d3d3b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-de230d3d3b79>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfmin_objective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepeat_good\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended_Hyperspace\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mfmin_objective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_Batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended_Hyperspace\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_config\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msqrt_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mfmin_objective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3e937ff5fc08>\u001b[0m in \u001b[0;36mcompute_Batch\u001b[0;34m(self, trials, nb_eval, iteration, function)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"itération\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"itération\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n\u001b[0;32m---> 46\u001b[0;31m +nb_eval, trials=trials)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         )\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         )\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bd96d914efd5>\u001b[0m in \u001b[0;36mtest_function\u001b[0;34m(x, models, h, losses, parent_model, k_f, iteration)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9770adc0062b>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                                        self.device, self.mnist_model_ref)\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_score\u001b[0m \u001b[0;31m#{\"lossg\": lossG, \"lossd\": lossD, \"is_score\": is_score}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9770adc0062b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(netD, netG, optimG, optimD, criterion, dataloader, iteration, device, mnist_model_ref)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mD_G_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0moptimG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Scheduler():\n",
    "    def __init__(self, model, num_iteration, num_config,\n",
    "                 oracle):\n",
    "        #Oracle manages the Bayesian optimization\n",
    "        self.oracle = oracle\n",
    "        self.iteration = num_iteration\n",
    "        self.num_config = num_config \n",
    "        self.sqrt_config =   math.floor(math.sqrt(num_config)) # math.ceil(num_config/5) #\n",
    "        \n",
    "        #self.h is for the m \"h\" used at every loop, h is a configuration from the search space\n",
    "        self.h = np.repeat({},num_config) \n",
    "        \n",
    "        #self.out is for storing the result of the algorithm, ie all \"h\" from all iterations\n",
    "        #from all sqrt(m) best models per iterations.\n",
    "        self.out = np.zeros((num_iteration,self.sqrt_config))\n",
    "        \n",
    "        #self.hyperspaces is for storing the sqrt(m) hyperspaces used by the algorithm\n",
    "        self.hyperspaces = np.zeros(self.sqrt_config)\n",
    "        \n",
    "        self.plot = np.zeros(num_iteration)\n",
    "\n",
    "        \n",
    "        #self.model is the m model that will explore new hyperspace points at every iterations\n",
    "        self.models = np.repeat(model,num_config)\n",
    "        \n",
    "        #self.parents is the sqrt(m) best model from last iteration\n",
    "        self.parents = np.repeat(model,self.sqrt_config)\n",
    "\n",
    "        #self.losses remembers the performances of all m models at one iteration to decide which ones are the sqrt(m) best from self.models.\n",
    "        self.losses = np.zeros(num_config)\n",
    "        \n",
    "        self.k = [0] # c'est pour avoir un pointeur sur k, c'est pas plus que O(sqrt)-paralélisable  pour le moment du coup.\n",
    "    \n",
    "    def initialisation(self):\n",
    "        num_config = self.num_config\n",
    "        extended_Hyperspace = Trials()\n",
    "        fmin_objective = partial(test_function, models=self.models,h=self.h,losses=self.losses,parent_model=self.models, k_f = self.k,iteration = 0)\n",
    "        self.oracle.compute_Batch(extended_Hyperspace ,num_config , 0 ,fmin_objective)\n",
    "            \n",
    "        indexes = np.argsort(self.losses)     \n",
    "        self.out[0] = (self.losses[indexes])[0:self.sqrt_config]\n",
    "        self.hyperspaces = np.repeat(extended_Hyperspace,self.sqrt_config)    \n",
    "        self.parents = np.array([Parent(copy.deepcopy(extended_Hyperspace),(self.h[indexes])[i], (self.models[indexes])[i],(self.losses[indexes])[i])  \n",
    "                                 for i in range(self.sqrt_config) ])         \n",
    "        self.plot[0] = self.losses[indexes][0]\n",
    "        \n",
    "    def loop(self):\n",
    "        sqrt_config = self.sqrt_config\n",
    "        iteration = self.iteration\n",
    "        for i in range(1,iteration):\n",
    "            \n",
    "            self.k[0] = 0\n",
    "\n",
    "            for j in range(sqrt_config):\n",
    "                parent = self.parents[j]\n",
    "                extended_Hyperspace = parent.get_hyperspace()\n",
    "                print(\"\\n loss of parent \" + str(parent.get_loss()[-1]) )\n",
    "                print(\"\\n loss \" + str(parent.get_loss()))\n",
    "                \n",
    "    \n",
    "                fmin_objective = partial(test_function, models=self.models,h=self.h,losses=self.losses,parent_model=parent.get_model(), k_f = self.k,iteration = i)\n",
    "                self.oracle.Repeat_good(extended_Hyperspace ,i ,fmin_objective,parent.configuration_list[-1])\n",
    "                self.oracle.compute_Batch(extended_Hyperspace ,int(self.num_config/sqrt_config) -1 , i ,fmin_objective)\n",
    "                   \n",
    "            indexes = np.argsort(self.losses)     \n",
    "            parent_idx = indexes[:sqrt_config]\n",
    "            print(self.losses)\n",
    "            print(indexes)\n",
    " \n",
    "            temp = np.empty(self.sqrt_config, dtype=Parent)\n",
    "            for a,x in enumerate(parent_idx):\n",
    "                x = int(x)\n",
    "                temp[a] = copy.deepcopy(self.parents[math.floor(x/self.num_config*sqrt_config)])\n",
    "                temp[a].update(self.h[x], self.losses[x], self.models[x])\n",
    "            self.parents = temp\n",
    "            self.plot[i] = self.losses[parent_idx][0]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "CONFIGURATION = 100\n",
    "ITERATIONS = 3\n",
    "config= {\n",
    "     \"netG_lr\": hp.uniform(\"netG_lr\",1,9)\n",
    "    , \"netD_lr\": hp.uniform(\"netD_lr\",1,9)\n",
    "      ,   \"netG_B\": hp.uniform(\"netG_B\",0,3),\n",
    "    \"netD_B\" : hp.uniform(\"netD_B\",0, 3),\n",
    "    \"weight_decay1\" : hp.uniform(\"weight_decay1\",3, 8),\n",
    "    \"weight_decay2\" : hp.uniform(\"weight_decay2\",3, 8)}\n",
    "\n",
    "model = PytorchTrainable\n",
    "oracle = Oracle(config)\n",
    "scheduler = Scheduler(\n",
    "    model,\n",
    "    ITERATIONS,\n",
    "    CONFIGURATION,\n",
    "    oracle) \n",
    "\n",
    "scheduler.initialisation()     \n",
    "scheduler.loop()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from functools import *\n",
    "# Oracle (Paul) TODO\n",
    "class Oracle():\n",
    "    def __init__(self, searchspace ):\n",
    "        #self.hyperspace is the original (input) searchspace\n",
    "        self.searchspace = searchspace\n",
    "\n",
    "    def Repeat_good(self,trials, iteration,function,configuration): #add space\n",
    "        space = copy.deepcopy(configuration)\n",
    "        for k,v in configuration.items():\n",
    "            space[k] =  hp.uniform(k,-1e-10+v,v + 1e-10) \n",
    "\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+1, trials=trials)\n",
    "        \n",
    "    def compute_Once(self,trials, iteration,function): #add space\n",
    "        space = copy.deepcopy(self.searchspace)\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+1, trials=trials)\n",
    "        \n",
    "        \n",
    "    def compute_Batch(self,trials, nb_eval, iteration,function): #add space\n",
    "        space = copy.deepcopy(self.searchspace)\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "            \n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+nb_eval, trials=trials)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x,models,h,losses, parent_model,k_f,iteration):\n",
    "  \n",
    "    for key, value in x.items():\n",
    "            print(key + \" \"+str(x[key]))\n",
    "\n",
    "    \n",
    "\n",
    "    if (isinstance(k_f,list)):\n",
    "            k=k_f[0]\n",
    "            Islist = True \n",
    "    else:\n",
    "            k = k_f\n",
    "            Islist = False\n",
    "        \n",
    "    if iteration == 0:\n",
    "     #   k = k_f[0]\n",
    "        models[k] = parent_model[k](x)\n",
    "   #     k_f[0] += 1\n",
    "    else:      \n",
    "       # k = k_f\n",
    "        models[k] = parent_model.adapt(x)\n",
    "       # k_f[0] += 1\n",
    "    if(Islist):\n",
    "        k_f[0] += 1\n",
    "    \n",
    "\n",
    "\n",
    "    h[k] = x\n",
    "    loss = models[k].step()\n",
    "    loss = models[k].step()\n",
    "    loss = models[k].step()\n",
    "    losses[k] = -loss\n",
    "    print(\"accuracy, \" + str(loss) + \"\\n\")\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10, STL10\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray import tune\n",
    "import gc\n",
    "import numpy as np\n",
    "from ray.tune.schedulers.pb2 import PB2\n",
    "\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(\n",
    "#    datasets.MNIST('../data', train=True, download=True,\n",
    "#                   transform=transforms.ToTensor()),\n",
    "#    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "#test_loader = torch.utils.data.DataLoader(\n",
    "#    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "#batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        super(VAE, self).__init__()\n",
    "        dim1= int(config.get(\"d1\", 0)) #36*12*4*3\n",
    "        dim2=int(config.get(\"d2\", 0)) #36*12*3\n",
    "        dim3=int(config.get(\"d3\", 0)) #20*27\n",
    "        dim4=int(config.get(\"d4\", 0)) #dim2\n",
    "        dim5=int(config.get(\"d5\", 0)) #dim1\n",
    "\n",
    "        print(\"gang\")\n",
    "        self.lf=image_L*image_L*3\n",
    "        print(\"endan\")\n",
    "\n",
    "        self.fc1 = nn.Linear(self.lf, dim1)\n",
    "        print(\"endan\")\n",
    "\n",
    "        self.fc12 = nn.Linear(dim1, dim2)\n",
    "        print(\"endan\")\n",
    "\n",
    "        self.fc21 = nn.Linear(dim2, dim3)\n",
    "        print(\"endan\")\n",
    "        self.fc22 = nn.Linear(dim2, dim3)\n",
    "        print(\"endan\")\n",
    "\n",
    "        self.fc23 = nn.Linear(dim3,dim4)\n",
    "\n",
    "        print(\"endan\")\n",
    "        self.fc3 = nn.Linear(dim4, dim5)\n",
    "        print(\"endan\")\n",
    "\n",
    "        self.fc4 = nn.Linear(dim5, self.lf)\n",
    "        print(\"endan\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x.view(-1, self.lf)))\n",
    "        h1 = F.relu(self.fc12(h1))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc23(z))\n",
    "        h3 = F.relu(self.fc3(h3))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "class PytorchTrainable(tune.Trainable):\n",
    "\n",
    "    def setup(self, config):\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "        #self.netD = VAES(channel_in=3).to(self.device)\n",
    "        self.vae_net = VAES(channel_in = 3).to(self.device)\n",
    "\n",
    "\n",
    "        lr=10**-(config.get(\"lr\", 0))\n",
    "        beta1=1-10**-(config.get(\"b1\", 0))\n",
    "        beta2=1-10**-(config.get(\"b2\", 0))\n",
    "        eps=10**-(config.get(\"eps\", 0))\n",
    "        weight_decay=10**-(config.get(\"wd\", 0))\n",
    "        self.optimizerD = optim.Adam(self.vae_net.parameters(),\n",
    "                                  lr=lr, betas=(beta1, beta2),\n",
    "                               eps=eps, weight_decay=weight_decay)\n",
    "        self.dimbotle=128*4\n",
    "        globalinc=0\n",
    "\n",
    "        self.train_loader=  get_pinned_object(X_id)\n",
    "        self.test_loader=  get_pinned_object(Y_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #kwargs = {'num_workers': 1, 'pin_memory': False} if args.cuda else {}\n",
    "       # self.train_loader = torch.utils.data.DataLoader(\n",
    "        #    datasets.STL10('/content/drive/My Drive/', split=\"unlabeled\", download=True,\n",
    "        #                   transform=transforms.ToTensor()),\n",
    "        #        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "        #self.test_loader = torch.utils.data.DataLoader(\n",
    "        #    datasets.STL10('/content/drive/My Drive/', split=\"test\", transform=transforms.ToTensor(),download=True),\n",
    "        #batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        device = torch.device(\"cuda\" if  torch.cuda.is_available() else \"cpu\")\n",
    "        train(self.vae_net,self.optimizerD,self.train_loader)\n",
    "        loss=test(self.vae_net,self.test_loader)\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64,self.dimbotle).to(device)\n",
    "            sample = self.vae_net.decoder(sample).cpu()\n",
    "            save_image(sample.view(64, 3, cst, cst),path +'sample_' + str(os.getpid()) + '.png')\n",
    "\n",
    "    \n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        torch.save({\n",
    "            \"netDmodel\": self.vae_net.state_dict(),\n",
    "            \"optimD\": self.optimizerD.state_dict(),\n",
    "\n",
    "        }, path)\n",
    "\n",
    "        return checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_dir):\n",
    "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        checkpoint = torch.load(path)\n",
    "        self.vae_net.load_state_dict(checkpoint[\"netDmodel\"])\n",
    "        self.optimizerD.load_state_dict(checkpoint[\"optimD\"])\n",
    "\n",
    "    def reset_config(self, new_config):\n",
    "        if \"lr\" in new_config:\n",
    "            for param_group in self.optimizerD.param_groups:\n",
    "                param_group[\"lr\"] = 10**-(new_config.get(\"lr\", 0))\n",
    "        if \"b1\" in new_config:\n",
    "            for param_group in self.optimizerD.param_groups:\n",
    "                param_group[\"betas\"] = (\n",
    "                    1-10**-(new_config.get(\"b1\", 0)),1-10**-(new_config.get(\"b2\", 0)))\n",
    "        if \"wd\" in new_config:\n",
    "            for param_group in self.optimizerD.param_groups:\n",
    "                param_group[\"weight_decay\"] = 10**-(new_config.get(\"wd\", 0))\n",
    "        if \"eps\" in new_config:\n",
    "            for param_group in self.optimizerD.param_groups:\n",
    "                param_group[\"eps\"] = 10**-(new_config.get(\"eps\", 0))\n",
    "        self.config = new_config\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "#  model = VAE().to(device)\n",
    "#optimizer = adabelief_pytorch.AdaBelief(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy_with_logits(recon_x, x.view(-1, cst*cst*3), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train(model,optimizer,train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    device = torch.device(\"cuda\" if  torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for i in range(1):\n",
    "          train_loss = 0\n",
    "          for batch_idx, (data, _) in enumerate(train_loader):\n",
    "          #   if(batch_idx>10):\n",
    "            #      break\n",
    "              data = data.to(device)\n",
    "              optimizer.zero_grad()\n",
    "              recon_batch, mu, logvar = model(data)\n",
    "              loss = loss_function(recon_batch, data, mu, logvar)\n",
    "              loss.backward()\n",
    "              train_loss += loss.item()\n",
    "              optimizer.step()\n",
    "              del data\n",
    "       # if batch_idx % args.log_interval == 0:\n",
    "       #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "       #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "       #         100. * batch_idx / len(train_loader),\n",
    "       #         loss.item() / len(data)))\n",
    "\n",
    "    #print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "  #        epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    device = torch.device(\"cuda\" if   torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "          #  if(i>10):\n",
    "           #     break\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batchSize, 3, 32, 32)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                             path+ 'reconstruction_' + str(os.getpid()) + '.png', nrow=n)\n",
    "            del data\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    gc.collect()\n",
    "  #  tune.report(loss=test_loss)\n",
    " #   print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n",
    "#   if __name__ == \"__main__\":\n",
    "#      for epoch in range(1, args.epochs + 1):\n",
    "  #      train(epoch)\n",
    " #       test(epoch)\n",
    "#        with torch.no_grad():\n",
    "#             sample = torch.randn(64,int(config.get(\"d3\", 0))).to(device)\n",
    "#              sample = model.decode(sample).cpu()\n",
    "#               save_image(sample.view(64, 3, 96, 96),'/home/antoine/Projet/NovelTuning/sample_' + str(epoch) + '.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "algo = HyperOptSearch(metric=\"loss\",\n",
    "    mode=\"min\")\n",
    "name=\"hypher\"\n",
    "\n",
    "#algo = ConcurrencyLimiter(algo, max_concurrent=1)\n",
    "#os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "scheduler = PB2(\n",
    "    time_attr=\"training_iteration\",\n",
    "    perturbation_interval=3,\n",
    "    hyperparam_bounds={\n",
    "        # distribution for resampling\n",
    "     \"lr\": [1, 8] #tune.uniform(1e-4, 0.1 ),#,1e-4), #*10\n",
    ",     \"wd\":[1, 10]#tune.uniform(1, 5)#,1e-4), #*10 et 0\n",
    ",     \"b1\": [0, 2]#,1e-4), #*10 et 0\n",
    " ,    \"b2\": [1, 5] #,1e-4), #*10 et 0\n",
    " ,    \"eps\": [2, 10]#,1e-4), #*10 et 0\n",
    "    }) \n",
    "\n",
    "#   hyperparam_bounds={\n",
    "#        # distribution for resampling\n",
    "#     \"lr\":  lambda: np.random.uniform(1, 8) #tune.uniform(1e-4, 0.1 ),#,1e-4), #*10\n",
    "#,     \"wd\":lambda: np.random.uniform(1, 10)#tune.uniform(1, 5)#,1e-4), #*10 et 0\n",
    "#,     \"b1\": lambda: np.random.uniform(0, 2)#,1e-4), #*10 et 0\n",
    "# ,    \"b2\": lambda: np.random.uniform(1, 5)#,1e-4), #*10 et 0\n",
    "# ,    \"eps\": lambda: np.random.uniform(2, 10)#,1e-4), #*10 et 0\n",
    "#    })\n",
    "\n",
    "imageSize = 32\n",
    "\n",
    "cst=imageSize\n",
    "total=cst*cst*3\n",
    "def trial_name_id(trial):\n",
    "    return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "from ray import tune\n",
    "\n",
    "analysis = tune.run(\n",
    "PytorchTrainable,\n",
    "name=name,\n",
    "scheduler=scheduler,\n",
    "reuse_actors=True,\n",
    "search_alg=algo,\n",
    "verbose=2,\n",
    "checkpoint_at_end=True,\n",
    "num_samples=1024,\n",
    "# export_formats=[ExportFormat.MODEL],\n",
    "            config= {\n",
    " \"lr\":  tune.uniform(2.5, 8) #tune.uniform(1e-4, 0.1 ),#,1e-4), #*10\n",
    ",     \"wd\":tune.uniform(1, 10)#tune.uniform(1, 5)#,1e-4), #*10 et 0\n",
    ",     \"b1\": tune.uniform(0, 2)#,1e-4), #*10 et 0\n",
    " ,    \"b2\": tune.uniform(1, 5)#,1e-4), #*10 et 0\n",
    " ,    \"eps\": tune.uniform(2, 10)#,1e-4), #*10 et 0\n",
    "# ,    \"d1\": tune.uniform(27648/6, 27648/3)\n",
    "# ,    \"d2\": tune.uniform(27648/12, 27648/6)\n",
    "# ,    \"d3\": tune.uniform(27648/24, 27648/12)\n",
    "# ,    \"d4\": tune.uniform(27648/12, 27648/6)\n",
    "#,    \"d5\": tune.uniform(27648/6, 27648/3)\n",
    "\n",
    "                \n",
    "    },      stop={\n",
    "        \"training_iteration\": 10,\n",
    "    },        metric=\"loss\",\n",
    "    mode=\"min\",resources_per_trial={'gpu': 1}\n",
    "              loggers=[TestLogger])\n",
    ")\n",
    "#all_trials = analysis.trials\n",
    "#checkpoint_paths = [\n",
    "#    os.path.join(analysis.get_best_checkpoint(t), \"checkpoint\")\n",
    "#    for t in all_trials\n",
    "#] \n",
    "#demo_gan(checkpoint_paths) in\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
