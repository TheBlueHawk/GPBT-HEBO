{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 3 following cells aim at simuling the behavior of NN models with a simple model for MNIST\n",
    "\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "#This is a function that can be used by several NN model\n",
    "def train(model, optimizer ,func ,train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    #for (data, target) in train_loader:\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "           # print(\"hehe\")\n",
    "            return\n",
    "        # We set this just for the example to run quickly.\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#This is a function that can be used by several NN model (it only does accuracy ATM)\n",
    "def test(model, func, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "                \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random mnist from the internet to get a correct model to reason about\n",
    "\n",
    "class train_mnist():\n",
    "    def __init__(self,config):\n",
    "        \n",
    "        self.config = {\n",
    "       , \"sigmoid_func\": 1\n",
    "      ,  \"hidden_dim\":43\n",
    "      ,  \"n_layer\":2    }\n",
    "        for key, value in config.items():\n",
    "            self.config[key] = value\n",
    "        config = self.config\n",
    "        \n",
    "        self.i = 0\n",
    "        \n",
    "        mnist_transforms = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "            batch_size=64,\n",
    "            shuffle=True)\n",
    "        self.test_loader = DataLoader(\n",
    "            datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "            batch_size=64,\n",
    "            shuffle=True)\n",
    "\n",
    "        sigmoid_func_uniq = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.model = LeNet(192,int(round(config.get(\"hidden_dim\",64))),10,\n",
    "                    int( round(config.get(\"n_layer\",1))),\n",
    "                    config.get(\"droupout_prob\",0.1) ,sigmoid_func_uniq)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \n",
    "                                     betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\n",
    "                                    eps=config.get(\"eps\", 1e-08), \n",
    "                                     weight_decay=config.get(\"weight_decay\", 0), \n",
    "                                     amsgrad=True)\n",
    "\n",
    "    \n",
    "    def adapt(self, config):\n",
    "        for key, value in config.items():\n",
    "            self.config[key] = value\n",
    "        config = self.config\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \n",
    "                                     betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\n",
    "                                    eps=config.get(\"eps\", 1e-08), \n",
    "                                     weight_decay=config.get(\"weight_decay\", 0), \n",
    "                                     amsgrad=True)\n",
    "        return copy.deepcopy(self)\n",
    "    \n",
    "    \n",
    "# All NN models should have a function train1 and test1 that calls the common train and test defined above.\n",
    "# train1 and test1 is then used in the scheduler\n",
    "    def train1(self):\n",
    "        print(\"iteration: \" + str(self.i) )\n",
    "        self.i+=1\n",
    "        train(self.model, self.optimizer, F.nll_loss, self.train_loader)\n",
    "\n",
    "    def test1(self):\n",
    "        return test(self.model, F.nll_loss, self.test_loader)\n",
    "\n",
    "# This should be a hyperspace instead of constants.\n",
    "\n",
    "# __INCEPTION_SCORE_begin__\n",
    "class LeNet(nn.Module):\n",
    "    \"\"\"\n",
    "    LeNet for MNist classification, used for inception_score\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_dim, hidden_dim, output_dim, n_layers,\n",
    "                 drop_prob, sigmoid ):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# Convolution Neural network using Pytorch \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,input_dim, hidden_dim, output_dim, n_layers,\n",
    "                 drop_prob, sigmoid ):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.sigmoid = sigmoid\n",
    "        self.i_d = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.first= nn.Linear(input_dim, hidden_dim)\n",
    "        self.hidden = [nn.Linear(hidden_dim,hidden_dim) for _ in range(self.n_layers)]\n",
    "        self.drop_out = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.last = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, self.i_d)\n",
    "        x=self.first(x)\n",
    "        x=self.drop_out(x)\n",
    "        for i in range(self.n_layers):\n",
    "            x=self.hidden[i](x)\n",
    "            x=self.drop_out(x)\n",
    "        x = self.last(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_linear_reg = {\n",
    "    \"lr\": 0.031,\n",
    "    \"l2_regularization\": .01,\n",
    "    \"minibatch_size\": 512,\n",
    "    \"hidden_dims\": [150, 100, 75],\n",
    "    \"droupout_prob\": 0.28,\n",
    "    \"weight_decay\": .017,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "class LinearReg(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(LinearReg, self).__init__()\n",
    "\n",
    "        hidden_dims = config.get(\"hidden_dims\", [150, 100, 75])\n",
    "        self.linears = nn.ModuleList([nn.Linear(28*28, hidden_dims[0], bias=True), nn.ReLU()])\n",
    "        for i in range(1, len(hidden_dims) ):\n",
    "            self.linears.append(nn.Linear(hidden_dims[i-1], hidden_dims[i], bias=True))\n",
    "            self.linears.append(nn.ReLU())\n",
    "        self.model = Net(self.linears) \n",
    "\n",
    "        mnist_transforms = transforms.Compose([transforms.ToTensor(), \\\n",
    "                                               transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "        self.train_loader = DataLoader(datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\\\n",
    "                                       batch_size=config.get(\"batch_size\", 64), shuffle=True)\n",
    "\n",
    "        self.test_loader = DataLoader(datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\\\n",
    "                                      batch_size=config.get(\"batch_size\", 64), shuffle=True)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \n",
    "                                     betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\n",
    "                                    eps=config.get(\"eps\", 1e-08), \n",
    "                                     weight_decay=config.get(\"weight_decay\", 0), \n",
    "                                     amsgrad=True)\n",
    "    def adapt(self, config):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\", 0.01), \\\n",
    "                                          betas=((config.get(\"b1\", 0.999),config.get(\"b2\", 0.9999))),\\\n",
    "                                          eps=config.get(\"eps\", 1e-08), weight_decay=config.get(\"weight_decay\", 0), \\\n",
    "                                          amsgrad=True)\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.linears):\n",
    "            x = l(x)\n",
    "        return x     \n",
    "    \n",
    "    def train1(self):\n",
    "        train(self.model, self.optimizer, F.nll_loss, self.train_loader)\n",
    "\n",
    "    def test1(self):\n",
    "        return test(self.model, F.nll_loss, self.test_loader)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self,linears):\n",
    "        super(Net, self).__init__()\n",
    "        self.linears = linears\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.linears):\n",
    "            x = layer(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 5 required positional arguments: 'hidden_dim', 'output_dim', 'n_layers', 'drop_prob', and 'sigmoid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-809977c7ece2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-1ec818f111ed>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         mnist_transforms = transforms.Compose([transforms.ToTensor(), \\\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 5 required positional arguments: 'hidden_dim', 'output_dim', 'n_layers', 'drop_prob', and 'sigmoid'"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": 0.031,\n",
    "    \"l2_regularization\": .01,\n",
    "    \"minibatch_size\": 512,\n",
    "    \"hidden_dims\": [150, 100, 75],\n",
    "    \"droupout_prob\": 0.28,\n",
    "    \"weight_decay\": .017,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "a = LinearReg(config)\n",
    "a.train1()\n",
    "print(a.test1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "0.1714\n"
     ]
    }
   ],
   "source": [
    "# A random mnist from the internet to get a correct model to reason about\n",
    "\n",
    "class toy():\n",
    "    def __init__(self,config):\n",
    "        self.hyperparameter = config.get(\"lr\",0)\n",
    "    \n",
    "    def adapt(self,config):\n",
    "        self.hyperparameter = config.get(\"lr\",0)\n",
    "        return self\n",
    "    \n",
    "    def train1(self):\n",
    "        self.hyperparameter = self.hyperparameter * 2 \n",
    "    def test1(self):\n",
    "        return self.hyperparameter\n",
    "\n",
    "# This should be a hyperspace instead of constants.\n",
    "config= {\n",
    "     \"lr\": 0.031\n",
    "}\n",
    "a = train_mnist(config)\n",
    "a.train1()\n",
    "print(a.test1())\n",
    "\n",
    "class Parent():\n",
    "    def __init__(self,hyperspace,configuration, model, loss):\n",
    "        \n",
    "        self.hyperspace = hyperspace\n",
    "        self.configuration_list = np.array(configuration) \n",
    "        self.loss_list = [np.array(loss)] \n",
    "        self.model = model\n",
    "    \n",
    "    def update(self,configuration,loss, model):\n",
    "        self.configuration_list = np.append(self.configuration_list,configuration) \n",
    "        self.loss_list = np.append(self.loss_list,loss)\n",
    "        self.model = model\n",
    "    \n",
    "    def get_hyperspace(self):\n",
    "        return self.hyperspace\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3674\n"
     ]
    }
   ],
   "source": [
    "a.train1()\n",
    "print(a.test1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "a.train1()\n",
    "print(a.test1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " lr, 0.07533558198243544\n",
      "dropout_prob, 0.693140938181428                       \n",
      "weight_decay, 0.23867346786112376                     \n",
      "iteration: 0                                          \n",
      "accuracy, 0.0932                                      \n",
      "                                                                     \n",
      " lr, 0.0845619699486023\n",
      "dropout_prob, 0.746749775007297                                      \n",
      "weight_decay, 0.1500726587336071                                     \n",
      "iteration: 0                                                         \n",
      "accuracy, 0.204                                                      \n",
      "                                                                     \n",
      " lr, 0.09664422978578663\n",
      "dropout_prob, 0.931574790684421                                     \n",
      "weight_decay, 0.08278096295636182                                   \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.1295                                                    \n",
      "                                                                    \n",
      " lr, 0.0016019136976878762\n",
      "dropout_prob, 0.02769814155575645                                   \n",
      "weight_decay, 0.9474927240210134                                    \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.0803                                                    \n",
      "                                                                    \n",
      " lr, 0.032926445567769115\n",
      "dropout_prob, 0.2656982452893489                                    \n",
      "weight_decay, 0.6854184377802862                                    \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.0892                                                    \n",
      "                                                                    \n",
      " lr, 0.05463787360396424\n",
      "dropout_prob, 0.962202164943893                                     \n",
      "weight_decay, 0.43692987775743825                                   \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.1016                                                    \n",
      "                                                                    \n",
      " lr, 0.09789422084622061\n",
      "dropout_prob, 0.5506912082502535                                    \n",
      "weight_decay, 0.002188442688189074                                  \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.1032                                                    \n",
      "                                                                    \n",
      " lr, 0.024029959838283505\n",
      "dropout_prob, 0.27143549520681987                                   \n",
      "weight_decay, 0.5838746511951554                                    \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.1028                                                    \n",
      "                                                                    \n",
      " lr, 0.06854877914996219\n",
      "dropout_prob, 0.742692103638581                                     \n",
      "weight_decay, 0.323154168498596                                     \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.098                                                     \n",
      "                                                                    \n",
      " lr, 0.0828903749929641\n",
      "dropout_prob, 0.36420205990855653                                   \n",
      "weight_decay, 0.8295741204562922                                    \n",
      "iteration: 0                                                        \n",
      "accuracy, 0.1028                                                    \n",
      "                                                                     \n",
      " lr, 0.002247286005754412\n",
      "dropout_prob, 0.07758383187869344                                    \n",
      "weight_decay, 0.15491352900781669                                    \n",
      "iteration: 0                                                         \n",
      "accuracy, 0.3934                                                     \n",
      "                                                                      \n",
      " lr, 0.0019378341475183125\n",
      "dropout_prob, 0.018544517508434832                                    \n",
      "weight_decay, 0.40321554195692266                                     \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.1032                                                      \n",
      "                                                                      \n",
      " lr, 0.02000124343068037\n",
      "dropout_prob, 0.1266755951478436                                      \n",
      "weight_decay, 0.6179345538732216                                      \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.1098                                                      \n",
      "                                                                      \n",
      " lr, 0.043533738455741024\n",
      "dropout_prob, 0.47742285103510673                                     \n",
      "weight_decay, 0.9907559460558928                                      \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.1009                                                      \n",
      "                                                                      \n",
      " lr, 0.01165179609645435\n",
      "dropout_prob, 0.1262996679418224                                      \n",
      "weight_decay, 0.019994535853863737                                    \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.3936                                                      \n",
      "                                                                      \n",
      " lr, 0.014416417634842617\n",
      "dropout_prob, 0.1906880310841308                                      \n",
      "weight_decay, 0.005237953365799297                                    \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.252                                                       \n",
      "                                                                      \n",
      " lr, 0.05457372838916046\n",
      "dropout_prob, 0.45033540296432023                                     \n",
      "weight_decay, 0.7926384398821121                                      \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.0958                                                      \n",
      "                                                                      \n",
      " lr, 0.00930955796726117\n",
      "dropout_prob, 0.0982024380170142                                      \n",
      "weight_decay, 0.18300263872611863                                     \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.2092                                                      \n",
      "                                                                      \n",
      " lr, 0.03069250166621038\n",
      "dropout_prob, 0.018751422972881855                                    \n",
      "weight_decay, 0.2814366674781253                                      \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.0974                                                      \n",
      "                                                                      \n",
      " lr, 0.0012390938956661005\n",
      "dropout_prob, 0.2110992173359204                                      \n",
      "weight_decay, 0.0786148106230582                                      \n",
      "iteration: 0                                                          \n",
      "accuracy, 0.2007                                                      \n",
      "100%|██████████| 20/20 [00:48<00:00,  2.43s/trial, best loss: -0.3936]\n",
      "\n",
      " loss of parent -0.3936\n",
      "\n",
      " loss [array(-0.3936)]\n",
      "                                                       \n",
      " lr, 0.00996788336826355\n",
      "dropout_prob, 0.35749594238412274                               \n",
      "weight_decay, 0.004725061150271152                              \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.669                                                 \n",
      "100%|██████████| 21/21 [00:03<00:00,  6.89trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.04187371733378621\n",
      "dropout_prob, 0.3553931751527205                                \n",
      "weight_decay, 0.0016383884283431081                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1                                                    \n",
      "accuracy, 0.1776                                                \n",
      "100%|██████████| 22/22 [00:02<00:00,  9.93trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.014072665611075305\n",
      "dropout_prob, 0.5581414957908524                                \n",
      "weight_decay, 0.369921037600242                                 \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.098                                                 \n",
      "100%|██████████| 23/23 [00:02<00:00, 10.55trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.026009679432969002\n",
      "dropout_prob, 0.39196835366412996                               \n",
      "weight_decay, 0.0769975868942736                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.0892                                                \n",
      "100%|██████████| 24/24 [00:02<00:00, 10.95trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.03651824022850986\n",
      "dropout_prob, 0.3010991161873983                                \n",
      "weight_decay, 0.4884498168334255                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1072                                                \n",
      "100%|██████████| 25/25 [00:02<00:00, 11.01trial/s, best loss: -0.669]\n",
      "\n",
      " loss of parent -0.3934\n",
      "\n",
      " loss [array(-0.3934)]\n",
      "                                                       \n",
      " lr, 0.041778624324717385\n",
      "dropout_prob, 0.372419430740062                                 \n",
      "weight_decay, 0.0049472644874550276                             \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 21/21 [00:02<00:00,  9.31trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.016714460731298016\n",
      "dropout_prob, 0.11826841722849135                               \n",
      "weight_decay, 0.1335522020268725                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.2275                                                \n",
      "100%|██████████| 22/22 [00:02<00:00, 10.01trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.007314920080755145\n",
      "dropout_prob, 0.5682067048012126                                \n",
      "weight_decay, 0.36675145422606764                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.2496                                                \n",
      "100%|██████████| 23/23 [00:02<00:00, 10.05trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.0274550196169034\n",
      "dropout_prob, 0.3210964615868639                                \n",
      "weight_decay, 0.2343496152914616                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 24/24 [00:02<00:00, 10.72trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.03785869731867364\n",
      "dropout_prob, 0.0017205112107086945                             \n",
      "weight_decay, 0.07999756347852113                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.0974                                                \n",
      "100%|██████████| 25/25 [00:02<00:00, 10.86trial/s, best loss: -0.3936]\n",
      "\n",
      " loss of parent -0.252\n",
      "\n",
      " loss [array(-0.252)]\n",
      "                                                       \n",
      " lr, 0.04088906125667891\n",
      "dropout_prob, 0.32410372660096215                               \n",
      "weight_decay, 0.0028441722998432117                             \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.348                                                 \n",
      "100%|██████████| 21/21 [00:02<00:00,  9.15trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.00839680052769613\n",
      "dropout_prob, 0.10673260872674867                               \n",
      "weight_decay, 0.11025769294056176                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.3683                                                \n",
      "100%|██████████| 22/22 [00:02<00:00,  9.50trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.019242638018383478\n",
      "dropout_prob, 0.38184202942073675                               \n",
      "weight_decay, 0.21195534819158604                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.101                                                 \n",
      "100%|██████████| 23/23 [00:02<00:00, 10.29trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.027290806403262844\n",
      "dropout_prob, 0.5925376586110065                                \n",
      "weight_decay, 0.4375734085622902                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 24/24 [00:02<00:00, 10.40trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.014591995939973724\n",
      "dropout_prob, 0.0009250607171153585                             \n",
      "weight_decay, 0.3302916132337769                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.101                                                 \n",
      "100%|██████████| 25/25 [00:02<00:00, 10.75trial/s, best loss: -0.3936]\n",
      "\n",
      " loss of parent -0.2092\n",
      "\n",
      " loss [array(-0.2092)]\n",
      "                                                       \n",
      " lr, 0.011234857840589375\n",
      "dropout_prob, 0.35597138338520096                               \n",
      "weight_decay, 0.08235476112931417                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.3827                                                \n",
      "100%|██████████| 21/21 [00:02<00:00,  8.66trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.04133091607211377\n",
      "dropout_prob, 0.10364416881235192                               \n",
      "weight_decay, 0.35532413447783984                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 22/22 [00:02<00:00,  9.81trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.02713255245915277\n",
      "dropout_prob, 0.637569645160031                                 \n",
      "weight_decay, 0.48983808493878805                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.101                                                 \n",
      "100%|██████████| 23/23 [00:02<00:00, 10.20trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.007071861889960506\n",
      "dropout_prob, 0.35584207166615417                               \n",
      "weight_decay, 0.19231329823579357                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.2478                                                \n",
      "100%|██████████| 24/24 [00:02<00:00, 10.24trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.01923235094682575\n",
      "dropout_prob, 0.0026415550728182413                             \n",
      "weight_decay, 0.011154676504950709                              \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1151                                                \n",
      "100%|██████████| 25/25 [00:02<00:00, 10.46trial/s, best loss: -0.3936]\n",
      "[-0.669  -0.1776 -0.098  -0.0892 -0.1135 -0.2275 -0.2496 -0.1135 -0.348\n",
      " -0.3683 -0.101  -0.1028 -0.3827 -0.1135 -0.101  -0.2478 -0.1151 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 0 12  9  8  6 15  5 17 19  1 16  4  7 13 11 10 14  2 18  3]\n",
      "\n",
      " loss of parent -0.669\n",
      "\n",
      " loss [-0.3936 -0.669 ]\n",
      "                                                       \n",
      " lr, 0.010369321425054912\n",
      "dropout_prob, 0.17875742649594725                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay, 0.2494164522901307                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.566                                                 \n",
      "100%|██████████| 26/26 [00:03<00:00,  7.97trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.06290662030590038\n",
      "dropout_prob, 0.6095316985448869                                \n",
      "weight_decay, 0.21708388923685676                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1536                                                \n",
      "100%|██████████| 27/27 [00:03<00:00,  8.17trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.01923843644468677\n",
      "dropout_prob, 0.22008344628588658                               \n",
      "weight_decay, 0.33298016533347335                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1527                                                \n",
      "100%|██████████| 28/28 [00:03<00:00,  8.26trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.008665337841675239\n",
      "dropout_prob, 0.6319941571594012                                \n",
      "weight_decay, 0.2613656932362652                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.6166                                                \n",
      "100%|██████████| 29/29 [00:03<00:00,  8.97trial/s, best loss: -0.669]\n",
      "                                                       \n",
      " lr, 0.043371256374963835\n",
      "dropout_prob, 0.8819336109744067                                \n",
      "weight_decay, 0.5327687580034419                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1011                                                \n",
      "100%|██████████| 30/30 [00:02<00:00, 12.19trial/s, best loss: -0.669]\n",
      "\n",
      " loss of parent -0.3827\n",
      "\n",
      " loss [-0.252  -0.3827]\n",
      "                                                       \n",
      " lr, 0.03571581179244697\n",
      "dropout_prob, 0.1750158109538101                                \n",
      "weight_decay, 0.04121824576456662                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.138                                                 \n",
      "100%|██████████| 26/26 [00:02<00:00, 10.54trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.005986076126775198\n",
      "dropout_prob, 0.0653951022300149                                \n",
      "weight_decay, 0.1445881958927127                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.5205                                                \n",
      "100%|██████████| 27/27 [00:03<00:00,  7.99trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.06092149616200967\n",
      "dropout_prob, 0.256779385586838                                 \n",
      "weight_decay, 0.36353261805671205                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.19                                                  \n",
      "100%|██████████| 28/28 [00:03<00:00,  9.09trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.04559342438493119\n",
      "dropout_prob, 0.8479822347980644                                \n",
      "weight_decay, 0.5010543805778005                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.0894                                                \n",
      "100%|██████████| 29/29 [00:02<00:00, 12.89trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.00926604514779155\n",
      "dropout_prob, 0.41141672241308097                               \n",
      "weight_decay, 0.2567308793295782                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.3662                                                \n",
      "100%|██████████| 30/30 [00:03<00:00,  9.53trial/s, best loss: -0.5205]\n",
      "\n",
      " loss of parent -0.3683\n",
      "\n",
      " loss [-0.3934 -0.3683]\n",
      "                                                       \n",
      " lr, 0.009502749462860463\n",
      "dropout_prob, 0.17693440075510175                               \n",
      "weight_decay, 0.5353100873937983                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.132                                                 \n",
      "100%|██████████| 26/26 [00:02<00:00, 12.04trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.06356797874466143\n",
      "dropout_prob, 0.10049498274497619                               \n",
      "weight_decay, 0.46339784609082085                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.0773                                                \n",
      "100%|██████████| 27/27 [00:02<00:00, 12.17trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.02325502846809968\n",
      "dropout_prob, 0.398540531360264                                 \n",
      "weight_decay, 0.20405776802263287                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 28/28 [00:02<00:00, 12.42trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.013798181981263202\n",
      "dropout_prob, 0.6120419688227519                                \n",
      "weight_decay, 0.3011735224498531                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.3365                                                \n",
      "100%|██████████| 29/29 [00:03<00:00,  8.58trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.047613422660892635\n",
      "dropout_prob, 0.8250737202905556                                \n",
      "weight_decay, 0.0621796558317082                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.2769                                                \n",
      "100%|██████████| 30/30 [00:03<00:00,  8.82trial/s, best loss: -0.3936]\n",
      "\n",
      " loss of parent -0.348\n",
      "\n",
      " loss [-0.3934 -0.348 ]\n",
      "                                                       \n",
      " lr, 0.011173746882302098\n",
      "dropout_prob, 0.1744969218603884                                \n",
      "weight_decay, 0.5240565880994069                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 26/26 [00:02<00:00, 11.17trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.06259285083086483\n",
      "dropout_prob, 0.07503042298822424                               \n",
      "weight_decay, 0.18921792322733852                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1086                                                \n",
      "100%|██████████| 27/27 [00:02<00:00, 12.54trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.02277770152059748\n",
      "dropout_prob, 0.4221335789400252                                \n",
      "weight_decay, 0.5004356921065534                                \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.0892                                                \n",
      "100%|██████████| 28/28 [00:02<00:00, 11.82trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.005646864084280523\n",
      "dropout_prob, 0.636845653543951                                 \n",
      "weight_decay, 0.29358887932380817                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.2643                                                \n",
      "100%|██████████| 29/29 [00:03<00:00,  9.05trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.046208656822658095\n",
      "dropout_prob, 0.275351295667996                                 \n",
      "weight_decay, 0.23349591122441463                               \n",
      "iteration: 2                                                    \n",
      "accuracy, 0.1135                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 12.92trial/s, best loss: -0.3936]\n",
      "[-0.566  -0.1536 -0.1527 -0.6166 -0.138  -0.5205 -0.19   -0.0894 -0.132\n",
      " -0.0773 -0.1028 -0.3365 -0.1135 -0.1086 -0.0892 -0.2643 -0.1135 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 3  0  5 11 15 17 19  6  1  2  4  8 12 16 13 10 18  7 14  9]\n",
      "\n",
      " loss of parent -0.6166\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166]\n",
      "                                                       \n",
      " lr, 0.006050530587450748\n",
      "dropout_prob, 0.6221405348692626                                \n",
      "weight_decay, 0.1064705226453958                                \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.7815                                                \n",
      "100%|██████████| 31/31 [00:03<00:00,  9.41trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.026688497689751685\n",
      "dropout_prob, 0.7063946256626648                                \n",
      "weight_decay, 0.13448942677276504                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.1136                                                \n",
      "100%|██████████| 32/32 [00:02<00:00, 14.50trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.019629552191321186\n",
      "dropout_prob, 0.8287977209381888                                \n",
      "weight_decay, 0.09387527821029548                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.585                                                 \n",
      "100%|██████████| 33/33 [00:02<00:00, 14.94trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.00486372567715738\n",
      "dropout_prob, 0.4254307195747476                                \n",
      "weight_decay, 0.18344488980817897                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.7738                                                \n",
      "100%|██████████| 34/34 [00:03<00:00, 10.00trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.07802325734193247\n",
      "dropout_prob, 0.8215951217178561                                \n",
      "weight_decay, 0.21121071781303627                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.1156                                                \n",
      "100%|██████████| 35/35 [00:02<00:00, 15.01trial/s, best loss: -0.7815]\n",
      "\n",
      " loss of parent -0.566\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566 ]\n",
      "                                                       \n",
      " lr, 0.006764586624156613\n",
      "dropout_prob, 0.6632361873859359                                \n",
      "weight_decay, 0.11763973047365986                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.7166                                                \n",
      "100%|██████████| 31/31 [00:02<00:00, 13.50trial/s, best loss: -0.7166]\n",
      "                                                       \n",
      " lr, 0.02427657349341858\n",
      "dropout_prob, 0.8221238617252478                                \n",
      "weight_decay, 0.11353260740476759                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.2051                                                \n",
      "100%|██████████| 32/32 [00:02<00:00, 13.15trial/s, best loss: -0.7166]\n",
      "                                                       \n",
      " lr, 0.05124012248624484\n",
      "dropout_prob, 0.7189717954053564                                \n",
      "weight_decay, 0.13181850833770248                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.164                                                 \n",
      "100%|██████████| 33/33 [00:02<00:00, 13.51trial/s, best loss: -0.7166]\n",
      "                                                       \n",
      " lr, 0.005643747159157414\n",
      "dropout_prob, 0.8016215468733281                                \n",
      "weight_decay, 0.05262387749449324                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.7877                                                \n",
      "100%|██████████| 34/34 [00:02<00:00, 15.07trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.07785591985880497\n",
      "dropout_prob, 0.8327328721022044                                \n",
      "weight_decay, 0.20489790138896602                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.1373                                                \n",
      "100%|██████████| 35/35 [00:02<00:00, 15.48trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.5205\n",
      "\n",
      " loss [-0.252  -0.3827 -0.5205]\n",
      "                                                       \n",
      " lr, 0.022764861870876178\n",
      "dropout_prob, 0.5913136039254634                                \n",
      "weight_decay, 0.24171503958452484                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 31/31 [00:02<00:00, 13.03trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.03786038495032011\n",
      "dropout_prob, 0.6473238240680641                                \n",
      "weight_decay, 0.12955069265463626                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.0762                                                \n",
      "100%|██████████| 32/32 [00:02<00:00, 14.24trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.07065920436286482\n",
      "dropout_prob, 0.1760572193308224                                \n",
      "weight_decay, 0.510723289969546                                 \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.1621                                                \n",
      "100%|██████████| 33/33 [00:02<00:00, 14.81trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.013584409673165883\n",
      "dropout_prob, 0.3073023650515101                                \n",
      "weight_decay, 0.06201059953146113                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.3881                                                \n",
      "100%|██████████| 34/34 [00:02<00:00, 14.86trial/s, best loss: -0.5205]\n",
      "                                                       \n",
      " lr, 0.08960602328905742\n",
      "dropout_prob, 0.8820221396781049                                \n",
      "weight_decay, 0.17603696175419825                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.098                                                 \n",
      "100%|██████████| 35/35 [00:03<00:00, 11.07trial/s, best loss: -0.5205]\n",
      "\n",
      " loss of parent -0.3365\n",
      "\n",
      " loss [-0.3934 -0.3683 -0.3365]\n",
      "                                                       \n",
      " lr, 0.00021549012456378858\n",
      "dropout_prob, 0.28375460924395773                               \n",
      "weight_decay, 0.1660264969076119                                \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.305                                                 \n",
      "100%|██████████| 31/31 [00:03<00:00, 10.09trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.03501473930922249\n",
      "dropout_prob, 0.06133590336107933                               \n",
      "weight_decay, 0.2504774968321656                                \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 32/32 [00:03<00:00, 10.38trial/s, best loss: -0.3936]\n",
      "                                                       \n",
      " lr, 0.0078792625187027\n",
      "dropout_prob, 0.21931791322231609                               \n",
      "weight_decay, 0.12318239300771769                               \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.4428                                                \n",
      "100%|██████████| 33/33 [00:02<00:00, 14.89trial/s, best loss: -0.4428]\n",
      "                                                       \n",
      " lr, 0.08818908678543491\n",
      "dropout_prob, 0.21875428366328198                               \n",
      "weight_decay, 0.03471235491548079                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 34/34 [00:03<00:00, 11.32trial/s, best loss: -0.4428]\n",
      "                                                       \n",
      " lr, 0.06376639562858674\n",
      "dropout_prob, 0.43775427675795486                               \n",
      "weight_decay, 0.1212760631468595                                \n",
      "iteration: 3                                                    \n",
      "accuracy, 0.0981                                                \n",
      "100%|██████████| 35/35 [00:02<00:00, 16.10trial/s, best loss: -0.4428]\n",
      "[-0.7815 -0.1136 -0.585  -0.7738 -0.7166 -0.2051 -0.164  -0.7877 -0.1028\n",
      " -0.0762 -0.1621 -0.3881 -0.305  -0.1028 -0.4428 -0.1028 -0.0981 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 7  0  3  4  2 14 11 12 17  5 19  6 10  1  8 13 15 16 18  9]\n",
      "\n",
      " loss of parent -0.7877\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877]\n",
      "                                                       \n",
      " lr, 0.03177763211281947\n",
      "dropout_prob, 0.6597009541642591                                \n",
      "weight_decay, 0.04962519599820227                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 36/36 [00:02<00:00, 16.34trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.018498406443708808\n",
      "dropout_prob, 0.9786117312072035                                \n",
      "weight_decay, 0.47122512463264826                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.2033                                                \n",
      "100%|██████████| 37/37 [00:03<00:00, 11.99trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.06101623214264416\n",
      "dropout_prob, 0.9167746638433104                                \n",
      "weight_decay, 0.7236583867202618                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.098                                                 \n",
      "100%|██████████| 38/38 [00:02<00:00, 17.36trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.006248998020473923\n",
      "dropout_prob, 0.8476266091451442                                \n",
      "weight_decay, 0.3125545660094927                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.7457                                                \n",
      "100%|██████████| 39/39 [00:02<00:00, 18.41trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.08753219698483256\n",
      "dropout_prob, 0.7897150570822539                                \n",
      "weight_decay, 0.33358220765680263                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1038                                                \n",
      "100%|██████████| 40/40 [00:02<00:00, 13.52trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.7815\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7815]\n",
      "                                                       \n",
      " lr, 0.03587484550904139\n",
      "dropout_prob, 0.6433760351438724                                \n",
      "weight_decay, 0.47266777650032743                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.0375                                                \n",
      "100%|██████████| 36/36 [00:02<00:00, 16.11trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.004889944701957607\n",
      "dropout_prob, 0.5318965126121064                                \n",
      "weight_decay, 0.12267315161680326                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.7146                                                \n",
      "100%|██████████| 37/37 [00:02<00:00, 16.86trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.04983561596380178\n",
      "dropout_prob, 0.4476194687453471                                \n",
      "weight_decay, 0.6830675834056752                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 38/38 [00:03<00:00, 12.32trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.08758381430632302\n",
      "dropout_prob, 0.6826170740433362                                \n",
      "weight_decay, 0.30385876701868314                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1019                                                \n",
      "100%|██████████| 39/39 [00:03<00:00, 12.11trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.06015641122565861\n",
      "dropout_prob, 0.7882942889128843                                \n",
      "weight_decay, 0.3850001176865184                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.071                                                 \n",
      "100%|██████████| 40/40 [00:02<00:00, 17.81trial/s, best loss: -0.7815]\n",
      "\n",
      " loss of parent -0.7738\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738]\n",
      "                                                       \n",
      " lr, 0.09153254811391068\n",
      "dropout_prob, 0.6579247045736138                                \n",
      "weight_decay, 0.4646690108998189                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1098                                                \n",
      "100%|██████████| 36/36 [00:02<00:00, 15.41trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.03472540743750309\n",
      "dropout_prob, 0.43255965375236866                               \n",
      "weight_decay, 0.12041129925478128                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 37/37 [00:02<00:00, 16.00trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.04941627336049361\n",
      "dropout_prob, 0.557679244690971                                 \n",
      "weight_decay, 0.31903134674326006                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.0958                                                \n",
      "100%|██████████| 38/38 [00:02<00:00, 16.91trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.06563732483902379\n",
      "dropout_prob, 0.992913508349218                                 \n",
      "weight_decay, 0.6749230496465073                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1009                                                \n",
      "100%|██████████| 39/39 [00:02<00:00, 18.07trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.004748331751187509\n",
      "dropout_prob, 0.5191732456457092                                \n",
      "weight_decay, 0.043849153741131935                              \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.804                                                 \n",
      "100%|██████████| 40/40 [00:03<00:00, 12.23trial/s, best loss: -0.804]\n",
      "\n",
      " loss of parent -0.7166\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7166]\n",
      "                                                       \n",
      " lr, 0.0355891605750492\n",
      "dropout_prob, 0.6525622040529176                                \n",
      "weight_decay, 0.45943489940537896                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 36/36 [00:02<00:00, 13.09trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.0001572951406282365\n",
      "dropout_prob, 0.5161901789645439                               \n",
      "weight_decay, 0.12403506202229775                              \n",
      "iteration: 4                                                   \n",
      "accuracy, 0.7533                                               \n",
      "100%|██████████| 37/37 [00:02<00:00, 12.81trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.061793226271800936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout_prob, 0.5688761563020416                                \n",
      "weight_decay, 0.3200887851193691                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1953                                                \n",
      "100%|██████████| 38/38 [00:02<00:00, 16.85trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.04942818754483203\n",
      "dropout_prob, 0.40419092632936665                               \n",
      "weight_decay, 0.7070509751556157                                \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.1245                                                \n",
      "100%|██████████| 39/39 [00:02<00:00, 16.64trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.0910178432169928\n",
      "dropout_prob, 0.7907724489767428                                \n",
      "weight_decay, 0.40209520828113404                               \n",
      "iteration: 4                                                    \n",
      "accuracy, 0.06                                                  \n",
      "100%|██████████| 40/40 [00:02<00:00, 16.01trial/s, best loss: -0.7815]\n",
      "[-0.1135 -0.2033 -0.098  -0.7457 -0.0375 -0.7146 -0.1135 -0.1019 -0.1098\n",
      " -0.1135 -0.0958 -0.1009 -0.1135 -0.7533 -0.1953 -0.1245 -0.06   -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[13  3  5 17  1 19 14 15 12  0  6  9  8  7 11  2 18 10 16  4]\n",
      "\n",
      " loss of parent -0.7533\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738 -0.7533]\n",
      "                                                       \n",
      " lr, 0.0050792407741197965\n",
      "dropout_prob, 0.7926059053519605                                \n",
      "weight_decay, 0.04896338627983173                               \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.8304                                                \n",
      "100%|██████████| 41/41 [00:02<00:00, 17.17trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.015872742320231593\n",
      "dropout_prob, 0.7754595474440986                                \n",
      "weight_decay, 0.9046217410468431                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.1026                                                \n",
      "100%|██████████| 42/42 [00:02<00:00, 18.12trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.02932821513180886\n",
      "dropout_prob, 0.9342490442099758                                \n",
      "weight_decay, 0.03355955052526322                               \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.3287                                                \n",
      "100%|██████████| 43/43 [00:02<00:00, 16.40trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.023313412023328133\n",
      "dropout_prob, 0.8761917037593199                                \n",
      "weight_decay, 0.3955263393559484                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.1009                                                \n",
      "100%|██████████| 44/44 [00:03<00:00, 12.64trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.03826680641472721\n",
      "dropout_prob, 0.5315259136517935                                \n",
      "weight_decay, 0.5763751988865371                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.1018                                                \n",
      "100%|██████████| 45/45 [00:03<00:00, 13.52trial/s, best loss: -0.8304]\n",
      "\n",
      " loss of parent -0.7457\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457]\n",
      "                                                       \n",
      " lr, 0.039294448411983464\n",
      "dropout_prob, 0.988935992821302                                 \n",
      "weight_decay, 0.40333767272690557                               \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 41/41 [00:03<00:00, 12.36trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.09062788796022385\n",
      "dropout_prob, 0.8708979746266666                                \n",
      "weight_decay, 0.5547768116806934                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.101                                                 \n",
      "100%|██████████| 42/42 [00:02<00:00, 17.66trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.004053193800340353\n",
      "dropout_prob, 0.9355259697628875                                \n",
      "weight_decay, 0.6341963339916014                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.6454                                                \n",
      "100%|██████████| 43/43 [00:03<00:00, 13.42trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.027540661859074403\n",
      "dropout_prob, 0.7722795729249344                                \n",
      "weight_decay, 0.17055158295752276                               \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.0985                                                \n",
      "100%|██████████| 44/44 [00:02<00:00, 19.77trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.04687152995899685\n",
      "dropout_prob, 0.5497176858103059                                \n",
      "weight_decay, 0.2896826211411241                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.0958                                                \n",
      "100%|██████████| 45/45 [00:03<00:00, 14.40trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.7146\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7815 -0.7146]\n",
      "                                                       \n",
      " lr, 1.3124889162597492e-06\n",
      "dropout_prob, 0.9926019340499015                                \n",
      "weight_decay, 0.4405367069218915                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.7148                                                \n",
      "100%|██████████| 41/41 [00:02<00:00, 16.57trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.03032646769219692\n",
      "dropout_prob, 0.8963777806604025                                \n",
      "weight_decay, 0.04555238274872504                               \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 42/42 [00:03<00:00, 12.39trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.02117800564658026\n",
      "dropout_prob, 0.5828467947068214                                \n",
      "weight_decay, 0.5562343549956501                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 43/43 [00:03<00:00, 12.39trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.09321680364994418\n",
      "dropout_prob, 0.413739291690459                                 \n",
      "weight_decay, 0.34441127360310075                               \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.0958                                                \n",
      "100%|██████████| 44/44 [00:02<00:00, 17.76trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.06936728878126427\n",
      "dropout_prob, 0.5071034312861187                                \n",
      "weight_decay, 0.8939246299269723                                \n",
      "iteration: 5                                                    \n",
      "accuracy, 0.0956                                                \n",
      "100%|██████████| 45/45 [00:02<00:00, 17.15trial/s, best loss: -0.7815]\n",
      "\n",
      " loss of parent -0.2092\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7166 -0.2092]\n",
      "                                                       \n",
      " lr, 0.006114581375153632\n",
      "dropout_prob, 0.9207478189505469                                \n",
      "weight_decay, 0.16861848412393132                               \n",
      "iteration: 1                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 0.1874                                                \n",
      "100%|██████████| 41/41 [00:02<00:00, 15.58trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.030949177901648556\n",
      "dropout_prob, 0.9849186411211723                                \n",
      "weight_decay, 0.06719701682243173                               \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1061                                                \n",
      "100%|██████████| 42/42 [00:02<00:00, 16.06trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.004992783312678181\n",
      "dropout_prob, 0.713620253751165                                 \n",
      "weight_decay, 0.6343811130888085                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 43/43 [00:03<00:00, 12.47trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.01681608287991245\n",
      "dropout_prob, 0.44424110058908606                               \n",
      "weight_decay, 0.5453678281647972                                \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.0958                                                \n",
      "100%|██████████| 44/44 [00:02<00:00, 17.09trial/s, best loss: -0.7815]\n",
      "                                                       \n",
      " lr, 0.07271066154004457\n",
      "dropout_prob, 0.2982529457692908                                \n",
      "weight_decay, 0.300136937600782                                 \n",
      "iteration: 1                                                    \n",
      "accuracy, 0.1113                                                \n",
      "100%|██████████| 45/45 [00:03<00:00, 13.45trial/s, best loss: -0.7815]\n",
      "[-0.8304 -0.1026 -0.3287 -0.1009 -0.1028 -0.101  -0.6454 -0.0985 -0.7148\n",
      " -0.1135 -0.1135 -0.0958 -0.1874 -0.1061 -0.1135 -0.0958 -0.1113 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 0  8  6  2 17 19 12 10 14  9 16 13  4  1  5  3  7 18 11 15]\n",
      "\n",
      " loss of parent -0.8304\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738 -0.7533 -0.8304]\n",
      "                                                       \n",
      " lr, 0.048144818200967485\n",
      "dropout_prob, 0.6971282503648542                                \n",
      "weight_decay, 0.045389222202046844                              \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 46/46 [00:03<00:00, 14.06trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.05861163940166199\n",
      "dropout_prob, 0.7553850856396439                                \n",
      "weight_decay, 0.690660638380321                                 \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 47/47 [00:03<00:00, 14.64trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.07237987879846654\n",
      "dropout_prob, 0.5026759436389229                                \n",
      "weight_decay, 0.1634012371716203                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 48/48 [00:02<00:00, 22.71trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.0005498099509034897\n",
      "dropout_prob, 0.800142468943581                                 \n",
      "weight_decay, 0.4366674087707243                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.8407                                                \n",
      "100%|██████████| 49/49 [00:03<00:00, 15.69trial/s, best loss: -0.8407]\n",
      "                                                       \n",
      " lr, 8.273204455297792e-05\n",
      "dropout_prob, 0.9775181861201                                   \n",
      "weight_decay, 0.7865933486116019                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.8335                                                \n",
      "100%|██████████| 50/50 [00:03<00:00, 16.27trial/s, best loss: -0.8407]\n",
      "\n",
      " loss of parent -0.7148\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.7148]\n",
      "                                                       \n",
      " lr, 0.03480680500595831\n",
      "dropout_prob, 0.7121640324369                                   \n",
      "weight_decay, 0.45153126653449793                               \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1497                                                \n",
      "100%|██████████| 46/46 [00:03<00:00, 13.57trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.06841274505832193\n",
      "dropout_prob, 0.8493291706890319                                \n",
      "weight_decay, 0.4029363412959547                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.0906                                                \n",
      "100%|██████████| 47/47 [00:02<00:00, 20.03trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.019207997033631873\n",
      "dropout_prob, 0.5840131961086034                                \n",
      "weight_decay, 0.8501128037806077                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.098                                                 \n",
      "100%|██████████| 48/48 [00:02<00:00, 18.96trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.004956396478071149\n",
      "dropout_prob, 0.7750259612117812                                \n",
      "weight_decay, 0.669265956145404                                 \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.5232                                                \n",
      "100%|██████████| 49/49 [00:03<00:00, 12.49trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.00098634291390027\n",
      "dropout_prob, 0.5109583878203008                                \n",
      "weight_decay, 0.05552039001540506                               \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.8143                                                \n",
      "100%|██████████| 50/50 [00:02<00:00, 18.53trial/s, best loss: -0.8143]\n",
      "\n",
      " loss of parent -0.6454\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454]\n",
      "                                                       \n",
      " lr, 0.06846615137406882\n",
      "dropout_prob, 0.6949580314855469                                \n",
      "weight_decay, 0.4335110688203464                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1896                                                \n",
      "100%|██████████| 46/46 [00:03<00:00, 14.07trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.01601071814268925\n",
      "dropout_prob, 0.8781884450887317                                \n",
      "weight_decay, 0.3803099216733119                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.0982                                                \n",
      "100%|██████████| 47/47 [00:02<00:00, 20.27trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.00046066541487805625\n",
      "dropout_prob, 0.5934090045827443                                \n",
      "weight_decay, 0.8864529393802731                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.6473                                                \n",
      "100%|██████████| 48/48 [00:02<00:00, 20.77trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.021667692818124668\n",
      "dropout_prob, 0.7414423665741913                                \n",
      "weight_decay, 0.4504684684496224                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.0974                                                \n",
      "100%|██████████| 49/49 [00:03<00:00, 14.73trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.03687293043071922\n",
      "dropout_prob, 0.45076528126451615                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay, 0.6778687064268569                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 50/50 [00:03<00:00, 15.33trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.3287\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738 -0.7533 -0.3287]\n",
      "                                                       \n",
      " lr, 0.00047124184789688797\n",
      "dropout_prob, 0.718108892187628                                 \n",
      "weight_decay, 0.15001726652388933                               \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.3555                                                \n",
      "100%|██████████| 46/46 [00:02<00:00, 18.55trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.05128820084614362\n",
      "dropout_prob, 0.49805170489572814                               \n",
      "weight_decay, 0.7686751709566366                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1025                                                \n",
      "100%|██████████| 47/47 [00:03<00:00, 14.22trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.07195894388696958\n",
      "dropout_prob, 0.7938271142635618                                \n",
      "weight_decay, 0.06477283560977326                               \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 48/48 [00:03<00:00, 14.78trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.05729032037680134\n",
      "dropout_prob, 0.6653102430479302                                \n",
      "weight_decay, 0.4345505097195366                                \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1028                                                \n",
      "100%|██████████| 49/49 [00:02<00:00, 19.67trial/s, best loss: -0.8304]\n",
      "                                                       \n",
      " lr, 0.09026629301586142\n",
      "dropout_prob, 0.990049873101353                                 \n",
      "weight_decay, 0.28874514102965465                               \n",
      "iteration: 6                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 50/50 [00:02<00:00, 21.60trial/s, best loss: -0.8304]\n",
      "[-0.1135 -0.1135 -0.1135 -0.8407 -0.1497 -0.0906 -0.098  -0.5232 -0.1896\n",
      " -0.0982 -0.6473 -0.0974 -0.3555 -0.1025 -0.1135 -0.1028 -0.1135 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 3 10  7 12 17 19  8  4 16 14  0  2  1 15 13  9  6 11 18  5]\n",
      "\n",
      " loss of parent -0.8407\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738 -0.7533 -0.8304 -0.8407]\n",
      "                                                       \n",
      " lr, 0.054224408162726695\n",
      "dropout_prob, 0.9445263645350872                                \n",
      "weight_decay, 0.8004775351092865                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.0892                                                \n",
      "100%|██████████| 51/51 [00:03<00:00, 16.96trial/s, best loss: -0.8407]\n",
      "                                                       \n",
      " lr, 0.08753761943260925\n",
      "dropout_prob, 0.9953047336798477                                \n",
      "weight_decay, 0.8685309126382468                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1186                                                \n",
      "100%|██████████| 52/52 [00:02<00:00, 18.29trial/s, best loss: -0.8407]\n",
      "                                                       \n",
      " lr, 0.0006241266815313318\n",
      "dropout_prob, 0.8866424449106923                                \n",
      "weight_decay, 0.7507295363457084                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.842                                                 \n",
      "100%|██████████| 53/53 [00:02<00:00, 20.85trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.016253596953691028\n",
      "dropout_prob, 0.8824901392994977                                \n",
      "weight_decay, 0.7452844004270279                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1011                                                \n",
      "100%|██████████| 54/54 [00:03<00:00, 17.05trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.039168854398330996\n",
      "dropout_prob, 0.8544474051863238                                \n",
      "weight_decay, 0.9625450372669881                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.0276                                                \n",
      "100%|██████████| 55/55 [00:02<00:00, 24.67trial/s, best loss: -0.842]\n",
      "\n",
      " loss of parent -0.6473\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.6473]\n",
      "                                                       \n",
      " lr, 0.028544549367626584\n",
      "dropout_prob, 0.5031853228871441                                \n",
      "weight_decay, 0.5160735795588228                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 51/51 [00:03<00:00, 15.65trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.09487934806891118\n",
      "dropout_prob, 0.823175760525243                                 \n",
      "weight_decay, 0.037608168420743715                              \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1329                                                \n",
      "100%|██████████| 52/52 [00:02<00:00, 21.84trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.006728950416912999\n",
      "dropout_prob, 0.9575336148032089                                \n",
      "weight_decay, 0.31116535416452307                               \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.6511                                                \n",
      "100%|██████████| 53/53 [00:02<00:00, 23.45trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.004816165822502428\n",
      "dropout_prob, 0.7805433739712688                                \n",
      "weight_decay, 0.22635661626680986                               \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.6467                                                \n",
      "100%|██████████| 54/54 [00:03<00:00, 17.72trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.014040885624678003\n",
      "dropout_prob, 0.910966497861454                                 \n",
      "weight_decay, 0.1479475173293673                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.4907                                                \n",
      "100%|██████████| 55/55 [00:03<00:00, 17.67trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.5232\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.7148 -0.5232]\n",
      "                                                       \n",
      " lr, 0.09505221116026823\n",
      "dropout_prob, 0.5081050967762142                                \n",
      "weight_decay, 0.058538841693571764                              \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1175                                                \n",
      "100%|██████████| 51/51 [00:02<00:00, 23.42trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.015505677220759986\n",
      "dropout_prob, 0.4223790565432596                                \n",
      "weight_decay, 0.9700102296933629                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.0974                                                \n",
      "100%|██████████| 52/52 [00:02<00:00, 23.04trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.028171180793975212\n",
      "dropout_prob, 0.5000573082181112                                \n",
      "weight_decay, 0.9287385344481696                                \n",
      "iteration: 7                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 53/53 [00:02<00:00, 23.34trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 8.98465076273221e-05\n",
      "dropout_prob, 0.3063761396595653                                \n",
      "weight_decay, 0.15716040259494374                               \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.6182                                                \n",
      "100%|██████████| 54/54 [00:03<00:00, 17.27trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.05805490179839351\n",
      "dropout_prob, 0.42531565882520006                               \n",
      "weight_decay, 0.039318066547826366                              \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.0973                                                \n",
      "100%|██████████| 55/55 [00:02<00:00, 25.88trial/s, best loss: -0.8143]\n",
      "\n",
      " loss of parent -0.3555\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.3555]\n",
      "                                                       \n",
      " lr, 0.02980039576170426\n",
      "dropout_prob, 0.9989669830144362                                \n",
      "weight_decay, 0.5265026520829398                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.101                                                 \n",
      "100%|██████████| 51/51 [00:02<00:00, 23.58trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.00520717349672329\n",
      "dropout_prob, 0.8221029913746465                                \n",
      "weight_decay, 0.0457067105690764                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.5175                                                \n",
      "100%|██████████| 52/52 [00:03<00:00, 16.47trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.034409174552834515\n",
      "dropout_prob, 0.9280734361323555                                \n",
      "weight_decay, 0.2832094252285007                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1216                                                \n",
      "100%|██████████| 53/53 [00:02<00:00, 23.57trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.016658155611618354\n",
      "dropout_prob, 0.5053753036083004                                \n",
      "weight_decay, 0.21197000788815099                               \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.1767                                                \n",
      "100%|██████████| 54/54 [00:02<00:00, 24.08trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.00021020925757730957\n",
      "dropout_prob, 0.7847554882981606                                \n",
      "weight_decay, 0.7601460730627485                                \n",
      "iteration: 7                                                    \n",
      "accuracy, 0.358                                                 \n",
      "100%|██████████| 55/55 [00:03<00:00, 17.43trial/s, best loss: -0.7877]\n",
      "[-0.0892 -0.1186 -0.842  -0.1011 -0.1135 -0.1329 -0.6511 -0.6467 -0.1175\n",
      " -0.0974 -0.1135 -0.6182 -0.101  -0.5175 -0.1216 -0.1767 -0.358  -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 2  6  7 11 13 16 17 19 15  5 14  1  8  4 10  3 12  9 18  0]\n",
      "\n",
      " loss of parent -0.842\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738 -0.7533 -0.8304 -0.8407 -0.842 ]\n",
      "                                                       \n",
      " lr, 0.030064611080522625\n",
      "dropout_prob, 0.9061599843367303                                \n",
      "weight_decay, 0.6362883780698747                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.1029                                                \n",
      "100%|██████████| 56/56 [00:02<00:00, 23.60trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.0004396059580214782\n",
      "dropout_prob, 0.7357171046909958                                \n",
      "weight_decay, 0.5230365408098077                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.8376                                                \n",
      "100%|██████████| 57/57 [00:02<00:00, 23.46trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.0226057145065688\n",
      "dropout_prob, 0.586972028194064                                  \n",
      "weight_decay, 0.7156906748414125                                 \n",
      "iteration: 8                                                     \n",
      "accuracy, 0.098                                                  \n",
      "100%|██████████| 58/58 [00:03<00:00, 16.91trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.0468134871271594\n",
      "dropout_prob, 0.8138194101051894                                \n",
      "weight_decay, 0.8910548280202875                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.1034                                                \n",
      "100%|██████████| 59/59 [00:02<00:00, 23.59trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.09542102583122991\n",
      "dropout_prob, 0.6647881010685199                                \n",
      "weight_decay, 0.5794095183022745                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.1366                                                \n",
      "100%|██████████| 60/60 [00:03<00:00, 18.73trial/s, best loss: -0.842]\n",
      "\n",
      " loss of parent -0.6511\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.6473 -0.6511]\n",
      "                                                       \n",
      " lr, 0.035574771145523\n",
      "dropout_prob, 0.679200943347744                                  \n",
      "weight_decay, 0.5888130680113413                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.036                                                 \n",
      "100%|██████████| 56/56 [00:02<00:00, 19.50trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.0002673823482851048\n",
      "dropout_prob, 0.7260657015700702                                \n",
      "weight_decay, 0.08923403131816765                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.6729                                                \n",
      "100%|██████████| 57/57 [00:02<00:00, 20.03trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.047202383748651384\n",
      "dropout_prob, 0.534570686875218                                 \n",
      "weight_decay, 0.7609175441881475                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0967                                                \n",
      "100%|██████████| 58/58 [00:02<00:00, 20.21trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.05791177239073644\n",
      "dropout_prob, 0.9950104444037042                                \n",
      "weight_decay, 0.17698893856795717                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0978                                                \n",
      "100%|██████████| 59/59 [00:02<00:00, 19.82trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.0795616438866325\n",
      "dropout_prob, 0.40115635392066074                               \n",
      "weight_decay, 0.35692557066207586                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.084                                                 \n",
      "100%|██████████| 60/60 [00:02<00:00, 20.26trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.6467\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.6473 -0.6467]\n",
      "                                                       \n",
      " lr, 0.034766803037149144\n",
      "dropout_prob, 0.5114808256995715                                \n",
      "weight_decay, 0.08472155351546326                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.1152                                                \n",
      "100%|██████████| 56/56 [00:02<00:00, 19.15trial/s, best loss: -0.7877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " lr, 0.05885375591640321\n",
      "dropout_prob, 0.8493384648947297                                \n",
      "weight_decay, 0.5795902539679801                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.097                                                 \n",
      "100%|██████████| 57/57 [00:02<00:00, 19.15trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.00010617342337718161\n",
      "dropout_prob, 0.7032703045037285                                \n",
      "weight_decay, 0.7546003350325764                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.6536                                                \n",
      "100%|██████████| 58/58 [00:02<00:00, 20.20trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.04717152450382445\n",
      "dropout_prob, 0.9999224337605909                                \n",
      "weight_decay, 0.1927963691910858                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0558                                                \n",
      "100%|██████████| 59/59 [00:02<00:00, 20.24trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.07178704581029698\n",
      "dropout_prob, 0.4188577063937594                                \n",
      "weight_decay, 0.2597531645211325                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.1032                                                \n",
      "100%|██████████| 60/60 [00:02<00:00, 20.40trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.6182\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.7148 -0.5232 -0.6182]\n",
      "                                                       \n",
      " lr, 0.023664861090622952\n",
      "dropout_prob, 0.6866138171777678                                \n",
      "weight_decay, 0.21323407074944664                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0926                                                \n",
      "100%|██████████| 56/56 [00:02<00:00, 18.83trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.07141301336439382\n",
      "dropout_prob, 0.5478576527337375                                \n",
      "weight_decay, 0.09987045739921513                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0872                                                \n",
      "100%|██████████| 57/57 [00:02<00:00, 19.35trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.00013171437779231957\n",
      "dropout_prob, 0.05978355531766011                               \n",
      "weight_decay, 0.02372476474398648                               \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.7142                                                \n",
      "100%|██████████| 58/58 [00:03<00:00, 19.22trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.036430790956927216\n",
      "dropout_prob, 0.4680666620126325                                \n",
      "weight_decay, 0.365392668447432                                 \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0974                                                \n",
      "100%|██████████| 59/59 [00:02<00:00, 19.84trial/s, best loss: -0.8143]\n",
      "                                                       \n",
      " lr, 0.01652345891367401\n",
      "dropout_prob, 0.7448643596563537                                \n",
      "weight_decay, 0.7475347425725374                                \n",
      "iteration: 8                                                    \n",
      "accuracy, 0.0983                                                \n",
      "100%|██████████| 60/60 [00:02<00:00, 20.16trial/s, best loss: -0.8143]\n",
      "[-0.1029 -0.8376 -0.098  -0.1034 -0.036  -0.6729 -0.0967 -0.0978 -0.1152\n",
      " -0.097  -0.6536 -0.0558 -0.0926 -0.0872 -0.7142 -0.0974 -0.0983 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[ 1 14  5 10 17 19  8  3  0 16  2  7 18 15  9  6 12 13 11  4]\n",
      "\n",
      " loss of parent -0.8376\n",
      "\n",
      " loss [-0.3936 -0.669  -0.6166 -0.7738 -0.7533 -0.8304 -0.8407 -0.842  -0.8376]\n",
      "                                                       \n",
      " lr, 0.09998869524403847\n",
      "dropout_prob, 0.7262104568974119                                \n",
      "weight_decay, 0.45297180999336845                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.101                                                 \n",
      "100%|██████████| 61/61 [00:03<00:00, 20.01trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.08134596284142281\n",
      "dropout_prob, 0.9169228493629105                                \n",
      "weight_decay, 0.4123217340223805                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.0964                                                \n",
      "100%|██████████| 62/62 [00:02<00:00, 20.93trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.01240320983853254\n",
      "dropout_prob, 0.9535901297513298                                \n",
      "weight_decay, 0.6082677024226412                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.2721                                                \n",
      "100%|██████████| 63/63 [00:02<00:00, 21.33trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.0076391349513798305\n",
      "dropout_prob, 0.4650480161253561                                \n",
      "weight_decay, 0.7494677726636434                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.3206                                                \n",
      "100%|██████████| 64/64 [00:03<00:00, 20.69trial/s, best loss: -0.842]\n",
      "                                                       \n",
      " lr, 0.03205769704924425\n",
      "dropout_prob, 0.5840830221978665                                \n",
      "weight_decay, 0.5264315914173991                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.0958                                                \n",
      "100%|██████████| 65/65 [00:03<00:00, 21.19trial/s, best loss: -0.842]\n",
      "\n",
      " loss of parent -0.7142\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.6473 -0.6467 -0.7142]\n",
      "                                                       \n",
      " lr, 0.08183959585274765\n",
      "dropout_prob, 0.2998450535236393                                \n",
      "weight_decay, 0.9422026205834055                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.1097                                                \n",
      "100%|██████████| 61/61 [00:02<00:00, 21.18trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.02406268039439112\n",
      "dropout_prob, 0.6657687435933208                                \n",
      "weight_decay, 0.3805457489445325                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.0958                                                \n",
      "100%|██████████| 62/62 [00:03<00:00, 20.39trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.054743171845268404\n",
      "dropout_prob, 0.5752325154488687                                \n",
      "weight_decay, 0.0713986851895897                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 63/63 [00:02<00:00, 21.79trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.017516749427953615\n",
      "dropout_prob, 0.750326946711133                                 \n",
      "weight_decay, 0.3438802220252577                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.2617                                                \n",
      "100%|██████████| 64/64 [00:02<00:00, 21.94trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.01253354578211527\n",
      "dropout_prob, 0.9420726301491165                                \n",
      "weight_decay, 0.40741099793849744                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9                                                    \n",
      "accuracy, 0.2645                                                \n",
      "100%|██████████| 65/65 [00:02<00:00, 22.57trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.6729\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.6473 -0.6511 -0.6729]\n",
      "                                                       \n",
      " lr, 0.06983726568509771\n",
      "dropout_prob, 0.6200715024221032                                \n",
      "weight_decay, 0.26618859507604165                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.1137                                                \n",
      "100%|██████████| 61/61 [00:02<00:00, 20.81trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.022137961170488947\n",
      "dropout_prob, 0.840760416921249                                 \n",
      "weight_decay, 0.9328729655500371                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.1009                                                \n",
      "100%|██████████| 62/62 [00:02<00:00, 20.93trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.017035923697307317\n",
      "dropout_prob, 0.5826339534180358                                \n",
      "weight_decay, 0.04996523738839953                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.4591                                                \n",
      "100%|██████████| 63/63 [00:02<00:00, 21.97trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.05265069780945493\n",
      "dropout_prob, 0.3118670352386991                                \n",
      "weight_decay, 0.42318401353311313                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.0974                                                \n",
      "100%|██████████| 64/64 [00:03<00:00, 20.34trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.012800095709711166\n",
      "dropout_prob, 0.4934457885353621                                \n",
      "weight_decay, 0.2966580094482138                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.2738                                                \n",
      "100%|██████████| 65/65 [00:03<00:00, 21.22trial/s, best loss: -0.7877]\n",
      "\n",
      " loss of parent -0.6536\n",
      "\n",
      " loss [-0.3936 -0.669  -0.566  -0.7877 -0.7457 -0.6454 -0.6473 -0.6467 -0.6536]\n",
      "                                                       \n",
      " lr, 0.021374264129924003\n",
      "dropout_prob, 0.6639837573056152                                \n",
      "weight_decay, 0.9223291041611065                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.1009                                                \n",
      "100%|██████████| 61/61 [00:03<00:00, 18.10trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.07855795188149316\n",
      "dropout_prob, 0.3085778086332558                                \n",
      "weight_decay, 0.6381420647934906                                \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.106                                                 \n",
      "100%|██████████| 62/62 [23:29<00:00, 22.73s/trial, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.017039178513853392\n",
      "dropout_prob, 0.752816544607524                                 \n",
      "weight_decay, 0.37908560117234646                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.0943                                                \n",
      "100%|██████████| 63/63 [00:02<00:00, 21.58trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.02297921223203063\n",
      "dropout_prob, 0.5637670696842776                                \n",
      "weight_decay, 0.34949937058494884                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.1135                                                \n",
      "100%|██████████| 64/64 [00:02<00:00, 23.44trial/s, best loss: -0.7877]\n",
      "                                                       \n",
      " lr, 0.05495276605235125\n",
      "dropout_prob, 0.9506932316402331                                \n",
      "weight_decay, 0.29546676254367477                               \n",
      "iteration: 9                                                    \n",
      "accuracy, 0.0998                                                \n",
      "100%|██████████| 65/65 [00:02<00:00, 22.50trial/s, best loss: -0.7877]\n",
      "[-0.101  -0.0964 -0.2721 -0.3206 -0.1097 -0.0958 -0.1135 -0.2617 -0.1137\n",
      " -0.1009 -0.4591 -0.0974 -0.1009 -0.106  -0.0943 -0.1135 -0.0998 -0.2092\n",
      " -0.0974 -0.2007]\n",
      "[10  3  2  7 17 19  8 15  6  4 13  0 12  9 16 18 11  1  5 14]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Scheduler():\n",
    "    def __init__(self, model, num_iteration, num_config,\n",
    "                 oracle):\n",
    "        #Oracle manages the Bayesian optimization\n",
    "        self.oracle = oracle\n",
    "        self.iteration = num_iteration\n",
    "        self.num_config = num_config \n",
    "        self.sqrt_config =  math.floor(math.sqrt(num_config)) #math.ceil(num_config/10)\n",
    "        \n",
    "        #self.h is for the m \"h\" used at every loop, h is a configuration from the search space\n",
    "        self.h = np.repeat({},num_config) \n",
    "        \n",
    "        #self.out is for storing the result of the algorithm, ie all \"h\" from all iterations\n",
    "        #from all sqrt(m) best models per iterations.\n",
    "        self.out = np.zeros((num_iteration,self.sqrt_config))\n",
    "        \n",
    "        #self.hyperspaces is for storing the sqrt(m) hyperspaces used by the algorithm\n",
    "        self.hyperspaces = np.zeros(self.sqrt_config)\n",
    "        \n",
    "\n",
    "        \n",
    "        #self.model is the m model that will explore new hyperspace points at every iterations\n",
    "        self.models = np.repeat(model,num_config)\n",
    "        \n",
    "        #self.parents is the sqrt(m) best model from last iteration\n",
    "        self.parents = np.repeat(model,self.sqrt_config)\n",
    "\n",
    "        #self.losses remembers the performances of all m models at one iteration to decide which ones are the sqrt(m) best from self.models.\n",
    "        self.losses = np.zeros(num_config)\n",
    "        \n",
    "        self.k = [0] # c'est pour avoir un pointeur sur k, c'est pas paralélisable pour le moment du coup.\n",
    "    \n",
    "    def initialisation(self):\n",
    "        num_config = self.num_config\n",
    "        extended_Hyperspace = Trials()\n",
    "        #for k in range(num_config):\n",
    "        fmin_objective = partial(test_function, models=self.models,h=self.h,losses=self.losses,parent_model=self.models, k_f = self.k,iteration = 0)\n",
    "        self.oracle.compute_Batch(extended_Hyperspace ,num_config , 0 ,fmin_objective)\n",
    "            \n",
    "        indexes = np.argsort(self.losses)     \n",
    "        self.out[0] = (self.losses[indexes])[0:self.sqrt_config]\n",
    "        self.hyperspaces = np.repeat(extended_Hyperspace,self.sqrt_config)    \n",
    "        self.parents = np.array([Parent(copy.deepcopy(extended_Hyperspace),(self.h[indexes])[i], (self.models[indexes])[i],(self.losses[indexes])[i])  \n",
    "                                 for i in range(self.sqrt_config) ])         \n",
    "        \n",
    "    def loop(self):\n",
    "        sqrt_config = self.sqrt_config\n",
    "        iteration = self.iteration\n",
    "        for i in range(1,iteration):\n",
    "            for j in range(sqrt_config):\n",
    "                k = j*sqrt_config\n",
    "                parent = self.parents[j]\n",
    "                extended_Hyperspace = parent.get_hyperspace()\n",
    "                print(\"\\n loss of parent \" + str(parent.get_loss()[-1]) )\n",
    "                print(\"\\n loss \" + str(parent.get_loss()))\n",
    "\n",
    "                \n",
    "                for l in range(int(self.num_config/sqrt_config)):\n",
    "                    fmin_objective = partial(test_function, models=self.models,h=self.h,losses=self.losses,parent_model=parent.get_model(), k_f = k,iteration = i)\n",
    "                    self.oracle.compute_Once(extended_Hyperspace ,i ,fmin_objective)\n",
    "                    k = k+1\n",
    "                \n",
    "            indexes = np.argsort(self.losses)     \n",
    "            #parent_idx = np.floor(indexes/sqrt_config)[:sqrt_config]\n",
    "            parent_idx = indexes[:sqrt_config]\n",
    "            print(self.losses)\n",
    "            print(indexes)\n",
    "            #print(parent_idx)\n",
    " \n",
    "            temp = np.empty(self.sqrt_config, dtype=Parent)\n",
    "            for a,x in enumerate(parent_idx):\n",
    "                x = int(x)\n",
    "                temp[a] = copy.deepcopy(self.parents[math.floor(x/self.num_config*sqrt_config)])\n",
    "                temp[a].update(self.h[x], self.losses[x], self.models[x])\n",
    "            self.parents = temp\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "CONFIGURATION = 20\n",
    "ITERATIONS = 10\n",
    "config= {\n",
    "     \"lr\": hp.uniform(\"lr\",0,.1)\n",
    "    , \"droupout_prob\": hp.uniform(\"droupout_prob\",0,1),\n",
    "             \"weight_decay\": hp.uniform(\"weight_decay\",0,1)\n",
    "\n",
    "\n",
    "}\n",
    "model = train_mnist\n",
    "oracle = Oracle(config)\n",
    "scheduler = Scheduler(\n",
    "    model,\n",
    "    ITERATIONS,\n",
    "    CONFIGURATION,\n",
    "    oracle) \n",
    "\n",
    "scheduler.initialisation()     \n",
    "scheduler.loop()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "# Oracle (Paul) TODO\n",
    "class Oracle():\n",
    "    def __init__(self, searchspace ):\n",
    "        #self.hyperspace is the original (input) searchspace\n",
    "        self.searchspace = searchspace\n",
    "\n",
    "    def compute_Once(self,trials, iteration,function): #add space\n",
    "        space = copy.deepcopy(self.searchspace)\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+1, trials=trials)\n",
    "        \n",
    "        \n",
    "    def compute_Batch(self,trials, nb_eval, iteration,function): #add space\n",
    "        space = copy.deepcopy(self.searchspace)\n",
    "        curr_eval = getattr(trials,'_ids')\n",
    "        if curr_eval == set():\n",
    "            curr_eval = 0\n",
    "        else:\n",
    "            curr_eval = max(curr_eval) +1\n",
    "            \n",
    "        space[\"itération\"] =  hp.quniform(\"itération\",-.5+iteration,.5+iteration, 1) \n",
    "        fmin(function, space, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=curr_eval\n",
    "+nb_eval, trials=trials)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x,models,h,losses, parent_model,k_f,iteration):\n",
    "    if iteration == 0:\n",
    "        k = k_f[0]\n",
    "        models[k] = parent_model[k](x)\n",
    "        k_f[0] += 1\n",
    "\n",
    "    else:      \n",
    "        k = k_f\n",
    "        models[k] = parent_model.adapt(x)\n",
    "    print(\"\\n lr, \" + str(x[\"lr\"]))\n",
    "    print(\"dropout_prob, \" + str(x[\"droupout_prob\"]))\n",
    "    print(\"weight_decay, \" + str(x[\"weight_decay\"]))\n",
    "\n",
    "    \n",
    "\n",
    "    h[k] = x\n",
    "    models[k].train1()\n",
    "    loss = models[k].test1()\n",
    "    losses[k] = -loss\n",
    "    print(\"accuracy, \" + str(loss))\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal Bayes Opt\n",
    "\n",
    "def function(x):\n",
    "    print(x)\n",
    "    model = train_mnist(x)\n",
    "    for _ in range(10):\n",
    "            model.train1()\n",
    "    loss = model.test1()\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesOpt():\n",
    "    def __init__(self, searchspace ):\n",
    "        self.searchspace = searchspace\n",
    "\n",
    "    def compute_Once(self,function): \n",
    "        fmin(function, self.searchspace, algo=partial(tpe.suggest, n_startup_jobs=1), max_evals=20, trials=Trials())\n",
    "    \n",
    "config= {\n",
    "     \"lr\": hp.uniform(\"lr\",0,.11),\n",
    "     \"droupout_prob\": hp.uniform(\"droupout_prob\",0,1),\n",
    "     \"weight_decay\": hp.uniform(\"weight_decay\",0,1)\n",
    "    \n",
    "}\n",
    "oracle = BayesOpt(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'droupout_prob': 0.08195461068614285, 'lr': 0.05882682078394428, 'weight_decay': 0.6724825422787089}\n",
      "iteration: 0                                          \n",
      "iteration: 1                                          \n",
      "iteration: 2                                          \n",
      "iteration: 3                                          \n",
      "iteration: 4                                          \n",
      "iteration: 5                                          \n",
      "iteration: 6                                          \n",
      "iteration: 7                                          \n",
      "iteration: 8                                          \n",
      "iteration: 9                                          \n",
      "{'droupout_prob': 0.04943277773811725, 'lr': 0.0577914251573257, 'weight_decay': 0.7355425948950876}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.08945662764665531, 'lr': 0.013581836662577618, 'weight_decay': 0.9754570928860755}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.8962924534228722, 'lr': 0.10784648892151635, 'weight_decay': 0.02338293102675476}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.504995476691115, 'lr': 0.07142495907136877, 'weight_decay': 0.20706671404090726}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.6252487667953381, 'lr': 0.10981320565654563, 'weight_decay': 0.07789067488960219}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.4409233065527701, 'lr': 0.013354103655196625, 'weight_decay': 0.2954266021597045}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.4104347587390188, 'lr': 0.08536027643033449, 'weight_decay': 0.35911658132373003}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.961420188226694, 'lr': 0.03854911745594433, 'weight_decay': 0.18273552995543416}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.9624617761316385, 'lr': 0.032587734667841727, 'weight_decay': 0.5474936609441199}\n",
      "iteration: 0                                                         \n",
      "iteration: 1                                                         \n",
      "iteration: 2                                                         \n",
      "iteration: 3                                                         \n",
      "iteration: 4                                                         \n",
      "iteration: 5                                                         \n",
      "iteration: 6                                                         \n",
      "iteration: 7                                                         \n",
      "iteration: 8                                                         \n",
      "iteration: 9                                                         \n",
      "{'droupout_prob': 0.7694808246113076, 'lr': 0.03853180752116445, 'weight_decay': 0.9997101733077152}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.27935944997473994, 'lr': 0.08857529363524526, 'weight_decay': 0.47648938338642055}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.753372667792815, 'lr': 0.035204568741040755, 'weight_decay': 0.1344509020612883}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.9844029292327697, 'lr': 0.009331658018476768, 'weight_decay': 0.8387662377702901}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.2388578864217445, 'lr': 0.00185927505999392, 'weight_decay': 0.4628865704604541}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.8353129821931116, 'lr': 0.04559251523395115, 'weight_decay': 0.3021983049981902}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.644834825963712, 'lr': 0.022962896181088877, 'weight_decay': 0.5874135006925106}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.7346767735657841, 'lr': 0.02901625603772884, 'weight_decay': 0.13155741391383102}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.6617519159011506, 'lr': 0.02407504247340886, 'weight_decay': 0.013873446545638227}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "{'droupout_prob': 0.5962717698274687, 'lr': 0.047841600150780414, 'weight_decay': 0.014634920871366752}\n",
      "iteration: 0                                                          \n",
      "iteration: 1                                                          \n",
      "iteration: 2                                                          \n",
      "iteration: 3                                                          \n",
      "iteration: 4                                                          \n",
      "iteration: 5                                                          \n",
      "iteration: 6                                                          \n",
      "iteration: 7                                                          \n",
      "iteration: 8                                                          \n",
      "iteration: 9                                                          \n",
      "100%|██████████| 20/20 [01:16<00:00,  3.81s/trial, best loss: -0.8279]\n"
     ]
    }
   ],
   "source": [
    "oracle.compute_Once(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
