save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.6586252610901482, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 1887, 'use_cuda': True, 'aiteration': 0, 'drp': 0.05241257531286249, 'eps': 0.00013597817549969944, 'lr': 0.36497764792101767, 'weight_decay': 0.00010755336180274167}
Random Seed: 1887
python version : 3.7.10 (default, Feb 20 2021, 21:17:23)  [GCC 7.5.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '1887'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-04-15 19:25:07] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.364978] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 0.283 (0.283)   Data 0.169 (0.169)   Loss 2.3862 (2.3862)   Prec@1 13.000 (13.000)   Prec@5 51.000 (51.000)   [2021-04-15 19:25:07]
  Epoch: [000][200/500]   Time 0.178 (0.180)   Data 0.000 (0.001)   Loss 1.6879 (1.7755)   Prec@1 37.000 (34.199)   Prec@5 89.000 (85.537)   [2021-04-15 19:25:43]
  Epoch: [000][400/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 1.3178 (1.5683)   Prec@1 60.000 (42.416)   Prec@5 94.000 (89.431)   [2021-04-15 19:26:19]
  **Train** Prec@1 45.466 Prec@5 90.662 Error@1 54.534
  **Test** Prec@1 52.680 Prec@5 94.140 Error@1 47.320
  **Test** Prec@1 53.660 Prec@5 94.460 Error@1 46.340

==>>[2021-04-15 19:26:42] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.364978] [Best : Accuracy=52.68, Error=47.32]
  Epoch: [001][000/500]   Time 0.259 (0.259)   Data 0.150 (0.150)   Loss 1.0914 (1.0914)   Prec@1 59.000 (59.000)   Prec@5 97.000 (97.000)   [2021-04-15 19:26:43]
  Epoch: [001][200/500]   Time 0.176 (0.180)   Data 0.000 (0.001)   Loss 1.2503 (1.0431)   Prec@1 50.000 (62.682)   Prec@5 97.000 (96.348)   [2021-04-15 19:27:18]
  Epoch: [001][400/500]   Time 0.183 (0.180)   Data 0.000 (0.001)   Loss 0.7641 (0.9800)   Prec@1 77.000 (65.349)   Prec@5 98.000 (96.786)   [2021-04-15 19:27:54]
  **Train** Prec@1 66.528 Prec@5 96.942 Error@1 33.472
  **Test** Prec@1 71.980 Prec@5 97.820 Error@1 28.020

==>>[2021-04-15 19:28:15] [Epoch=002/540] [Need: 00:00:00] [learning_rate=0.364978] [Best : Accuracy=71.98, Error=28.02]
  Epoch: [002][000/500]   Time 0.254 (0.254)   Data 0.152 (0.152)   Loss 0.7662 (0.7662)   Prec@1 73.000 (73.000)   Prec@5 97.000 (97.000)   [2021-04-15 19:28:15]
  Epoch: [002][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.7922 (0.7760)   Prec@1 69.000 (73.005)   Prec@5 98.000 (98.050)   [2021-04-15 19:28:51]
  Epoch: [002][400/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.5676 (0.7498)   Prec@1 80.000 (73.890)   Prec@5 100.000 (98.207)   [2021-04-15 19:29:27]
  **Train** Prec@1 74.304 Prec@5 98.252 Error@1 25.696
  **Test** Prec@1 72.980 Prec@5 98.460 Error@1 27.020

==>>[2021-04-15 19:29:47] [Epoch=003/540] [Need: 00:00:00] [learning_rate=0.364978] [Best : Accuracy=72.98, Error=27.02]
  Epoch: [003][000/500]   Time 0.246 (0.246)   Data 0.149 (0.149)   Loss 0.5854 (0.5854)   Prec@1 82.000 (82.000)   Prec@5 98.000 (98.000)   [2021-04-15 19:29:48]
  Epoch: [003][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.8011 (0.6417)   Prec@1 71.000 (77.831)   Prec@5 97.000 (98.756)   [2021-04-15 19:30:24]
  Epoch: [003][400/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.8537 (0.6316)   Prec@1 69.000 (78.045)   Prec@5 98.000 (98.778)   [2021-04-15 19:30:59]
  **Train** Prec@1 78.146 Prec@5 98.762 Error@1 21.854
  **Test** Prec@1 75.240 Prec@5 99.040 Error@1 24.760

==>>[2021-04-15 19:31:20] [Epoch=004/540] [Need: 00:00:00] [learning_rate=0.364978] [Best : Accuracy=75.24, Error=24.76]
  Epoch: [004][000/500]   Time 0.264 (0.264)   Data 0.157 (0.157)   Loss 0.5489 (0.5489)   Prec@1 83.000 (83.000)   Prec@5 100.000 (100.000)   [2021-04-15 19:31:20]
  Epoch: [004][200/500]   Time 0.187 (0.180)   Data 0.000 (0.001)   Loss 0.5817 (0.5722)   Prec@1 81.000 (80.363)   Prec@5 99.000 (98.970)   [2021-04-15 19:31:56]
  Epoch: [004][400/500]   Time 0.175 (0.180)   Data 0.000 (0.001)   Loss 0.4865 (0.5595)   Prec@1 84.000 (80.810)   Prec@5 100.000 (98.998)   [2021-04-15 19:32:32]
  **Train** Prec@1 81.094 Prec@5 99.014 Error@1 18.906
  **Test** Prec@1 79.840 Prec@5 99.060 Error@1 20.160

==>>[2021-04-15 19:32:52] [Epoch=005/540] [Need: 00:00:00] [learning_rate=0.364978] [Best : Accuracy=79.84, Error=20.16]
  Epoch: [005][000/500]   Time 0.285 (0.285)   Data 0.161 (0.161)   Loss 0.5126 (0.5126)   Prec@1 80.000 (80.000)   Prec@5 99.000 (99.000)   [2021-04-15 19:32:53]
  Epoch: [005][200/500]   Time 0.181 (0.180)   Data 0.000 (0.001)   Loss 0.4023 (0.5111)   Prec@1 88.000 (82.433)   Prec@5 100.000 (99.129)   [2021-04-15 19:33:29]
  Epoch: [005][400/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.4624 (0.5007)   Prec@1 87.000 (82.758)   Prec@5 100.000 (99.187)   [2021-04-15 19:34:04]
  **Train** Prec@1 82.860 Prec@5 99.196 Error@1 17.140
  **Test** Prec@1 83.780 Prec@5 99.440 Error@1 16.220
  **Test** Prec@1 84.300 Prec@5 99.420 Error@1 15.700

==>>[2021-04-15 19:34:28] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.000001] [Best : Accuracy=52.68, Error=47.32]
  Epoch: [001][000/500]   Time 0.266 (0.266)   Data 0.161 (0.161)   Loss 1.2348 (1.2348)   Prec@1 56.000 (56.000)   Prec@5 95.000 (95.000)   [2021-04-15 19:34:28]
  Epoch: [001][200/500]   Time 0.181 (0.179)   Data 0.000 (0.001)   Loss 1.0710 (1.0947)   Prec@1 59.000 (60.791)   Prec@5 97.000 (95.801)   [2021-04-15 19:35:04]
  Epoch: [001][400/500]   Time 0.178 (0.179)   Data 0.000 (0.001)   Loss 1.0841 (1.0951)   Prec@1 66.000 (60.721)   Prec@5 94.000 (95.793)   [2021-04-15 19:35:40]
  **Train** Prec@1 60.902 Prec@5 95.876 Error@1 39.098
  **Test** Prec@1 61.400 Prec@5 96.580 Error@1 38.600
