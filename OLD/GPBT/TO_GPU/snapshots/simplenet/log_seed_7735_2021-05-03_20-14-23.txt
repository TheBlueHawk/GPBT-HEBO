save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.679021460437766, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 7735, 'use_cuda': True, 'aiteration': 0, 'drp': 0.14802371921616803, 'eps': 0.0033371175959646905, 'lr': 0.08564386464899738, 'weight_decay': 0.0002504693079126629}
Random Seed: 7735
python version : 3.6.9 (default, Jan 26 2021, 15:33:00)  [GCC 8.4.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '7735'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-05-03 20:14:25] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.085644] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 0.166 (0.166)   Data 0.100 (0.100)   Loss 2.4172 (2.4172)   Prec@1 9.000 (9.000)   Prec@5 45.000 (45.000)   [2021-05-03 20:14:25]
  Epoch: [000][200/500]   Time 0.152 (0.151)   Data 0.000 (0.001)   Loss 1.9632 (1.8525)   Prec@1 23.000 (29.433)   Prec@5 85.000 (83.259)   [2021-05-03 20:14:55]
  Epoch: [000][400/500]   Time 0.147 (0.151)   Data 0.000 (0.000)   Loss 1.5467 (1.7181)   Prec@1 47.000 (35.244)   Prec@5 89.000 (86.805)   [2021-05-03 20:15:25]
  **Train** Prec@1 37.306 Prec@5 87.776 Error@1 62.694
  **Test** Prec@1 54.080 Prec@5 95.120 Error@1 45.920
  **Test** Prec@1 52.200 Prec@5 95.060 Error@1 47.800

==>>[2021-05-03 22:54:22] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.085644] [Best : Accuracy=54.08, Error=45.92]
  Epoch: [001][000/500]   Time 0.184 (0.184)   Data 0.118 (0.118)   Loss 1.3648 (1.3648)   Prec@1 49.000 (49.000)   Prec@5 98.000 (98.000)   [2021-05-03 22:54:22]
  Epoch: [001][200/500]   Time 0.150 (0.148)   Data 0.000 (0.001)   Loss 1.2900 (1.3665)   Prec@1 54.000 (49.856)   Prec@5 95.000 (93.652)   [2021-05-03 22:54:52]
  Epoch: [001][400/500]   Time 0.152 (0.149)   Data 0.000 (0.000)   Loss 1.1779 (1.3175)   Prec@1 56.000 (51.893)   Prec@5 96.000 (93.998)   [2021-05-03 22:55:22]
  **Train** Prec@1 52.998 Prec@5 94.188 Error@1 47.002
  **Test** Prec@1 62.180 Prec@5 97.080 Error@1 37.820

==>>[2021-05-03 22:55:40] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.343590] [Best : Accuracy=54.08, Error=45.92]
  Epoch: [001][000/500]   Time 0.190 (0.190)   Data 0.124 (0.124)   Loss 1.5495 (1.5495)   Prec@1 43.000 (43.000)   Prec@5 92.000 (92.000)   [2021-05-03 22:55:40]
  Epoch: [001][200/500]   Time 0.150 (0.148)   Data 0.000 (0.001)   Loss 1.1633 (1.6432)   Prec@1 54.000 (40.617)   Prec@5 96.000 (89.781)   [2021-05-03 22:56:10]
  Epoch: [001][400/500]   Time 0.148 (0.149)   Data 0.000 (0.000)   Loss 1.0142 (1.4637)   Prec@1 67.000 (47.127)   Prec@5 96.000 (92.042)   [2021-05-03 22:56:40]
  **Train** Prec@1 49.242 Prec@5 92.782 Error@1 50.758
  **Test** Prec@1 61.360 Prec@5 96.880 Error@1 38.640

==>>[2021-05-03 22:56:58] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.000001] [Best : Accuracy=54.08, Error=45.92]
  Epoch: [001][000/500]   Time 0.188 (0.188)   Data 0.121 (0.121)   Loss 1.3892 (1.3892)   Prec@1 48.000 (48.000)   Prec@5 93.000 (93.000)   [2021-05-03 22:56:58]
  Epoch: [001][200/500]   Time 0.151 (0.148)   Data 0.000 (0.001)   Loss 1.7223 (1.4043)   Prec@1 42.000 (48.318)   Prec@5 88.000 (92.955)   [2021-05-03 22:57:27]
  Epoch: [001][400/500]   Time 0.149 (0.149)   Data 0.000 (0.000)   Loss 1.6254 (1.4073)   Prec@1 46.000 (48.481)   Prec@5 89.000 (92.885)   [2021-05-03 22:57:57]
  **Train** Prec@1 48.398 Prec@5 92.876 Error@1 51.602
  **Test** Prec@1 54.160 Prec@5 95.240 Error@1 45.840

==>>[2021-05-03 22:58:15] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.141084] [Best : Accuracy=54.08, Error=45.92]
  Epoch: [001][000/500]   Time 0.184 (0.184)   Data 0.117 (0.117)   Loss 1.5260 (1.5260)   Prec@1 51.000 (51.000)   Prec@5 93.000 (93.000)   [2021-05-03 22:58:16]
  Epoch: [001][200/500]   Time 0.151 (0.148)   Data 0.000 (0.001)   Loss 1.3419 (1.4095)   Prec@1 50.000 (48.119)   Prec@5 94.000 (93.119)   [2021-05-03 22:58:45]
  Epoch: [001][400/500]   Time 0.153 (0.149)   Data 0.000 (0.000)   Loss 1.2406 (1.3286)   Prec@1 55.000 (51.761)   Prec@5 98.000 (93.813)   [2021-05-03 22:59:15]
  **Train** Prec@1 53.020 Prec@5 94.208 Error@1 46.980
  **Test** Prec@1 62.180 Prec@5 96.980 Error@1 37.820

==>>[2021-05-03 22:59:33] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.000697] [Best : Accuracy=54.08, Error=45.92]
  Epoch: [001][000/500]   Time 0.188 (0.188)   Data 0.119 (0.119)   Loss 1.3967 (1.3967)   Prec@1 52.000 (52.000)   Prec@5 93.000 (93.000)   [2021-05-03 22:59:33]
  Epoch: [001][200/500]   Time 0.150 (0.148)   Data 0.000 (0.001)   Loss 1.4858 (1.3744)   Prec@1 50.000 (49.766)   Prec@5 91.000 (93.269)   [2021-05-03 23:00:03]
  Epoch: [001][400/500]   Time 0.151 (0.149)   Data 0.000 (0.000)   Loss 1.1621 (1.3634)   Prec@1 58.000 (50.010)   Prec@5 100.000 (93.464)   [2021-05-03 23:00:33]
  **Train** Prec@1 50.154 Prec@5 93.556 Error@1 49.846
  **Test** Prec@1 56.980 Prec@5 95.820 Error@1 43.020

==>>[2021-05-03 23:00:51] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.000000] [Best : Accuracy=54.08, Error=45.92]
  Epoch: [001][000/500]   Time 0.194 (0.194)   Data 0.127 (0.127)   Loss 1.4721 (1.4721)   Prec@1 53.000 (53.000)   Prec@5 90.000 (90.000)   [2021-05-03 23:00:51]
  Epoch: [001][200/500]   Time 0.148 (0.150)   Data 0.000 (0.001)   Loss 1.4950 (1.4003)   Prec@1 49.000 (48.269)   Prec@5 92.000 (93.343)   [2021-05-03 23:01:21]
  Epoch: [001][400/500]   Time 0.150 (0.150)   Data 0.000 (0.000)   Loss 1.3784 (1.4028)   Prec@1 52.000 (48.342)   Prec@5 95.000 (93.090)   [2021-05-03 23:01:51]
  **Train** Prec@1 48.368 Prec@5 93.176 Error@1 51.632
  **Test** Prec@1 53.960 Prec@5 95.140 Error@1 46.040
