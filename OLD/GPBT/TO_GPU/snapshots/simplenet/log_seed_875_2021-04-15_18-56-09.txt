save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.945371659064528, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 875, 'use_cuda': True, 'aiteration': 0, 'drp': 0.09621751290862249, 'eps': 0.0016663222131287727, 'lr': 0.1607057356651594, 'weight_decay': 0.0015684091652539648}
Random Seed: 875
python version : 3.7.10 (default, Feb 20 2021, 21:17:23)  [GCC 7.5.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '875'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-04-15 18:56:14] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.160706] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 3.009 (3.009)   Data 0.174 (0.174)   Loss 2.3856 (2.3856)   Prec@1 8.000 (8.000)   Prec@5 52.000 (52.000)   [2021-04-15 18:56:17]
  Epoch: [000][200/500]   Time 0.173 (0.190)   Data 0.000 (0.001)   Loss 1.5895 (1.7908)   Prec@1 43.000 (33.075)   Prec@5 89.000 (85.458)   [2021-04-15 18:56:52]
  Epoch: [000][400/500]   Time 0.181 (0.184)   Data 0.000 (0.001)   Loss 1.2243 (1.6213)   Prec@1 55.000 (39.943)   Prec@5 96.000 (88.978)   [2021-04-15 18:57:28]
  **Train** Prec@1 42.710 Prec@5 90.104 Error@1 57.290
  **Test** Prec@1 52.380 Prec@5 93.360 Error@1 47.620
  **Test** Prec@1 53.100 Prec@5 93.240 Error@1 46.900

==>>[2021-04-15 19:02:47] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.160706] [Best : Accuracy=52.38, Error=47.62]
  Epoch: [001][000/500]   Time 0.267 (0.267)   Data 0.150 (0.150)   Loss 1.1199 (1.1199)   Prec@1 63.000 (63.000)   Prec@5 95.000 (95.000)   [2021-04-15 19:02:47]
  Epoch: [001][200/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 1.2703 (1.1652)   Prec@1 54.000 (58.015)   Prec@5 95.000 (95.308)   [2021-04-15 19:03:23]
  Epoch: [001][400/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 1.0483 (1.1012)   Prec@1 60.000 (60.514)   Prec@5 95.000 (95.893)   [2021-04-15 19:03:59]
  **Train** Prec@1 61.640 Prec@5 96.018 Error@1 38.360
  **Test** Prec@1 62.380 Prec@5 96.480 Error@1 37.620

==>>[2021-04-15 19:04:19] [Epoch=002/540] [Need: 00:00:00] [learning_rate=0.160706] [Best : Accuracy=62.38, Error=37.62]
  Epoch: [002][000/500]   Time 0.263 (0.263)   Data 0.150 (0.150)   Loss 0.8814 (0.8814)   Prec@1 67.000 (67.000)   Prec@5 98.000 (98.000)   [2021-04-15 19:04:19]
  Epoch: [002][200/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.8512 (0.9074)   Prec@1 71.000 (68.030)   Prec@5 96.000 (97.189)   [2021-04-15 19:04:55]
  Epoch: [002][400/500]   Time 0.179 (0.179)   Data 0.000 (0.001)   Loss 0.8458 (0.8694)   Prec@1 66.000 (69.800)   Prec@5 99.000 (97.431)   [2021-04-15 19:05:31]
  **Train** Prec@1 70.256 Prec@5 97.554 Error@1 29.744
  **Test** Prec@1 69.860 Prec@5 98.000 Error@1 30.140

==>>[2021-04-15 19:05:52] [Epoch=003/540] [Need: 00:00:00] [learning_rate=0.160706] [Best : Accuracy=69.86, Error=30.14]
  Epoch: [003][000/500]   Time 0.264 (0.264)   Data 0.155 (0.155)   Loss 0.7548 (0.7548)   Prec@1 70.000 (70.000)   Prec@5 98.000 (98.000)   [2021-04-15 19:05:52]
  Epoch: [003][200/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.6072 (0.7489)   Prec@1 77.000 (73.856)   Prec@5 98.000 (98.109)   [2021-04-15 19:06:28]
  Epoch: [003][400/500]   Time 0.180 (0.179)   Data 0.000 (0.001)   Loss 0.6432 (0.7390)   Prec@1 78.000 (74.244)   Prec@5 99.000 (98.132)   [2021-04-15 19:07:04]
  **Train** Prec@1 74.564 Prec@5 98.168 Error@1 25.436
  **Test** Prec@1 74.020 Prec@5 97.760 Error@1 25.980

==>>[2021-04-15 19:07:24] [Epoch=004/540] [Need: 00:00:00] [learning_rate=0.160706] [Best : Accuracy=74.02, Error=25.98]
  Epoch: [004][000/500]   Time 0.270 (0.270)   Data 0.157 (0.157)   Loss 0.6694 (0.6694)   Prec@1 79.000 (79.000)   Prec@5 99.000 (99.000)   [2021-04-15 19:07:24]
  Epoch: [004][200/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.6124 (0.6713)   Prec@1 76.000 (76.975)   Prec@5 100.000 (98.507)   [2021-04-15 19:08:00]
  Epoch: [004][400/500]   Time 0.180 (0.179)   Data 0.000 (0.001)   Loss 0.5836 (0.6584)   Prec@1 79.000 (77.476)   Prec@5 100.000 (98.569)   [2021-04-15 19:08:36]
  **Train** Prec@1 77.698 Prec@5 98.580 Error@1 22.302
  **Test** Prec@1 80.260 Prec@5 98.980 Error@1 19.740

==>>[2021-04-15 19:08:56] [Epoch=005/540] [Need: 00:00:00] [learning_rate=0.160706] [Best : Accuracy=80.26, Error=19.74]
  Epoch: [005][000/500]   Time 0.271 (0.271)   Data 0.168 (0.168)   Loss 0.5130 (0.5130)   Prec@1 80.000 (80.000)   Prec@5 98.000 (98.000)   [2021-04-15 19:08:57]
  Epoch: [005][200/500]   Time 0.176 (0.179)   Data 0.000 (0.001)   Loss 0.5283 (0.6105)   Prec@1 80.000 (79.060)   Prec@5 98.000 (98.851)   [2021-04-15 19:09:33]
  Epoch: [005][400/500]   Time 0.183 (0.179)   Data 0.000 (0.001)   Loss 0.5749 (0.6036)   Prec@1 78.000 (79.357)   Prec@5 100.000 (98.736)   [2021-04-15 19:10:08]
  **Train** Prec@1 79.512 Prec@5 98.776 Error@1 20.488
  **Test** Prec@1 80.460 Prec@5 98.840 Error@1 19.540
