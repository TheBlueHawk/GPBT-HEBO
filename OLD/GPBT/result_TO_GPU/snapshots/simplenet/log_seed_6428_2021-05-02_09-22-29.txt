save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.9833243614365847, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 6428, 'use_cuda': True, 'aiteration': 0, 'drp': 0.07270263318003388, 'eps': 0.002037667567944254, 'lr': 0.1022546208558808, 'weight_decay': 0.003228688002975871}
Random Seed: 6428
python version : 3.6.9 (default, Jan 26 2021, 15:33:00)  [GCC 8.4.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '6428'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-05-02 09:22:30] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.102255] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 0.137 (0.137)   Data 0.098 (0.098)   Loss 2.3793 (2.3793)   Prec@1 8.000 (8.000)   Prec@5 54.000 (54.000)   [2021-05-02 09:22:31]
  Epoch: [000][200/500]   Time 0.069 (0.070)   Data 0.000 (0.001)   Loss 1.5752 (1.7690)   Prec@1 47.000 (34.104)   Prec@5 86.000 (85.269)   [2021-05-02 09:22:45]
  Epoch: [000][400/500]   Time 0.070 (0.070)   Data 0.000 (0.000)   Loss 1.3850 (1.5950)   Prec@1 54.000 (40.960)   Prec@5 96.000 (88.973)   [2021-05-02 09:22:58]
  **Train** Prec@1 43.492 Prec@5 90.042 Error@1 56.508
  **Test** Prec@1 58.240 Prec@5 94.720 Error@1 41.760
  **Test** Prec@1 59.180 Prec@5 94.900 Error@1 40.820

==>>[2021-05-02 09:34:47] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.102255] [Best : Accuracy=58.24, Error=41.76]
  Epoch: [001][000/500]   Time 0.138 (0.138)   Data 0.102 (0.102)   Loss 1.3343 (1.3343)   Prec@1 53.000 (53.000)   Prec@5 92.000 (92.000)   [2021-05-02 09:34:48]
  Epoch: [001][200/500]   Time 0.070 (0.070)   Data 0.000 (0.001)   Loss 0.8880 (1.1442)   Prec@1 67.000 (58.786)   Prec@5 98.000 (95.781)   [2021-05-02 09:35:02]
  Epoch: [001][400/500]   Time 0.069 (0.070)   Data 0.000 (0.000)   Loss 1.0289 (1.0760)   Prec@1 64.000 (61.611)   Prec@5 97.000 (96.229)   [2021-05-02 09:35:15]
  **Train** Prec@1 62.600 Prec@5 96.350 Error@1 37.400
  **Test** Prec@1 67.800 Prec@5 97.540 Error@1 32.200

==>>[2021-05-02 09:35:24] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.002560] [Best : Accuracy=58.24, Error=41.76]
  Epoch: [001][000/500]   Time 0.137 (0.137)   Data 0.102 (0.102)   Loss 1.1563 (1.1563)   Prec@1 57.000 (57.000)   Prec@5 98.000 (98.000)   [2021-05-02 09:35:24]
  Epoch: [001][200/500]   Time 0.070 (0.070)   Data 0.000 (0.001)   Loss 1.2758 (1.1357)   Prec@1 51.000 (59.333)   Prec@5 94.000 (95.701)   [2021-05-02 09:35:38]
  Epoch: [001][400/500]   Time 0.070 (0.070)   Data 0.000 (0.000)   Loss 1.0382 (1.1100)   Prec@1 65.000 (60.446)   Prec@5 98.000 (96.005)   [2021-05-02 09:35:52]
  **Train** Prec@1 60.716 Prec@5 95.984 Error@1 39.284
  **Test** Prec@1 65.420 Prec@5 97.540 Error@1 34.580

==>>[2021-05-02 09:36:00] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.001791] [Best : Accuracy=58.24, Error=41.76]
  Epoch: [001][000/500]   Time 0.136 (0.136)   Data 0.100 (0.100)   Loss 1.2394 (1.2394)   Prec@1 59.000 (59.000)   Prec@5 93.000 (93.000)   [2021-05-02 09:36:00]
  Epoch: [001][200/500]   Time 0.070 (0.070)   Data 0.000 (0.001)   Loss 1.0472 (1.1405)   Prec@1 62.000 (59.433)   Prec@5 93.000 (95.632)   [2021-05-02 09:36:14]
  Epoch: [001][400/500]   Time 0.069 (0.070)   Data 0.000 (0.000)   Loss 1.0921 (1.1215)   Prec@1 62.000 (59.681)   Prec@5 97.000 (95.736)   [2021-05-02 09:36:28]
  **Train** Prec@1 59.962 Prec@5 95.788 Error@1 40.038
  **Test** Prec@1 65.160 Prec@5 97.320 Error@1 34.840

==>>[2021-05-02 09:36:37] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.002536] [Best : Accuracy=58.24, Error=41.76]
  Epoch: [001][000/500]   Time 0.136 (0.136)   Data 0.099 (0.099)   Loss 1.0587 (1.0587)   Prec@1 59.000 (59.000)   Prec@5 99.000 (99.000)   [2021-05-02 09:36:37]
  Epoch: [001][200/500]   Time 0.070 (0.070)   Data 0.000 (0.001)   Loss 1.2237 (1.1385)   Prec@1 56.000 (59.159)   Prec@5 92.000 (95.423)   [2021-05-02 09:36:51]
  Epoch: [001][400/500]   Time 0.070 (0.070)   Data 0.000 (0.000)   Loss 1.1947 (1.1102)   Prec@1 56.000 (60.195)   Prec@5 95.000 (95.820)   [2021-05-02 09:37:05]
  **Train** Prec@1 60.388 Prec@5 95.904 Error@1 39.612
  **Test** Prec@1 65.620 Prec@5 97.460 Error@1 34.380

==>>[2021-05-02 09:37:13] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.000569] [Best : Accuracy=58.24, Error=41.76]
  Epoch: [001][000/500]   Time 0.139 (0.139)   Data 0.103 (0.103)   Loss 1.0797 (1.0797)   Prec@1 64.000 (64.000)   Prec@5 95.000 (95.000)   [2021-05-02 09:37:13]
  Epoch: [001][200/500]   Time 0.070 (0.070)   Data 0.000 (0.001)   Loss 1.1387 (1.1761)   Prec@1 56.000 (57.697)   Prec@5 97.000 (95.090)   [2021-05-02 09:37:27]
  Epoch: [001][400/500]   Time 0.070 (0.070)   Data 0.000 (0.000)   Loss 1.0467 (1.1542)   Prec@1 63.000 (58.618)   Prec@5 97.000 (95.319)   [2021-05-02 09:37:41]
  **Train** Prec@1 58.788 Prec@5 95.368 Error@1 41.212
  **Test** Prec@1 63.800 Prec@5 97.060 Error@1 36.200
