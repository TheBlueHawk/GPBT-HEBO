save path : ./snapshots/simplenet
{'data_path': './data/cifar.python', 'dataset': 'cifar10', 'arch': 'simplenet', 'epochs': 540, 'batch_size': 100, 'learning_rate': 0.1, 'momentum': 0.8821637388435417, 'decay': 0.002, 'print_freq': 200, 'save_path': './snapshots/simplenet', 'resume': '', 'start_epoch': 0, 'evaluate': False, 'ngpu': 1, 'workers': 2, 'manualSeed': 8302, 'use_cuda': True, 'aiteration': 0, 'drp': 0.08026243606224027, 'eps': 0.005847742775320022, 'lr': 0.1460663074297066, 'weight_decay': 0.001383931784560871}
Random Seed: 8302
python version : 3.7.10 (default, Feb 20 2021, 21:17:23)  [GCC 7.5.0]
torch  version : 1.6.0
cudnn  version : 7605
=> creating model 'simplenet'
=> Seed '8302'
=> dataset mean and std '[0.4913725490196078, 0.4823529411764706, 0.4466666666666667] - [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]'
=> did not use any checkpoint for simplenet model

==>>[2021-04-15 18:05:24] [Epoch=000/540] [Need: 00:00:00] [learning_rate=0.146066] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 3.049 (3.049)   Data 0.187 (0.187)   Loss 2.3687 (2.3687)   Prec@1 13.000 (13.000)   Prec@5 51.000 (51.000)   [2021-04-15 18:05:27]
  Epoch: [000][200/500]   Time 0.179 (0.191)   Data 0.000 (0.001)   Loss 1.3188 (1.7545)   Prec@1 51.000 (34.259)   Prec@5 93.000 (86.159)   [2021-04-15 18:06:03]
  Epoch: [000][400/500]   Time 0.179 (0.185)   Data 0.000 (0.001)   Loss 1.2550 (1.6010)   Prec@1 53.000 (40.571)   Prec@5 97.000 (89.461)   [2021-04-15 18:06:38]
  **Train** Prec@1 43.058 Prec@5 90.428 Error@1 56.942
  **Test** Prec@1 58.880 Prec@5 95.660 Error@1 41.120

==>>[2021-04-15 18:06:59] [Epoch=001/540] [Need: 00:00:00] [learning_rate=0.146066] [Best : Accuracy=58.88, Error=41.12]
  Epoch: [001][000/500]   Time 0.242 (0.242)   Data 0.150 (0.150)   Loss 1.0984 (1.0984)   Prec@1 61.000 (61.000)   Prec@5 95.000 (95.000)   [2021-04-15 18:06:59]
  Epoch: [001][200/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.9281 (1.1619)   Prec@1 66.000 (58.239)   Prec@5 97.000 (95.622)   [2021-04-15 18:07:35]
  Epoch: [001][400/500]   Time 0.179 (0.179)   Data 0.000 (0.001)   Loss 0.7472 (1.1038)   Prec@1 76.000 (60.571)   Prec@5 99.000 (96.027)   [2021-04-15 18:08:11]
  **Train** Prec@1 61.672 Prec@5 96.212 Error@1 38.328
  **Test** Prec@1 66.320 Prec@5 97.440 Error@1 33.680
  **Test** Prec@1 66.860 Prec@5 97.480 Error@1 33.140

==>>[2021-04-15 18:13:22] [Epoch=002/540] [Need: 00:00:00] [learning_rate=0.146066] [Best : Accuracy=66.32, Error=33.68]
  Epoch: [002][000/500]   Time 0.280 (0.280)   Data 0.163 (0.163)   Loss 0.8739 (0.8739)   Prec@1 69.000 (69.000)   Prec@5 99.000 (99.000)   [2021-04-15 18:13:22]
  Epoch: [002][200/500]   Time 0.178 (0.180)   Data 0.000 (0.001)   Loss 1.1021 (0.8960)   Prec@1 65.000 (68.070)   Prec@5 95.000 (97.428)   [2021-04-15 18:13:58]
  Epoch: [002][400/500]   Time 0.179 (0.180)   Data 0.000 (0.001)   Loss 0.6011 (0.8687)   Prec@1 73.000 (69.259)   Prec@5 99.000 (97.534)   [2021-04-15 18:14:34]
  **Train** Prec@1 69.712 Prec@5 97.612 Error@1 30.288
  **Test** Prec@1 71.520 Prec@5 98.240 Error@1 28.480

==>>[2021-04-15 18:14:54] [Epoch=003/540] [Need: 00:00:00] [learning_rate=0.146066] [Best : Accuracy=71.52, Error=28.48]
  Epoch: [003][000/500]   Time 0.261 (0.261)   Data 0.164 (0.164)   Loss 0.6854 (0.6854)   Prec@1 80.000 (80.000)   Prec@5 99.000 (99.000)   [2021-04-15 18:14:55]
  Epoch: [003][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.7511 (0.7512)   Prec@1 71.000 (73.950)   Prec@5 100.000 (98.149)   [2021-04-15 18:15:30]
  Epoch: [003][400/500]   Time 0.178 (0.180)   Data 0.000 (0.001)   Loss 0.6899 (0.7417)   Prec@1 73.000 (74.257)   Prec@5 98.000 (98.182)   [2021-04-15 18:16:06]
  **Train** Prec@1 74.634 Prec@5 98.240 Error@1 25.366
  **Test** Prec@1 75.880 Prec@5 98.300 Error@1 24.120
  **Test** Prec@1 76.180 Prec@5 98.080 Error@1 23.820

==>>[2021-04-15 18:16:30] [Epoch=002/540] [Need: 00:00:00] [learning_rate=0.003068] [Best : Accuracy=66.32, Error=33.68]
  Epoch: [002][000/500]   Time 0.261 (0.261)   Data 0.160 (0.160)   Loss 1.0797 (1.0797)   Prec@1 63.000 (63.000)   Prec@5 96.000 (96.000)   [2021-04-15 18:16:30]
  Epoch: [002][200/500]   Time 0.178 (0.180)   Data 0.000 (0.001)   Loss 0.7767 (0.8785)   Prec@1 73.000 (68.990)   Prec@5 96.000 (97.473)   [2021-04-15 18:17:06]
  Epoch: [002][400/500]   Time 0.185 (0.180)   Data 0.000 (0.001)   Loss 0.7848 (0.8544)   Prec@1 72.000 (69.940)   Prec@5 98.000 (97.706)   [2021-04-15 18:17:42]
  **Train** Prec@1 70.108 Prec@5 97.770 Error@1 29.892
  **Test** Prec@1 74.240 Prec@5 98.380 Error@1 25.760

==>>[2021-04-15 18:18:02] [Epoch=003/540] [Need: 00:00:00] [learning_rate=0.003068] [Best : Accuracy=74.24, Error=25.76]
  Epoch: [003][000/500]   Time 0.261 (0.261)   Data 0.148 (0.148)   Loss 0.6838 (0.6838)   Prec@1 74.000 (74.000)   Prec@5 99.000 (99.000)   [2021-04-15 18:18:02]
  Epoch: [003][200/500]   Time 0.180 (0.180)   Data 0.000 (0.001)   Loss 0.7083 (0.8158)   Prec@1 74.000 (71.617)   Prec@5 100.000 (97.811)   [2021-04-15 18:18:38]
  Epoch: [003][400/500]   Time 0.185 (0.180)   Data 0.000 (0.001)   Loss 0.7670 (0.8129)   Prec@1 74.000 (71.561)   Prec@5 100.000 (97.863)   [2021-04-15 18:19:14]
  **Train** Prec@1 71.548 Prec@5 97.846 Error@1 28.452
  **Test** Prec@1 74.680 Prec@5 98.500 Error@1 25.320
  **Test** Prec@1 75.780 Prec@5 98.760 Error@1 24.220
